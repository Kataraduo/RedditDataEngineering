id,title,selftext,score,num_comments,author,created_utc,url,gilded,subreddit
13akk9t,[ Removed by Reddit ],[ Removed by Reddit on account of violating the [content policy](/help/contentpolicy). ],1391,5394,mr_backster,2023-05-07 11:02:24,https://www.reddit.com/r/deeplearning/comments/13akk9t/removed_by_reddit/,0,deeplearning
jrkw6i,Training Deep NN be like,,678,26,alexein777,2020-11-10 13:26:19,https://v.redd.it/dfekpj9bzey51,0,deeplearning
jkci6f,Exploring MNIST Latent Space,,577,34,goatman12341,2020-10-29 15:48:34,https://v.redd.it/wywpgnyt12w51,0,deeplearning
gfpdsc,Taking code from GitHub and running on your data,,560,7,noidiz,2020-05-08 08:39:13,https://i.redd.it/j7p8pwto6ix41.jpg,0,deeplearning
ipfe2l,Holy crap! Some guy shouted ‚ÄúMachine learning is just statistics!‚Äù and then this happened,,509,40,lordcris,2020-09-09 12:58:12,https://v.redd.it/fe5dsy1wd4m51,0,deeplearning
jwempm,I work with models,,499,13,goncaloperes,2020-11-18 12:07:08,https://i.redd.it/2n3fosslozz51.jpg,0,deeplearning
hu6c0d,The truth üíØ! üòÇ,,441,23,aymenSekhri,2020-07-19 19:22:06,https://i.redd.it/8ju3joi07vb51.jpg,0,deeplearning
lu430g,It happens üòú,,435,14,mugeshk_97,2021-02-28 03:17:04,https://i.redd.it/42z4z651z4k61.jpg,0,deeplearning
lqknmb,üòÇ,,432,9,mugeshk_97,2021-02-23 15:13:36,https://i.redd.it/sb9a527bu8j61.jpg,0,deeplearning
ol41l0,[ Removed by Reddit ],[ Removed by Reddit on account of violating the [content policy](/help/contentpolicy). ],425,600,internweb,2021-07-15 22:57:44,https://www.reddit.com/r/deeplearning/comments/ol41l0/removed_by_reddit/,0,deeplearning
g45qwn,The merits of having many monitors,,408,16,abdeljalil73,2020-04-19 10:49:53,https://v.redd.it/cc6o948i8rt41,0,deeplearning
o6v6y8,a wild course of action.,,387,13,911OpenUp,2021-06-24 06:28:27,https://i.redd.it/8aspr95xq5771.jpg,0,deeplearning
j5n787,GANs,,394,13,prathamesh3099,2020-10-05 17:00:17,https://i.redd.it/5yvzg0bt4br51.png,0,deeplearning
mw2ro8,"""I've never met this man in my life""",,371,21,alexein777,2021-04-22 11:35:27,https://i.redd.it/jzyej8k9opu61.jpg,0,deeplearning
etlds7,Google datasets search,,335,16,theroyakash,2020-01-25 03:19:56,https://i.imgur.com/tcgffgE.jpg,0,deeplearning
i3agkp,signal/noise ratio,,315,8,redmoon_reddit,2020-08-04 01:52:04,https://i.redd.it/guwiw3796we51.png,0,deeplearning
17993et,What's the new thing is he talking about?,,318,136,TheUserIsUnknown,2023-10-16 15:46:56,https://i.redd.it/zs1unuhf5lub1.png,0,deeplearning
vgqwg2,Nature is healing,,299,15,moetsi_op,2022-06-20 17:29:33,https://i.redd.it/a0h9iavx9t691.jpg,0,deeplearning
gtivxj,Andrew be like,,295,7,8226,2020-05-30 18:16:36,https://i.redd.it/kobpy01r1y151.jpg,0,deeplearning
l0ulzy,Feast on my tears folks,,288,26,alexein777,2021-01-19 22:10:02,https://v.redd.it/zx8wb0xi4dc61,0,deeplearning
1au2avn,Transfer Learning vs. Fine-tuning vs. Multitask Learning vs. Federated Learning,,286,19,avee-81,2024-02-18 19:23:16,https://i.redd.it/hgq59vly9ejc1.gif,0,deeplearning
efvoyo,It's been a decade,,270,3,ashutoshatpandey,2019-12-26 13:57:30,https://i.redd.it/pp1on0qbhz641.jpg,0,deeplearning
hp4gto,"*Pro Tip* : When you do a task by hand, you can technically say that you trained neural nets to do it.",,245,10,james_shah,2020-07-11 05:11:19,https://i.redd.it/nvie9iuxv5a51.jpg,0,deeplearning
fueq8y,Deep Learning,,235,8,VeryOddEvey,2020-04-03 19:26:50,https://i.redd.it/t87gswsbmnq41.jpg,0,deeplearning
f26nc3,When your machine learning algorithm doesn't generalise well on real data,,235,5,ale152,2020-02-11 10:40:15,https://v.redd.it/f4g4bm3bw9g41,0,deeplearning
1b6g8ft,Full fine-tuning vs. LoRA fine-tuning vs. RAG,,230,18,avee-81,2024-03-04 17:09:43,https://i.redd.it/nw690mlnncmc1.gif,0,deeplearning
hzve33,(DataScienceHumor) Me while reading a research paper!,,225,13,dpkmc2,2020-07-29 06:04:45,https://i.redd.it/khvxftovlqd51.jpg,0,deeplearning
171zusp,Visualisation of each layer of a feed forward neural network as it learns from a dataset (regression),,224,15,None,2023-10-07 07:02:09,https://v.redd.it/a82hxfkgbqsb1,0,deeplearning
o0m0lk,(Data Science Humour) I've found this to be really accurate. Making something from scratch and then moving on to libraries is the best way to learn.,,221,30,None,2021-06-15 19:07:38,https://i.redd.it/adgnnwvx9h571.jpg,0,deeplearning
qasw2b,How to confuse machine learning,,214,13,lordnyrox,2021-10-18 18:34:50,https://i.redd.it/m2hl3d5969u71.jpg,0,deeplearning
dc7e1s,Deepfakes video from #TheOffice. Creeped out max.,,209,12,warmachine0609,2019-10-02 08:31:25,https://v.redd.it/cwzedv4m93q31,0,deeplearning
mgfhgo,Taking a walk after thinking deeply about CNNs,,204,7,Giacobako,2021-03-30 13:00:57,https://i.redd.it/aypo6ppjy5q61.jpg,0,deeplearning
19eeu70,Pondering torch vs TF - change my mind!,,200,49,nuke-from-orbit,2024-01-24 11:19:54,https://i.redd.it/ni2uzuhvgdec1.jpeg,0,deeplearning
nv6mzi,GAN trained on instagram models,,197,49,ThisModelDoesNotExis,2021-06-08 15:34:00,https://v.redd.it/50i9nxgv72471,0,deeplearning
14aqfp7,Performing NERF scenes reconstruction using only the eye reflection,,198,15,adesigne,2023-06-16 07:42:43,https://v.redd.it/ym5zi27u3c6b1,0,deeplearning
ox9xil,The devotion is real,,195,9,tumbleweedinthewind,2021-08-03 18:42:38,https://i.redd.it/lyeo3w7du6f71.jpg,0,deeplearning
k5ba3j,Putting those 175B parameters to good use.,,192,9,BryanKeller,2020-12-02 15:28:46,https://i.redd.it/t2qscww2ks261.png,0,deeplearning
10a3fwn,"I just started out guys, wish me luck",,190,11,47153,2023-01-12 16:14:55,https://i.redd.it/2xnt0pcxhoba1.jpg,0,deeplearning
r4aj44,PyTorch implementation of AnimeGANv2,,188,6,Illustrious_Row_9971,2021-11-28 18:15:34,https://i.redd.it/5845gy35od281.gif,0,deeplearning
11hezvk,Meta‚Äôs LLaMa weights leaked on torrent... and the best thing about it is someone put up a PR to replace the google form in the repo with it üòÇ,,185,23,RandomForests92,2023-03-03 21:08:20,https://i.redd.it/olnsv438alla1.jpg,0,deeplearning
dn9wny,Coursera Staff:If you want Andrew Ng to come out and teach the reinforcement learning? Vote this one,"Please vote here in this post if: **you want Andrew Ng to come out and teach the reinforcement learning.**

For more info: please check this post too.

 [https://coursera.community/course-suggestions-51/a-reinforcement-learning-course-by-andrew-ng-2528](https://coursera.community/course-suggestions-51/a-reinforcement-learning-course-by-andrew-ng-2528)",176,11,None,2019-10-26 05:57:52,https://www.reddit.com/r/deeplearning/comments/dn9wny/coursera_staffif_you_want_andrew_ng_to_come_out/,0,deeplearning
bs8hxd,Samsung AI lab develops tech that can animate highly realistic heads using only a few -or in some cases - only one starter image. (Paper: https://arxiv.org/abs/1905.08233),,177,13,ai-lover,2019-05-23 21:23:07,https://v.redd.it/1xno8etz21031,0,deeplearning
xigwzl,Real time 3D reconstruction with SimpleRecon,,177,4,imapurplemango,2022-09-19 16:17:18,https://v.redd.it/n0xjxvbubuo91,0,deeplearning
gsqgkv,Deep Learning with Keras Cheatsheet,,174,13,TheInsaneApp,2020-05-29 10:30:25,https://i.redd.it/582mihynlo151.jpg,0,deeplearning
pcfdmn,What do you wish for?,,175,8,tumbleweedinthewind,2021-08-27 03:39:52,https://i.redd.it/cktaszm6ntj71.jpg,0,deeplearning
138ttjq,Controlnet Face Model Test,,170,13,oridnary_artist,2023-05-05 16:28:05,https://v.redd.it/wzztqfmoh1ya1,0,deeplearning
jaz595,Van Gogh in video - Neural Style Transfer,,171,12,infundibuliforme,2020-10-14 11:47:17,https://v.redd.it/79jr8953s1t51,0,deeplearning
l18vyc,Sequence-Based Neural Nets Be Like,,172,13,goatman12341,2021-01-20 13:11:32,https://i.redd.it/j1kiv6kjlhc61.jpg,0,deeplearning
no9wjf,Street Murals start singing thanks to Deepfake,,168,4,Olyapyramid,2021-05-30 12:11:35,https://v.redd.it/xp89vy8719271,0,deeplearning
zdi9v6,the biggest risk with generative AI is not its potential for misinformation but cringe.,,165,9,hayAbhay,2022-12-05 20:18:25,https://i.redd.it/xpkmbw06154a1.png,0,deeplearning
rywv0p,These Tits Do Not Exist,,166,34,DrearyLisper,2022-01-08 10:23:08,https://www.thesetitsdonotexist.com,0,deeplearning
122hvp8,Angle Tracking for Football using Python and Mediapipe,,164,17,oridnary_artist,2023-03-26 10:16:38,https://v.redd.it/chgjtezz62qa1,0,deeplearning
pk5zk4,Project: Real Time Recognition of Handwritten Math Functions and Predicting their Graphs using Machine Learning & Computer Vision,,163,1,TheInsaneApp,2021-09-08 07:47:23,https://v.redd.it/fhlzn5tcc1m71,0,deeplearning
smrpbg,Long Short Term Memory Visualized,,159,12,TheInsaneApp,2022-02-07 14:36:19,https://v.redd.it/afzlbpt2ncg81,0,deeplearning
f3swnk,Happy Valentine's Day my dudes :). May we all find our global minima <3 <3,,160,12,GrImPeAper23032000,2020-02-14 14:27:11,https://i.redd.it/cbmvkyz0gwg41.jpg,0,deeplearning
dj02ev,PyTorch or die,,155,20,philippemnoel,2019-10-17 02:39:06,https://i.redd.it/5hpnpwcfk0t31.jpg,0,deeplearning
c1ws2b,"Quick art by Nvidia GauGAN, this is the mountain in my dream [Site: http://52.12.58.174]",,158,10,bonnieng,2019-06-18 02:45:27,https://i.redd.it/4kyct8b031531.png,0,deeplearning
ggo6x4,[Tutorial] Converting old footage to 4K + 60fps + colorized with AI,,154,7,tombalev,2020-05-09 21:33:22,https://v.redd.it/6z1px1765tx41,0,deeplearning
uoupt6,Rendering 3D objects using differentiable SDFs,,152,19,imapurplemango,2022-05-13 15:48:49,https://v.redd.it/t6d70a0bl9z81,0,deeplearning
g21oru,Ready to run a few models here - 4x TITAN RTX Water cooling build,,151,32,gimel1213,2020-04-15 21:56:01,https://i.redd.it/6b9isqsvz1t41.jpg,0,deeplearning
hdnb2l,TikTok New anime filter,,149,30,amarese,2020-06-22 07:02:12,https://v.redd.it/gzaywxt9ue651,0,deeplearning
ua87gm,GOOGLE researchers create animated avatars from a single photo,,148,5,SpatialComputing,2022-04-23 15:44:10,https://v.redd.it/ub7syme9gav81,0,deeplearning
mtaygk,Image & Video Background Removal Using Deep Learning,,144,12,nkapp,2021-04-18 11:19:16,https://v.redd.it/gbelvs630xt61,0,deeplearning
jokxvp,Real-time fingerspelling recognition from RGB camera finally exists !,,145,3,Fanos6,2020-11-05 15:42:32,https://v.redd.it/kqut7um4zfx51,0,deeplearning
nll3ce,Tutorial: Real-time YOLOv3 on a Laptop Using Sparse Quantization,,144,14,markurtz,2021-05-26 16:27:40,https://v.redd.it/j1f0yi39rh171,0,deeplearning
11slgy4,This is how a simplest neural network learns. read the first comment for further details,,142,24,Play-Equal,2023-03-16 05:44:46,https://v.redd.it/h76383keh1oa1,0,deeplearning
za73dc,GPT-3 Generated Rap Battle between Yann LeCun & Gary Marcus,,142,16,hayAbhay,2022-12-02 01:35:02,https://i.redd.it/ybfcfvez1e3a1.png,0,deeplearning
ce3yad,My notes for deeplearing.ai and fast.ai courses,"Hello guys,

During the past months I've gone through the deeplearing.ai specialization and fast.ai courses (the two deep learning courses and machine learning course), I've take some notes that I found myself I keep coming to them from time to time. So I though I'd share them and maybe someone will find them helpful, after taking sometime to polish them and correct spelling erros here they are:

- deeplearing.ai notes:  https://github.com/yassouali/deeplearning.ai_notes
- fastai notes: https://github.com/yassouali/fast.ai_notes",137,16,youali,2019-07-16 22:16:04,https://www.reddit.com/r/deeplearning/comments/ce3yad/my_notes_for_deeplearingai_and_fastai_courses/,0,deeplearning
ropc8l,I reviewed that boy.,,138,0,AsaduzZamanAZ,2021-12-26 04:33:54,https://i.redd.it/pxi55qt2ft781.jpg,0,deeplearning
103azcq,"Does anyone here use newer or custom frameworks aside from TensorFlow, Keras and PyTorch?","I was just starting out with ML and had no clue what I was doing. But eventually, I caught on and started reading about best practices and other stuff and I was reading an [article](https://jina.ai/news/why-dont-people-use-your-software-framework/) about why most people won‚Äôt use newer software frameworks. Specifically, the ones that are still hosted on Github.

I have a feeling people don't want to learn new things because they already worked hard to learn something else. Changing to a new way of doing things can be hard if it doesn't work with what you are already using. And it's hard to convince people to switch unless it‚Äôs a mandatory switch.

But I also think choosing a framework depends on people‚Äôs needs for their projects. If that project could benefit from that new framework or just use it out of curiosity, people would definitely try it out. If not, they‚Äôll just stick to the popular frameworks (i.e. TensorFlow or PyTorch).

So far what are your thoughts? Do you also use frameworks aside from the popular ones?",136,17,ConsciousInsects,2023-01-04 18:30:06,https://www.reddit.com/r/deeplearning/comments/103azcq/does_anyone_here_use_newer_or_custom_frameworks/,0,deeplearning
hpry5v,"After 3 years of doing Deep Learning, I sometimes still get this nightmare graph? Am I alone or someone else out here feels my pain? ( P.S This was a language generation model.)",,136,41,alaap001,2020-07-12 09:55:10,https://i.redd.it/q1xzladhfea51.jpg,0,deeplearning
ewxtqt,Quacks Like A Deep Fake,,133,2,None,2020-02-01 00:26:38,https://i.redd.it/pp8doz6ai7e41.png,0,deeplearning
b7z3sz,8x RTX TITAN workstation | I cannot wait to run some models on this beast !!!!,,130,33,gimel1213,2019-04-01 07:44:33,https://i.redd.it/uvef4oxkxlp21.jpg,0,deeplearning
hf0ngb,I made a flow chart on how to train deep neural networks. What do you think about it?,,136,21,komi96,2020-06-24 13:04:18,https://i.redd.it/vjd7sq8qwu651.png,0,deeplearning
tqaf1w,Learning to generate line drawings that convey geometry and semantics (CVPR 2022),,129,4,Illustrious_Row_9971,2022-03-28 14:22:46,https://v.redd.it/nchwu030w4q81,0,deeplearning
vwk673,Text2Live: Text driven neural image and video editing,,126,3,imapurplemango,2022-07-11 14:47:35,https://v.redd.it/gyhkst85cya91,0,deeplearning
19bxs6m,"How do you get ""really good"" ?","Hello my fellow DL enthusiasts,

I have close to 4 years of experience working majorly in computer vision and sometimes NLP. Even though I have worked on some challenging problems, I still feel that I am not as good as I should be. 

For example, if given a paper, I would be able to understand it no problem. But I won't be able to implement it and it's not that I lack programming knowledge as I am comfortable in pytorch. 


I can implement a simple NN using numpy from scratch or even Linear or Logistic regression. The reason I am mentioning this is that I have good understanding but I still feel that there is something which I am missing that separates me from an average ML engineer. 

Do I need to go for higher studies (Masters) to find that missing piece ?",126,38,ContributionWild5778,2024-01-21 07:17:27,https://www.reddit.com/r/deeplearning/comments/19bxs6m/how_do_you_get_really_good/,0,deeplearning
czidfj,"Fraudsters deepfake CEO's voice to trick manager into transferring $243,000",,123,10,LimarcAmbalina,2019-09-04 09:10:57,https://thenextweb.com/security/2019/09/02/fraudsters-deepfake-ceos-voice-to-trick-manager-into-transferring-243000/,0,deeplearning
hc2bjt,We're building a labeling platform for image segmentation. Looking for feedback!,,123,15,segments-bert,2020-06-19 15:06:29,https://v.redd.it/9kwwpa0ttv551,0,deeplearning
yzf32f,3D Novel view synthesis using diffusion models,,122,2,imapurplemango,2022-11-19 15:58:06,https://v.redd.it/a3ne8kn5kx0a1,0,deeplearning
e2x9r1,"Demonstrating American Sign Language Classification using Monk. Monk is an open-source low-code unified wrapper over major deep learning frameworks. Blog: http://bit.ly/sign_language_classification, Github: http://bit.ly/monk-github",,125,6,abhishek4273,2019-11-28 12:16:45,https://v.redd.it/fpdu1x8c5f141,0,deeplearning
rfofvw,ArcaneGAN: Face Portrait to Arcane Style,,121,6,Illustrious_Row_9971,2021-12-13 19:54:35,https://v.redd.it/q9l4c2qh7d581,0,deeplearning
okgenb,Me and my ‚ÄúProcess‚Äù,,120,4,DataScience-FTW,2021-07-14 23:26:56,https://i.redd.it/nv2svpnui9b71.gif,0,deeplearning
ejdwqz,"I made a python package that lets you remotely monitor your deep learning model's training and validation metrics. If you like this project, consider giving it a ‚≠ê on github. Link's in the comments.",,120,9,clean_pegasus,2020-01-03 10:56:32,https://i.redd.it/qcf910wboj841.jpg,0,deeplearning
taa0tv,"I published my first ever paper on ""Detection and Blocking of DNS Tunnelled Packages with DeepLearning "". Source code in the comments. Fell free to ask me if something wasn't clear on paper or source",,120,17,why_socynical,2022-03-09 15:18:08,https://i.redd.it/70so5x5bkdm81.gif,0,deeplearning
kv0qot,A neural network's internal weights adjusted to fit the training data (Implementation in pure Java),,118,9,longuyen2306,2021-01-11 11:17:53,https://i.redd.it/q2lx85rtsoa61.gif,0,deeplearning
10mhyek,‚≠ï What People Are Missing About Microsoft‚Äôs $10B Investment In OpenAI,"&#x200B;

[Sam Altman Might Have Just Pulled Off The Coup Of The Decade](https://preview.redd.it/sg24cw3zekea1.png?width=720&format=png&auto=webp&s=9eeae99b5e025a74a6cbe3aac7a842d2fff989a1)

Microsoft is investing $10B into OpenAI!

There is lots of frustration in the community about OpenAI not being all that open anymore. They appear to abandon their ethos of developing AI for everyone, [free](https://openai.com/blog/introducing-openai/) of economic pressures.

The fear is that OpenAI‚Äôs models are going to become fancy MS Office plugins. Gone would be the days of open research and innovation.

However, the specifics of the deal tell a different story.

To understand what is going on, we need to peek behind the curtain of the tough business of machine learning. We will find that Sam Altman might have just orchestrated the coup of the decade!

To appreciate better why there is some three-dimensional chess going on, let‚Äôs first look at Sam Altman‚Äôs backstory.

*Let‚Äôs go!*

# A Stellar Rise

Back in 2005, Sam Altman founded [Loopt](https://en.wikipedia.org/wiki/Loopt) and was part of the first-ever YC batch. He raised a total of $30M in funding, but the company failed to gain traction. Seven years into the business Loopt was basically dead in the water and had to be shut down.

Instead of caving, he managed to sell his startup for $[43M](https://golden.com/wiki/Sam_Altman-J5GKK5) to the finTech company [Green Dot](https://www.greendot.com/). Investors got their money back and he personally made $5M from the sale.

By YC standards, this was a pretty unimpressive outcome.

However, people took note that the fire between his ears was burning hotter than that of most people. So hot in fact that Paul Graham included him in his 2009 [essay](http://www.paulgraham.com/5founders.html?viewfullsite=1) about the five founders who influenced him the most.

He listed young Sam Altman next to Steve Jobs, Larry & Sergey from Google, and Paul Buchheit (creator of GMail and AdSense). He went on to describe him as a strategic mastermind whose sheer force of will was going to get him whatever he wanted.

And Sam Altman played his hand well!

He parleyed his new connections into raising $21M from Peter Thiel and others to start investing. Within four years he 10x-ed the money \[2\]. In addition, Paul Graham made him his successor as president of YC in 2014.

Within one decade of selling his first startup for $5M, he grew his net worth to a mind-bending $250M and rose to the circle of the most influential people in Silicon Valley.

Today, he is the CEO of OpenAI ‚Äî one of the most exciting and impactful organizations in all of tech.

However, OpenAI ‚Äî the rocket ship of AI innovation ‚Äî is in dire straights.

# OpenAI is Bleeding Cash

Back in 2015, OpenAI was kickstarted with $1B in donations from famous donors such as Elon Musk.

That money is long gone.

In 2022 OpenAI is projecting a revenue of $36M. At the same time, they spent roughly $544M. Hence the company has lost >$500M over the last year alone.

This is probably not an outlier year. OpenAI is headquartered in San Francisco and has a stable of 375 employees of mostly machine learning rockstars. Hence, salaries alone probably come out to be roughly $200M p.a.

In addition to high salaries their compute costs are stupendous. Considering it cost them $4.6M to train GPT3 once, it is likely that their cloud bill is in a very healthy nine-figure range as well \[4\].

So, where does this leave them today?

Before the Microsoft investment of $10B, OpenAI had received a total of $4B over its lifetime. With $4B in funding, a burn rate of $0.5B, and eight years of company history it doesn‚Äôt take a genius to figure out that they are running low on cash.

It would be reasonable to think: OpenAI is sitting on ChatGPT and other great models. Can‚Äôt they just lease them and make a killing?

Yes and no. OpenAI is projecting a revenue of $1B for 2024. However, it is unlikely that they could pull this off without significantly increasing their costs as well.

*Here are some reasons why!*

# The Tough Business Of Machine Learning

Machine learning companies are distinct from regular software companies. On the outside they look and feel similar: people are creating products using code, but on the inside things can be very different.

To start off, machine learning companies are usually way less profitable. Their gross margins land in the 50%-60% range, much lower than those of SaaS businesses, which can be as high as 80% \[7\].

On the one hand, the massive compute requirements and thorny data management problems drive up costs.

On the other hand, the work itself can sometimes resemble consulting more than it resembles software engineering. Everyone who has worked in the field knows that training models requires deep domain knowledge and loads of manual work on data.

To illustrate the latter point, imagine the unspeakable complexity of performing content moderation on ChatGPT‚Äôs outputs. If OpenAI scales the usage of GPT in production, they will need large teams of moderators to filter and label hate speech, slurs, tutorials on killing people, you name it.

*Alright, alright, alright! Machine learning is hard.*

*OpenAI already has ChatGPT working. That‚Äôs gotta be worth something?*

# Foundation Models Might Become Commodities:

In order to monetize GPT or any of their other models, OpenAI can go two different routes.

First, they could pick one or more verticals and sell directly to consumers. They could for example become the ultimate copywriting tool and blow [Jasper](https://app.convertkit.com/campaigns/10748016/jasper.ai) or [copy.ai](https://app.convertkit.com/campaigns/10748016/copy.ai) out of the water.

This is not going to happen. Reasons for it include:

1. To support their mission of building competitive foundational AI tools, and their huge(!) burn rate, they would need to capture one or more very large verticals.
2. They fundamentally need to re-brand themselves and diverge from their original mission. This would likely scare most of the talent away.
3. They would need to build out sales and marketing teams. Such a step would fundamentally change their culture and would inevitably dilute their focus on research.

The second option OpenAI has is to keep doing what they are doing and monetize access to their models via API. Introducing a [pro version](https://www.searchenginejournal.com/openai-chatgpt-professional/476244/) of ChatGPT is a step in this direction.

This approach has its own challenges. Models like GPT do have a defensible moat. They are just large transformer models trained on very large open-source datasets.

As an example, last week Andrej Karpathy released a [video](https://www.youtube.com/watch?v=kCc8FmEb1nY) of him coding up a version of GPT in an afternoon. Nothing could stop e.g. Google, StabilityAI, or HuggingFace from open-sourcing their own GPT.

As a result GPT inference would become a common good. This would melt OpenAI‚Äôs profits down to a tiny bit of nothing.

In this scenario, they would also have a very hard time leveraging their branding to generate returns. Since companies that integrate with OpenAI‚Äôs API control the interface to the customer, they would likely end up capturing all of the value.

An argument can be made that this is a general problem of foundation models. Their high fixed costs and lack of differentiation could end up making them akin to the [steel industry](https://www.thediff.co/archive/is-the-business-of-ai-more-like-steel-or-vba/).

To sum it up:

* They don‚Äôt have a way to sustainably monetize their models.
* They do not want and probably should not build up internal sales and marketing teams to capture verticals
* They need a lot of money to keep funding their research without getting bogged down by details of specific product development

*So, what should they do?*

# The Microsoft Deal

OpenAI and Microsoft [announced](https://blogs.microsoft.com/blog/2023/01/23/microsoftandopenaiextendpartnership/) the extension of their partnership with a $10B investment, on Monday.

At this point, Microsoft will have invested a total of $13B in OpenAI. Moreover, new VCs are in on the deal by buying up shares of employees that want to take some chips off the table.

However, the astounding size is not the only extraordinary thing about this deal.

First off, the ownership will be split across three groups. Microsoft will hold 49%, VCs another 49%, and the OpenAI foundation will control the remaining 2% of shares.

If OpenAI starts making money, the profits are distributed differently across four stages:

1. First, early investors (probably Khosla Ventures and Reid Hoffman‚Äôs foundation) get their money back with interest.
2. After that Microsoft is entitled to 75% of profits until the $13B of funding is repaid
3. When the initial funding is repaid, Microsoft and the remaining VCs each get 49% of profits. This continues until another $92B and $150B are paid out to Microsoft and the VCs, respectively.
4. Once the aforementioned money is paid to investors, 100% of shares return to the foundation, which regains total control over the company. \[3\]

# What This Means

This is absolutely crazy!

OpenAI managed to solve all of its problems at once. They raised a boatload of money and have access to all the compute they need.

On top of that, they solved their distribution problem. They now have access to Microsoft‚Äôs sales teams and their models will be integrated into MS Office products.

Microsoft also benefits heavily. They can play at the forefront AI, brush up their tools, and have OpenAI as an exclusive partner to further compete in a [bitter cloud war](https://www.projectpro.io/article/aws-vs-azure-who-is-the-big-winner-in-the-cloud-war/401) against AWS.

The synergies do not stop there.

OpenAI as well as GitHub (aubsidiary of Microsoft) e. g. will likely benefit heavily from the partnership as they continue to develop[ GitHub Copilot](https://github.com/features/copilot).

The deal creates a beautiful win-win situation, but that is not even the best part.

Sam Altman and his team at OpenAI essentially managed to place a giant hedge. If OpenAI does not manage to create anything meaningful or we enter a new AI winter, Microsoft will have paid for the party.

However, if OpenAI creates something in the direction of AGI ‚Äî whatever that looks like ‚Äî the value of it will likely be huge.

In that case, OpenAI will quickly repay the dept to Microsoft and the foundation will control 100% of whatever was created.

*Wow!*

Whether you agree with the path OpenAI has chosen or would have preferred them to stay donation-based, you have to give it to them.

*This deal is an absolute power move!*

I look forward to the future. Such exciting times to be alive!

As always, I really enjoyed making this for you and I sincerely hope you found it useful!

*Thank you for reading!*

Would you like to receive an article such as this one straight to your inbox every Thursday? Consider signing up for **The Decoding** ‚≠ï.

I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] [https://golden.com/wiki/Sam\_Altman-J5GKK5](https://golden.com/wiki/Sam_Altman-J5GKK5)‚Äã

\[2\] [https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny](https://www.newyorker.com/magazine/2016/10/10/sam-altmans-manifest-destiny)‚Äã

\[3\] [Article in Fortune magazine ](https://fortune.com/2023/01/11/structure-openai-investment-microsoft/?verification_code=DOVCVS8LIFQZOB&_ptid=%7Bkpdx%7DAAAA13NXUgHygQoKY2ZRajJmTTN6ahIQbGQ2NWZsMnMyd3loeGtvehoMRVhGQlkxN1QzMFZDIiUxODA3cnJvMGMwLTAwMDAzMWVsMzhrZzIxc2M4YjB0bmZ0Zmc0KhhzaG93T2ZmZXJXRDFSRzY0WjdXRTkxMDkwAToMT1RVVzUzRkE5UlA2Qg1PVFZLVlpGUkVaTVlNUhJ2LYIA8DIzZW55eGJhajZsWiYyYTAxOmMyMzo2NDE4OjkxMDA6NjBiYjo1NWYyOmUyMTU6NjMyZmIDZG1jaOPAtZ4GcBl4DA)‚Äã

\[4\] [https://arxiv.org/abs/2104.04473](https://arxiv.org/abs/2104.04473) Megatron NLG

\[5\] [https://www.crunchbase.com/organization/openai/company\_financials](https://www.crunchbase.com/organization/openai/company_financials)‚Äã

\[6\] Elon Musk donation [https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research](https://www.inverse.com/article/52701-openai-documents-elon-musk-donation-a-i-research)‚Äã

\[7\] [https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/](https://a16z.com/2020/02/16/the-new-business-of-ai-and-how-its-different-from-traditional-software-2/)",118,16,LesleyFair,2023-01-27 10:45:48,https://www.reddit.com/r/deeplearning/comments/10mhyek/what_people_are_missing_about_microsofts_10b/,0,deeplearning
iblhzl,Personal GPT-3 project üöÄ: Guess the movie! You can't recall the name of that movie you watched? You know what the movie's about but you just can't remember its name? I used the GPT-3 model to solve this problem! Just feed it a small description of the movie/tv show and it will do the rest.,,115,29,CallmeMehdi25,2020-08-17 19:53:20,https://i.redd.it/z12t847vamh51.gif,0,deeplearning
8eiqz4,When #DeepLearning learns #basketball üèÄ,,116,8,None,2018-04-24 07:55:05,https://v.redd.it/zesnsoalbtt01,0,deeplearning
nt2hiy,Generating Anime Images using PyTorch implementation of DCGAN,,113,9,rohitkuk,2021-06-05 18:47:10,https://i.redd.it/b0qal9b6th371.gif,0,deeplearning
10p2sks,Stable Diffusion + Dream Fusion + Text-to- Motion. This quick animation has been made with the AI-Game Dev platform I'm building. Next step is to integrate GPT3 for generating cool scripts. Seeking alpha testers.,,116,16,SpeaKrLipSync,2023-01-30 13:51:42,https://v.redd.it/9uwcsv13r6fa1,0,deeplearning
zowgqn,Neural Rendering: Reconstruct your city in 3D using only your mobile phone and CitySynth!,,111,11,ydrive-ai,2022-12-18 11:22:41,https://v.redd.it/cwklnsbd5n6a1,0,deeplearning
148lz3o,The battle of the deep learning frameworks - Number of new GitHub stars in the last 100 days.,,113,36,oscarleo0,2023-06-13 18:21:45,https://i.redd.it/xm7c3ne1vt5b1.gif,0,deeplearning
iusv67,"[R] After 15 Long Years, a NumPy Paper Finally Appears!","Since[ NumPy](https://numpy.org/) was introduced to the world 15 years ago, the primary array programming library has grown into the **fundamental package for scientific computing with Python.** NumPy serves as an efficient multi-dimensional container of generic data and plays a leading role in scientific computing. It is an essential component in research analysis pipelines across fields as diverse as physics, chemistry, astronomy, geoscience, biology, psychology, materials science, engineering, finance and economics. NumPy is open-sourced and has myriad contributors.

But one thing has always been missing. A thorough review paper that is fully representative of the team behind Numpy‚Äôs genesis has never been published.

The missing chapter in the NumPy story was written yesterday ‚Äî with the appearance of the paper *Array Programming with NumPy* in leading scientific journal *Nature.*

Here is a quick read: [After 15 Long Years, a NumPy Paper Finally Appears!](https://syncedreview.com/2020/09/17/after-15-long-years-a-numpy-paper-finally-appears/)

The paper *Array Programming with NumPy* is on [*Nature*](https://www.nature.com/articles/s41586-020-2649-2).",112,0,Yuqing7,2020-09-17 21:29:38,https://www.reddit.com/r/deeplearning/comments/iusv67/r_after_15_long_years_a_numpy_paper_finally/,0,deeplearning
fhy730,Largest Covid-19 Korea Dataset with unparalleled patient details,"&#x200B;

https://preview.redd.it/8saz4dltxfm41.png?width=966&format=png&auto=webp&s=477cb7ffb95820d7467830b82f10bafe46c6ea79

# Check out our [GitHub](https://github.com/ThisIsIsaac/COVID-19_Korea_Dataset) and please leave a star!

## 1. COVID-19 Korea Dataset with Patient Routes

**Dataset components**:

1. Largest Covid-19 Korean Dataset
2. 22 major epidemics
3. 16 vaccines
4. 7 chronic diseases
5. 5 major cancers
6. Annual health screening results
7. Medical facilities
8. Population
9. Depression & mental health
10. Life satisfaction

## 2. Multi-variate & Time-scrollable Data Visualizer

**Key features**:

1. Displays infected patient route and regional patient count
2. Visualizes changes in the number of patients and route with time
3. Displays non-COVID-19 data as heatmap

&#x200B;

&#x200B;

https://preview.redd.it/ljciaamyxfm41.png?width=1826&format=png&auto=webp&s=b81111c1d48fff83931a6484f1f5c5aa9daccbf5

&#x200B;

&#x200B;

## Upcoming

* \[ \] Official partnership with the Korean CDC (in progress)
* \[ \] More patient routes from non-Seoul provinces
* \[ \] Daily-updates on COVID-19
* \[ \] Release visualizer
* \[ \] More features for the visualizer
* \[ \] More non-COVID-19 data",114,15,AgnosticIsaac,2020-03-13 11:31:21,https://www.reddit.com/r/deeplearning/comments/fhy730/largest_covid19_korea_dataset_with_unparalleled/,0,deeplearning
qt36ls,These plants do not exist - Created using StyleGAN 2,,108,1,vadhavaniyafaijan,2021-11-13 15:10:19,https://v.redd.it/jxy5m9bvcsw71,0,deeplearning
i3hs9f,Introduction to Anomaly Detection with a Convolutional Auto-Encoder on Time Series transformed into Images,,108,11,AstroThese,2020-08-04 11:40:41,https://i.redd.it/cd5vic023ze51.gif,0,deeplearning
pcuvh9,Which ones have you built?,,108,12,tumbleweedinthewind,2021-08-27 20:00:38,https://i.redd.it/sntbt4w5iyj71.jpg,0,deeplearning
nhtwq4,Proud of this air cooled/3990x/2XA6000 Deep Learning build for my client! Let me know what you think!,,111,17,GPUaccelerated,2021-05-21 14:31:24,https://v.redd.it/kzjzy7c2ih071,0,deeplearning
lx0i49,Hey everyone! This is a project of mine that I have been working on. It is a video captioning project. This encoder decoder architecture is used to generate captions describing scene of a video at a particular event. Here is a demo of it working in real time. Check out my Github link below. Thanks!,,106,18,Shreya001,2021-03-03 18:16:17,https://v.redd.it/kc5ov9t3uuk61,0,deeplearning
b8fjdw,"4x RTX 2080 Ti | Deep learning workstation, overheating issue fixed !!!!",,106,20,gimel1213,2019-04-02 06:36:39,https://i.redd.it/6o9t6zgdqsp21.jpg,0,deeplearning
gvcwyg,Deep learning-based Gaze detection model to control the mouse pointer of your computer,,103,15,nullbyte91,2020-06-02 18:34:50,https://i.redd.it/dx475avojj251.gif,0,deeplearning
gw10x7,Deep Generation of Face Images from Sketches,,103,8,cmillionaire9,2020-06-03 19:42:19,https://youtu.be/hKXVvF_JDj0,0,deeplearning
wk4wo1,NAFSSR: Stereo Image Super-Resolution & Enhancement Using NAFNet,,100,8,imapurplemango,2022-08-09 14:34:48,https://i.redd.it/a3zphsg68pg91.gif,0,deeplearning
umhiux,BlobGAN enables object manipulation in an image,,99,5,imapurplemango,2022-05-10 12:26:29,https://v.redd.it/ss15bd6g6ny81,0,deeplearning
fq7q46,So about that stimulus check...,,100,7,sethcoast,2020-03-27 22:47:35,https://i.redd.it/nkpinxarnap41.jpg,0,deeplearning
jvcjp6,SFF by NVIDIA is a robust driving policy that analyzes and predicts the vehicle‚Äôs environment.,,100,0,Parth_varma,2020-11-16 18:53:23,https://v.redd.it/k85z6fye94z51,0,deeplearning
1ao61cj,How do AI researchers know create novel architectures? What do they know which I don't?,"For example take transformer architecture or attention mechanism. How did they know that by combining self attention with layer normalisation, positional encoding we can have models that will outperform lstm, CNNs? 

I am asking this from the perspective of mathematics. Currently I feel like I can never come up with something new, and there is something missing which ai researchers know which I don't. 

So what do I need to know that will allow me to solve problems in new ways. Otherwise I see myself as someone who can only apply what these novel architectures to solve problems. 

Thanks. I don't know if my question makes sense, but I do want to know the difference between me and them.",97,31,mono1110,2024-02-11 11:35:57,https://www.reddit.com/r/deeplearning/comments/1ao61cj/how_do_ai_researchers_know_create_novel/,0,deeplearning
zx73na,Wolf in Inkpunk style using SD,,99,23,oridnary_artist,2022-12-28 11:16:54,https://v.redd.it/46kxw3rfhm8a1,0,deeplearning
q79cs5,Deep Learning and API Explained,,98,7,vadhavaniyafaijan,2021-10-13 11:44:36,https://i.redd.it/kd2r1q27h5t71.jpg,0,deeplearning
ey5635,"Opensource GUI tool (in development) for computer vision and deep learning - detection, classification, segmentation, etc. Github: https://github.com/Tessellate-Imaging/Monk_Gui",,99,4,abhishek4273,2020-02-03 10:25:45,https://v.redd.it/n6y30syrqoe41,0,deeplearning
dhvdqu,Career Advice in ML and how to read research papers - Andrew Ng's Notes,"Here I have made notes of the **Deep Learning CS230** Lecture given by ***Andrew Ng*** on how to navigate a career in ML/DL and how to read research papers.

[https://deeps.site/blog/2019/10/14/reading-research-papers-career-advice/](https://deeps.site/blog/2019/10/14/reading-research-papers-career-advice/)

The **one hour lecture** has been **summarised into concise 5 minutes** read to ***save out on your time*** with  
visualisations to enrich the delivered content.  


Hope it helps you to build on top of Andrew's insights and save time.",100,10,deep_ak,2019-10-14 19:11:58,https://www.reddit.com/r/deeplearning/comments/dhvdqu/career_advice_in_ml_and_how_to_read_research/,0,deeplearning
kyh72j,"Using StyleGANs to recreate faces in historical paintings üñº You can clearly observe the depth of clarity, accuracy and precision in the outputs on the right. Truly amazing! More like these can be found on Nathan Shipley‚Äôs IG Account: https://lnkd.in/d3BYmUM",,97,22,Mskhan_1,2021-01-16 11:15:10,https://i.redd.it/g6g1gky4hob61.jpg,0,deeplearning
cub5nd,Nvidia made an awesome new imaging tool. http://nvidia-research-mingyuliu.com/gaugan,,98,1,susmit410,2019-08-23 08:50:01,https://imgur.com/mHfc8X6,0,deeplearning
rr2wme,I wrote a program with OpenAI's Codex that fixes errors,,99,6,tomd_96,2021-12-29 08:03:22,https://v.redd.it/jupdtry6vf881,0,deeplearning
jpoyxf,[P] Open-sourcing my PyTorch implementation of the original transformer paper (Attention Is All You Need)!,,96,15,gordicaleksa,2020-11-07 10:58:50,https://github.com/gordicaleksa/pytorch-original-transformer,0,deeplearning
hg7591,DeepMind's recommended list of ML resources,,98,5,VaeVictis27,2020-06-26 13:01:24,https://twitter.com/DeepMind/status/1276466352740610050?s=19,0,deeplearning
srfafu,The robot follows a specific person under severe indoor illumination changes.,,96,14,redhwanALgabri,2022-02-13 09:56:07,https://v.redd.it/1fxze065pkh81,0,deeplearning
mkr0nh,BikiniGAN!!,,96,13,willowill5,2021-04-05 18:12:32,https://v.redd.it/arowv28e5er61,0,deeplearning
bu5buv,I wanted to know what will happen to a generative network if I switch off its neurons one by one,,95,9,ale152,2019-05-28 20:48:05,https://vimeo.com/337909277,0,deeplearning
12hhap1,I am very happy to share our recent CVPR2023 work on instant volumetric head avatars (INSTA) which allows you to reconstruct an animatable NeRF of a human head within a few minutes.,,95,4,wojti_zielon,2023-04-10 12:26:52,https://v.redd.it/epwwlbruv1ta1,0,deeplearning
i437pt,image-GPT from OpenAI can generate the pixels of half of a picture from nothing using a NLP model,,93,6,OnlyProggingForFun,2020-08-05 10:58:06,https://www.youtube.com/watch?v=FwXQ568_io0,0,deeplearning
donip0,Introduction to Anomaly Detection with Auto-Encoder on time series,,94,6,AstroThese,2019-10-29 09:42:07,https://i.redd.it/iz8luu1uagv31.gif,0,deeplearning
lbldig,Valid point,,96,16,montecoelhos,2021-02-03 11:13:54,https://i.redd.it/5aprxffbx8f61.jpg,0,deeplearning
be5nro,Learning to paint: A Painting AI,,94,5,hzwer,2019-04-17 09:16:08,https://i.redd.it/szoiawbakss21.gif,0,deeplearning
dud1h9,AI has learned how to effectively separate audio recordings into music and vocals,,91,7,cmillionaire9,2019-11-10 15:47:35,https://youtu.be/7BtBA-ZC5XI,0,deeplearning
13v5f1r,One Click Deep Fakes using Roop -Tutorial,,94,30,oridnary_artist,2023-05-29 20:21:29,https://v.redd.it/vnxmwsw8xt2b1,0,deeplearning
mutjhg,Neural net trained to predict what other half of an image a face should look like given the first half as input either split vertically or horizontally (and it‚Äôs fairly accurate),,88,14,Extra-most-best,2021-04-20 15:57:37,https://www.reddit.com/gallery/mutjhg,0,deeplearning
llivy3,What is the best style transfer for photo and video for you? There is an example of what I did with JC Johnson code on github,,90,10,metas1,2021-02-17 01:32:49,https://v.redd.it/0h5izlc1yxh61,0,deeplearning
jj8wh5,[R] AI Halloween Avatars! StyleGAN2 Generator Reveals Your Inner Zombie,,89,10,Yuqing7,2020-10-27 20:14:11,https://i.redd.it/v8th9u8b3pv51.png,0,deeplearning
e7y0m5,Must start thanking the food outlets nearby.,,86,1,None,2019-12-08 19:19:53,https://i.redd.it/wwq9wwkfmg341.jpg,0,deeplearning
cy6ihy,This package sends your deep learning training metrics to your slack channel/user after ever specified epoch.,,90,3,clean_pegasus,2019-09-01 06:10:12,https://i.redd.it/zz4o90f7cxj31.jpg,0,deeplearning
v61isf,Deep Learning Classifier for Sex Positions,"Hello! I build some sex position classifiers using state-of-the-art techniques in deep learning! The best results were achieved by combining three input streams: RGB, Skeleton, and Audio.

Basically, human action recognition is applied to the adult content domain. It presents some technical difficulties, especially due to the enormous variation in camera position (the challenge is to classify actions based on a single video).

Check it out on Github: [https://github.com/rlleshi/phar](https://github.com/rlleshi/phar)

Possible use-cases include:

1. Improving the recommender system
2. Automatic tag generator
3. Automatic timestamp generator (when does an action start and finish)
4. Filtering video content based on actions (positions)",89,28,rlesii,2022-06-06 11:40:52,https://www.reddit.com/r/deeplearning/comments/v61isf/deep_learning_classifier_for_sex_positions/,0,deeplearning
18ol3i3,Overwhelmed by expectations to innovate,"I interned at a FAANG company and have now joined full-time as an ML Scientist.

During my internship, I discovered my strength in navigating from point A to B. When my manager assigns experiments, even with zero prior experience, I independently figure things out and accomplish tasks effectively. When given a clear objective, I consistently deliver.

However, as a full-time employee, the expectations have risen. I'm now required to innovate and design my experiments, and I've been struggling to generate novel ideas.

Have you ever faced a similar situation? Could you offer guidance on how to tackle this challenge? Please share pointers from where I can get some inspiration to create new model architectures, loss functions and different techniques. Thanks a ton!",89,18,Mundane-Army-5940,2023-12-22 18:08:52,https://www.reddit.com/r/deeplearning/comments/18ol3i3/overwhelmed_by_expectations_to_innovate/,0,deeplearning
mmn709,How Graph Neural Networks (GNN) work: introduction to graph convolutions from scratch,"Graph neural  networks are a super hot topic but kind of niche.

I  created  this detailed blog-post to understand them with absolutely  zero background on graph theory, no crazy  math, no buzzwords, and  arbitrary concepts.

Just basic machine-deep learning and you will build your first graph neural network from scratch!

Link: [https://theaisummer.com/graph-convolutional-networks/](https://theaisummer.com/graph-convolutional-networks/)

Let me know what you think!

Cheers,",86,5,black0017,2021-04-08 08:22:09,https://www.reddit.com/r/deeplearning/comments/mmn709/how_graph_neural_networks_gnn_work_introduction/,0,deeplearning
m0m4to,My project to debug and visualize Python code by using a combination of conventional static analysis tools and the attention based AI model. - Please ask me any questions!,,88,9,bobcodes247365,2021-03-08 18:19:58,https://i.redd.it/p80zewd9jul61.png,0,deeplearning
139yjkh,Animating Dogs with SD& Controlnet,,87,8,oridnary_artist,2023-05-06 18:48:32,https://v.redd.it/3u1jabopb9ya1,0,deeplearning
m86kbg,Lunar Lander using Deep Q-Learning,,86,11,mugeshk_97,2021-03-19 01:54:46,https://v.redd.it/hd7c3g9k5wn61,0,deeplearning
m748yb,My side project: Cloud GPUs for 1/3 the cost of AWS/GCP,"\[cross posting from /r/MachineLearning\]

I‚Äôve just finished building a little side project of mine - [https://gpu.land/](https://gpu.land/).

**What is it?** Cheap GPU instances in the cloud.

**Why is it awesome?**

* It‚Äôs dirt-cheap. You get a Tesla V100 for $0.99/hr, which is 1/3 the cost of AWS/GCP/Azure/\[insert big cloud name\].
* It‚Äôs dead simple. It takes 2mins from registration to a launched instance. Instances come pre-installed with everything you need for Deep Learning, including a 1-click Jupyter server.
* It sports a retro, MS-DOS-like look. Because why not:)

I‚Äôm a self-taught ML engineer. I built this because when I was starting my ML journey I was totally lost and frustrated by AWS. Hope this saves some of you some nerve cells (and some pennies)!

The most common question I get is - how is this so cheap? The answer is because AWS/GCP are charging you a huge markup and I‚Äôm not. In fact I‚Äôm charging just enough to break even, and built this project really to give back to community (and to learn some of the tech in the process). 

AMA!",85,11,xepo3abp,2021-03-17 16:26:27,https://www.reddit.com/r/deeplearning/comments/m748yb/my_side_project_cloud_gpus_for_13_the_cost_of/,0,deeplearning
io5b0a,AI Portrait : What kind of architecture to use to convert an image to a portrait using Deep Learning,,85,13,rayanaay,2020-09-07 10:48:46,https://i.redd.it/izxzltdzgpl51.jpg,0,deeplearning
cayqlf,Astounding deepfake of Jim Carrey in the Shining.,,86,18,OwlKneeArn,2019-07-09 09:47:52,https://www.youtube.com/watch?v=HG_NZpkttXE,0,deeplearning
agkbb1,Writing tweets like Donald Trump,"I've trained RNN model to write tweets like @realDonaldTrump

I use pre-trained 3-layer LSTM and by [transfer learning](https://nips2018creativity.github.io/doc/Transfer%20Learning%20for%20Style-Specific%20Text%20Generation.pdf) fine-tune this on 2k Trump's tweets.

Here are some examples of generated tweets:

* Working hard for America!
* These are the years of the most Angry and dangerous immigration reform.
* The Senate in November is a total mess . They are weak on crime and border security.
* Great to be there to watch for the great American people!
* There is no reason to spend a year without a wall. I want to protect the border and trade, as many as possible. Fix it!

You can get more examples on [https://twitter.com/realTrumpIdeas](https://twitter.com/realTrumpIdeas)

If anyone is interested I can share the source code after some cleaning/refactoring

\------------------

**EDIT**: thank you all for your interest! Source code of TweetGenerator stored [here](https://github.com/granilace/TweetGenerator)",84,30,yet_another_seeker,2019-01-16 11:39:12,https://www.reddit.com/r/deeplearning/comments/agkbb1/writing_tweets_like_donald_trump/,0,deeplearning
wwhru9,I made Telegram Bot where you can make Elon say anything you want @MuskFakeBot (only for fun) Will be glad to see your videos ü§£,,87,8,Excellent_Fly9717,2022-08-24 12:04:14,https://v.redd.it/ve4nqpu4jnj91,0,deeplearning
oqj0pa,Because everything works on synthetic!,,86,2,lifeinsrndpt,2021-07-24 04:32:21,https://i.redd.it/gauhvxuj93d71.jpg,0,deeplearning
labtv8,I created a GAN to generate Minecraft skins - http://perceptrons.tk:8501/,,84,19,Nicodico,2021-02-01 19:32:55,https://i.redd.it/2lpfomqi2xe61.png,0,deeplearning
fqot3h,Applied style transfer and composited.,,89,11,redhoot_,2020-03-28 17:47:40,https://i.redd.it/ce3du3y5bgp41.jpg,0,deeplearning
12c43uu,Vicuna : an open source chatbot impresses GPT-4 with 90% of the quality of ChatGPT,"Vicuna : ChatGPT Alternative, Open-Source, High Quality and Low Cost 

&#x200B;

[ Relative Response Quality Assessed by GPT-4 ](https://preview.redd.it/oaj1s995zyra1.png?width=599&format=png&auto=webp&s=1fb01b017b3b8b4f9149d4b80f40c48d3a072b91)

Vicuna-13B has demonstrated competitive performance against other open-source models, such as Stanford Alpaca, by fine-tuning a LLaMA base model on user-shared conversations collected from ShareGPT.

Evaluation using GPT-4 as a judge shows that Vicuna-13B achieves more than 90% of the quality of OpenAI ChatGPT and Google Bard AI, while outperforming other models such as Meta LLaMA (Large Language Model Meta AI) and Stanford Alpaca in more than 90% of cases.

The cost of training Vicuna-13B is approximately $300.

The training and serving code, along with an online demo, are publicly available for non-commercial use.

&#x200B;

More Information : [https://gpt4chatgpt.tistory.com/entry/Vicuna-an-open-source-chatbot-impresses-GPT-4-with-90-of-the-quality-of-ChatGPT](https://gpt4chatgpt.tistory.com/entry/Vicuna-an-open-source-chatbot-impresses-GPT-4-with-90-of-the-quality-of-ChatGPT)

Discord Server : [https://discord.gg/h6kCZb72G7](https://discord.gg/h6kCZb72G7)

Twitter : [https://twitter.com/lmsysorg](https://twitter.com/lmsysorg)",83,19,Time_Key8052,2023-04-05 01:36:40,https://www.reddit.com/r/deeplearning/comments/12c43uu/vicuna_an_open_source_chatbot_impresses_gpt4_with/,0,deeplearning
y6esa9,Generation of 3D shapes from point clouds using LION,,85,2,imapurplemango,2022-10-17 15:57:58,https://v.redd.it/p5x5s2l12eu91,0,deeplearning
p2fns4,Tutorial: Prune and quantize YOLOv5 for 10x better performance and 12x smaller size,,85,9,markurtz,2021-08-11 15:45:00,https://v.redd.it/et5uxa2n1rg71,0,deeplearning
fp90g7,I Used Deep Learning To Detect Naruto (Anime Series) Hand Signs,,87,9,oFlamingo,2020-03-26 10:08:11,https://youtu.be/mCcla6k3lXA,0,deeplearning
bxx1wg,[R] Stanford AI system can change what people said.,,86,7,NicoleK1993,2019-06-07 17:04:37,https://www.youtube.com/watch?v=0ybLCfVeFL4&t=22s,0,deeplearning
vc7ao9,CNN- A Quick Revision,,82,1,eforebrahim,2022-06-14 16:23:48,https://i.redd.it/8dfcemrp4m591.jpg,0,deeplearning
t9hhvw,These Nebulae Do Not Exist,,84,9,coffee869,2022-03-08 14:03:57,https://www.reddit.com/gallery/t9hhvw,0,deeplearning
sewpbg,ML vs. ML,,84,1,golddiggerhousewife,2022-01-28 18:03:37,https://www.reddit.com/gallery/sewpbg,0,deeplearning
npsknw,I wrote a small script to remove that annoying sound in Andrew NG Courses,"You can use it with Tampermonkey or Greasemonkey; 

[https://github.com/casab/andrew-ng-deesser](https://github.com/casab/andrew-ng-deesser)",82,5,homunduruk,2021-06-01 12:13:25,https://www.reddit.com/r/deeplearning/comments/npsknw/i_wrote_a_small_script_to_remove_that_annoying/,0,deeplearning
kfvz78,Just used GANs to generate fake pokemon,,84,19,GeeseChen,2020-12-18 23:07:00,https://i.redd.it/t61nxh3h11661.png,0,deeplearning
iz09q0,Python and FastAI to Qualify at FallGuys,,83,1,Dwigt-Snooot,2020-09-24 16:17:38,https://youtu.be/GS_0ZKzrvk0,0,deeplearning
drjcmq,The test set accuracy is 99%,,87,10,cmillionaire9,2019-11-04 15:44:16,https://youtu.be/gu3j2qsMvLE,0,deeplearning
13vp53c,"I made a package, TorchLens, that can visualize the structure of any PyTorch model and extract any intermediate activations you want in one line of code.",,81,11,therealjmt91,2023-05-30 12:37:30,https://i.redd.it/79rn6p3x803b1.jpg,0,deeplearning
13q0k34,Drag Your GAN,,85,4,imapurplemango,2023-05-23 20:58:14,https://v.redd.it/vijtbi6can1b1,0,deeplearning
xcicfr,Talking Face Generation using StableFace,,84,5,imapurplemango,2022-09-12 17:09:25,https://v.redd.it/gt38ut0zlgn91,0,deeplearning
hol97n,Full Stack Deep Learning: now packaged into a free online course,,83,9,tanmayJ527,2020-07-10 08:26:11,https://course.fullstackdeeplearning.com/,0,deeplearning
fo8l9f,Microsoft Research Uses Transfer Learning to Train Real-World Autonomous Drones,,87,7,cmillionaire9,2020-03-24 17:00:49,https://youtu.be/HoihL40wcf8,0,deeplearning
bhb5hr,Andrej Karpathy's recipe for training DNNs,[https://karpathy.github.io/2019/04/25/recipe/](https://karpathy.github.io/2019/04/25/recipe/),83,1,intvar,2019-04-25 17:09:38,https://www.reddit.com/r/deeplearning/comments/bhb5hr/andrej_karpathys_recipe_for_training_dnns/,0,deeplearning
yk4xnl,Vectory: a tool for tracking and comparing embedding spaces,,82,6,Leopiney,2022-11-02 13:12:58,https://i.redd.it/6eqtpcg1fjx91.gif,0,deeplearning
ncdyqr,"[R] Google Replaces BERT Self-Attention with Fourier Transform: 92% Accuracy, 7 Times Faster on GPUs","A research team from Google shows that replacing transformers‚Äô self-attention sublayers with Fourier Transform achieves 92 percent of BERT accuracy on the GLUE benchmark with training times seven times faster on GPUs and twice as fast on TPUs.

Here is a quick read: [Google Replaces BERT Self-Attention with Fourier Transform: 92% Accuracy, 7 Times Faster on GPUs.](https://syncedreview.com/2021/05/14/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-19/)

The paper *FNet: Mixing Tokens with Fourier Transforms* is on [arXiv](https://arxiv.org/abs/2105.03824).",81,12,Yuqing7,2021-05-14 17:23:21,https://www.reddit.com/r/deeplearning/comments/ncdyqr/r_google_replaces_bert_selfattention_with_fourier/,0,deeplearning
1325a0j,The Little Book of Deep Learning is a 140 page (phone-formatted!) technical introduction of the necessary background for denoising diffusion and GPT models. BY-NC-SA.,,79,6,FrancoisFleuret,2023-04-28 18:10:08,https://fleuret.org/public/lbdl.pdf,0,deeplearning
kmoq57,NEW Boston Dynamics Clip,,82,15,glassAlloy,2020-12-29 22:36:53,https://www.youtube.com/watch?v=fn3KWM1kuAw,0,deeplearning
dztzvu,Deep Learning with PyTorch book is now available for free,,83,10,ConfidentMushroom,2019-11-22 01:55:47,https://pytorch.org/deep-learning-with-pytorch,0,deeplearning
nr91wq,I'm looking for a tool that let's you visualize the models architecture like this. Any idea what it is called?,,80,26,pitrucha,2021-06-03 09:11:00,https://i.redd.it/c8puf6tlo0371.png,0,deeplearning
bymmhe,How I made top 0.3% on Kaggle,,78,3,0_marauders_0,2019-06-09 17:25:18,https://www.kaggle.com/lavanyashukla01/how-i-made-top-0-3-on-kaggle,0,deeplearning
viwgfx,How to make a deep learning engineer happy in one command? `nvidia-smi`:,,79,13,gvij,2022-06-23 13:02:50,https://www.qblocks.cloud,0,deeplearning
xgik2i,Made an NLP model that predicts subreddit based on the title of a post (link in comments),,79,6,None,2022-09-17 10:05:25,https://www.reddit.com/gallery/xgik2i,0,deeplearning
wxsg7n,Been playing with Stable Diffusion. Here‚Äôs my masterpiece,,76,7,WhizzleTeabags,2022-08-25 23:06:27,https://www.reddit.com/gallery/wxsg7n,0,deeplearning
qtrgh4,Chill out for a bit and share pic of your coding buddy (supervisor). ‚úåÔ∏è,,78,30,None,2021-11-14 14:56:36,https://i.redd.it/g859vwfxrkz71.jpg,0,deeplearning
bncph7,"Free: Hands-on Machine Learning with Scikit-Learn, Keras, and TensorFlow",,79,18,aiforworld2,2019-05-11 14:35:02,https://get.oreilly.com/ind_hands-on-machine-learning?fbclid=IwAR3JaiApszG-JYpjubJgelOxSZ9kfG1SuC1nJIz5zbxI1o7FM-KcmxY5bUA,0,deeplearning
mqovsq,A Complete Roadmap for Beginners in Machine Learning in 2021+ many valuable resources for any data scientist / AI workers or enthusiasts + how to stay up-to-date with news," This guide is intended for anyone having zero or a small background in programming, maths, and machine learning. There is no specific order to follow, but a classic path would be from top to bottom. If you don't like reading books, skip it, if you don't want to follow an online course, you can skip it as well. There is not a single way to become a machine learning expert and with motivation, you can absolutely achieve it. 

**The video**: https://youtu.be/RirEw-uaS\_8?list=PLO4GrDnQanVfb6Ins6up1xScJHl8YuwPQ

**The complete article**: [https://pub.towardsai.net/start-machine-learning-in-2020-become-an-expert-from-nothing-for-free-f31587630cf7](https://pub.towardsai.net/start-machine-learning-in-2020-become-an-expert-from-nothing-for-free-f31587630cf7)

**All the links on GitHub**: [https://github.com/louisfb01/start-machine-learning-in-2020](https://github.com/louisfb01/start-machine-learning-in-2020)

Artificial is a fantastic field, but it goes extremely fast. Don't miss out on the most important and exciting news by joining great communities, people, newsletters, and more you can all find in this guide!",77,2,OnlyProggingForFun,2021-04-14 11:49:35,https://www.reddit.com/r/deeplearning/comments/mqovsq/a_complete_roadmap_for_beginners_in_machine/,0,deeplearning
hsyz7a,So we developed a mask detection application and cookie wasn't wearing a mask. It works!,,78,11,unspiritual_rumi,2020-07-17 16:39:05,https://i.redd.it/jgmt5vd34gb51.jpg,0,deeplearning
c6nw46,Part 2: Deep Learning from the Foundations(2019) by Fast.ai is launched!,,75,8,harrshjain,2019-06-28 18:39:43,https://course.fast.ai/part2.html,0,deeplearning
9kihrp,Mask R-CNN using OpenCV (C++/Python),,79,3,spmallick,2018-10-01 17:38:36,https://v.redd.it/jtzck3wz0mp11,0,deeplearning
rklhsk,Supervised Learning and Reinforcement Learning Explained,,76,1,vadhavaniyafaijan,2021-12-20 11:44:52,https://v.redd.it/g68taxirmi681,0,deeplearning
q09xbm,Types of box and whisker plot,,74,5,Mammoth_Grade_6875,2021-10-03 03:38:16,https://i.redd.it/zobyt20fo5r71.jpg,0,deeplearning
nurkp4,Character animation layering using AI is here! [https://youtu.be/SkJNxLYNwN0],,74,4,-BlackSquirrel-,2021-06-08 00:12:31,https://v.redd.it/z6jxfr71px371,0,deeplearning
mheqz6,Made website with best resources I could find on GANs and Transformers,"I spent \~50 hours looking for the best resources on various GANs and Transformer models and organized them into a website [backprop.org](https://backprop.org).

Check it out! If people find this useful I'll add more pages on more topics. 

Also, if you know any great resources that I missed send it my way!",76,4,backpropsite,2021-03-31 20:18:33,https://www.reddit.com/r/deeplearning/comments/mheqz6/made_website_with_best_resources_i_could_find_on/,0,deeplearning
i9m8s5,Transfer clothes between photos using AI,,75,8,Independent-Square32,2020-08-14 13:46:10,https://youtu.be/-BVyPIZxxNA,0,deeplearning
hmmcm0,Pytorch Book (free!),"[https://pytorch.org/deep-learning-with-pytorch](https://pytorch.org/deep-learning-with-pytorch)   Enjoy! 

(I hope post like this is permitted in this forum)",74,7,Lumpy-Carob,2020-07-07 02:54:00,https://www.reddit.com/r/deeplearning/comments/hmmcm0/pytorch_book_free/,0,deeplearning
18mxenq,[Original Creation] A small meme-post about ReLu activation,,75,10,Partinius,2023-12-20 15:36:28,https://i.redd.it/u0z553bsyg7c1.png,0,deeplearning
12u2w8v,"AI speech/language conversion is making progress, one step closer to a universal translator?",,75,10,Lewenhart87,2023-04-21 14:07:54,https://v.redd.it/4tw0oj5ys8va1,0,deeplearning
wg8lzu,The Best and Easy to Blend two images in Canva,"it's very simple canva tutorial , and no need for canva pro

&#x200B;

https://preview.redd.it/z87l73g5qqf91.png?width=1280&format=png&auto=webp&s=2666c43a0a32cb6117f34ad61d989ea4bda1b8b4

&#x200B;

here is the tutorial [link](https://youtu.be/gOej6z40L_w)",75,2,chatouaki,2022-08-04 18:33:35,https://www.reddit.com/r/deeplearning/comments/wg8lzu/the_best_and_easy_to_blend_two_images_in_canva/,0,deeplearning
w60hy9,"We have developed CVEDIA-RT as a free tool to help companies and hobbyist interactively play with, and deploy their AI models on the edge or cloud. We're in early beta and are looking for feedback.",,74,4,ajcvedia,2022-07-23 10:06:42,https://v.redd.it/ngpe5unxkad91,0,deeplearning
lsn57t,"Nice video from my high schooler mentee who completed his AI project to play CS:Go in real time. From automatic data annotation to cloud training, neural net development and game integration. Proud mentor here :)",,75,2,abstractmoor,2021-02-26 02:05:58,https://www.youtube.com/watch?v=3WLbxi9MSpA,0,deeplearning
igwsel,Elon Musk has said he will demonstrate a functional brain-computer interface this week during a live presentation from his mysterious Neuralink startup.,,76,15,Shradha_Singh,2020-08-26 11:01:29,https://www.independent.co.uk/life-style/gadgets-and-tech/news/elon-musk-neuralink-brain-computer-chip-ai-event-when-a9688966.html,0,deeplearning
hytai8,Collection of best Computer Vision Colab Notebooks,,77,1,imapurplemango,2020-07-27 14:29:56,https://www.qblocks.cloud/creators/computer-vision-google-colab-notebooks,0,deeplearning
eg9d52,MIT lecture series on deep learning in January 2020,,75,19,None,2019-12-27 10:00:39,https://deeplearning.mit.edu/,0,deeplearning
dg434w,"Facebook Debuts PyTorch 1.3 With PyTorch Mobile, Quantization, TPU Support and More",,73,7,Yuqing7,2019-10-10 20:33:03,https://medium.com/syncedreview/facebook-debuts-pytorch-1-3-with-pytorch-mobile-quantization-tpu-support-and-more-9b4fc35e5e38,0,deeplearning
108fzfw,Nerf Technology with Stable Diffusion,,74,9,oridnary_artist,2023-01-10 17:48:16,https://v.redd.it/gycltjc779ba1,0,deeplearning
pyzujv,Understand sensitivity and specificity graphically @twitter (Ana Vldv),,72,0,Mammoth_Grade_6875,2021-10-01 03:44:54,https://i.redd.it/3ber6evtfrq71.jpg,0,deeplearning
g63w45,Background Matting: The World is Your Green Screen,,75,6,cmillionaire9,2020-04-22 16:07:41,https://youtu.be/JE-7OcNrPao,0,deeplearning
f0c4j9,Facebook released Pytorch3D. Working with 3D datasets(object with meshes),,71,4,cmillionaire9,2020-02-07 15:38:38,https://youtu.be/lG3s_uHJQYY,0,deeplearning
dpshra,SinGAN Explained! (ICCV '19 Best Paper),[https://youtu.be/-f8sz8AExdc](https://youtu.be/-f8sz8AExdc),72,6,HenryAILabs,2019-10-31 19:24:40,https://www.reddit.com/r/deeplearning/comments/dpshra/singan_explained_iccv_19_best_paper/,0,deeplearning
bx5c2r,PyTorch for Beginners: Semantic Segmentation using torchvision,,76,2,spmallick,2019-06-05 17:32:39,https://i.redd.it/wn38tnhbpk231.gif,0,deeplearning
199rmhh,Why (almost) nobody is using Retnet?,"In July, Microsoft presented the Retnet model that claims to be better than the transformers architecture:

  
¬∑ RetNet has **BETTER** language modeling performance

¬∑ RetNet achieves that with **3.4x** lower memory consumption

¬∑ ‚Ä¶.**8.4x** higher throughput

¬∑ ‚Ä¶**15.6x** lower latency

&#x200B;

However, at the moment, there hasn't been much talk about this architecture",70,20,girlpwr2,2024-01-18 14:40:06,https://www.reddit.com/r/deeplearning/comments/199rmhh/why_almost_nobody_is_using_retnet/,0,deeplearning
w3s7zq,How to measure bias and variance in ML models,,73,1,roycoding,2022-07-20 17:29:30,https://i.redd.it/cyp9u9ad9rc91.png,0,deeplearning
muisan,StyleGAN2 + CLIP = StyleCLIP: You Describe & AI Photoshops Faces For You,,74,3,cloud_weather,2021-04-20 04:40:13,https://youtu.be/d1OET63Ulwc,0,deeplearning
iq10sj,Council-GAN - Breaking the Cycle (CVPR 2020) - Free live zoom lecture by the author,,74,1,dataskml,2020-09-10 10:49:55,https://www.reddit.com/gallery/iq10sj,0,deeplearning
h8bzeb,Learning the Math required for Neural Networks,"Hello! I hope you're doing great,

I would like to help anyone interested in learning the math required in neural networks. My impression is that a lot of people are intimidated by the math for different reasons. In my case, I used to find it difficult to even read some equations. 

My aim is to make math less intimidating by writing reader-friendly math. By which I mean math that reminds the reader of the rules required to follow along. And by which I also mean math with equations that avoid skipping so many steps and making us ponder what happened between one line and the next.

In this [article](https://towardsdatascience.com/dismantling-neural-networks-to-understand-the-inner-workings-with-math-and-pytorch-beac8760b595), I explain with reader-friendly math some of the most common functions in a neural network. I also ensure that the reader recalls the differentiation rules needed before differentiating each function. I provide easy examples to support the explanation. Finally, I implement the math in Python and show the equivalent in PyTorch. 

My hope is that you find the article engaging and informative. Please do not hesitate if you have questions, I will do my best to help you with anything you didn't understand.",74,13,trouble-seeker,2020-06-13 17:42:21,https://www.reddit.com/r/deeplearning/comments/h8bzeb/learning_the_math_required_for_neural_networks/,0,deeplearning
14f5ycg,"Finished my PhD researching ""self-aware AI 3D printers"" at Cambridge!",,72,3,dbrion,2023-06-21 12:07:52,https://v.redd.it/b03444vf0d7b1,0,deeplearning
13i621i,"ML Enthusiasts Club - read papers, books and do projects together","I'm lucky enough to be running this super cool community where we all geek out over machine learning papers, dive into foundational books, and smash out projects in teams. We're already a gang of 1000+ strong ML enthusiasts keeping each other accountable and motivated.

We split into intimate learning groups (currently there are about 100 active ones) each of around 10 people.

If this sounds like your kind of scene, give me a shout and I'll slide a Discord invite your way in a DM.

Can't wait to welcome you aboard

EDIT:Here is the invite link: [https://discord.gg/3gT8PVggPN](https://discord.gg/3gT8PVggPN)

&#x200B;",72,332,__god_bless_you_,2023-05-15 11:54:04,https://www.reddit.com/r/deeplearning/comments/13i621i/ml_enthusiasts_club_read_papers_books_and_do/,0,deeplearning
13hdhdi,[Tutorial] Master Deep Voice Cloning in Minutes: Unleash Your Vocal Superpowers! Free and Locally on Your PC,,69,7,CeFurkan,2023-05-14 14:20:27,https://www.youtube.com/watch?v=OiMRlqcgDL0&deeplearning,0,deeplearning
xk44fj,New approach for fine-tuning Text to image diffusion models in 3-5 images,,71,1,imapurplemango,2022-09-21 12:53:58,https://v.redd.it/hwrwkzucl7p91,0,deeplearning
kci2oo,"Liquid Warping GAN - ""Deepfake"" Movements with 1 image ONLY",,72,2,cloud_weather,2020-12-13 20:29:06,https://youtu.be/Zkrcx3_DtCw,0,deeplearning
i1so7x,"How did you get ""good"" at deep learning?","Hey guys I have been self-teaching myself machine learning, data science and deep learning for almost a year now. I have gone through a bunch of courses including all of Andrew Ng's. I have spent almost 3 hours everyday studying. I have done a bunch of small projects by myself, as well as all the projects included in the courses. But it seems like I have hit a plateau. I'm trying to apply deliberate practice to get better in this field, but unlike learning to play an instrument or a sport it is almost impossible to measure progress, or understand if you're going in the right direction. This past month I have just been looking at winning kaggle notebooks and trying to replicate them and also have started fast ais deep learning course. My question is how should I go about learning to get better? When I try to make deep learning projects on my own I tend to get stuck, whether its with cleaning the data or later down the line when it comes to training the model. Any feedback would be much appreciated.",73,34,Goodd0ctor,2020-08-01 14:01:55,https://www.reddit.com/r/deeplearning/comments/i1so7x/how_did_you_get_good_at_deep_learning/,0,deeplearning
mq6zq4,Yann LeCun ‚Äî Self supervised learning and uncertainty representation,,72,0,Itoka,2021-04-13 17:22:41,https://www.youtube.com/watch?v=D9SBRVLb6Yw,0,deeplearning
l8sr7z,I'm open-sourcing Graph Attention Network (GAT) in PyTorch!,,72,2,gordicaleksa,2021-01-30 18:57:38,https://github.com/gordicaleksa/pytorch-GAT,0,deeplearning
kowr6h,Rubik's Cube Solution using OpenCV,,73,1,cmillionaire9,2021-01-02 12:30:29,https://youtu.be/okJ4DMuXRRs,0,deeplearning
ikohsd,"NVIDIA Launches RTX 3070, 3080 and 3090 for $499, $699 and $1,499: Based on Samsung's 8nm Process | Hardware Times",,72,34,kurtstir,2020-09-01 17:18:25,https://www.hardwaretimes.com/nvidia-launches-rtx-3070-3080-and-3090-for-499-699-and-1499-based-on-samsungs-8nm-process/,0,deeplearning
ic4ucs,The new deep fake app goes viral‚Ä¶,,73,19,Vladimirsvsv7777,2020-08-18 16:56:56,https://v.redd.it/s5a17uhgksh51,0,deeplearning
hkjn7q,this is haunting my dreams,,70,5,wAtGeT,2020-07-03 14:06:44,https://i.redd.it/22s054u5gn851.png,0,deeplearning
ekpywo,Face to Face Translation: Translating talking face videos to different languages,,72,16,prajwalkr,2020-01-06 06:15:28,https://www.youtube.com/watch?v=aHG6Oei8jF0,0,deeplearning
e3fwqt,ML Paper Notes: My notes of various ML research papers (DL - CV - NLP),"Hello,

As a PhD student, I read quite a lot of papers, and sometimes I make short summaries with a simple latex template to get a better understanding and have clearer idea of the paper's contributions. For a while I stored them in private Github repo, so I tought why note share them, some people might find them helpful.

PS: Sorry for the (sometimes frequent) spelling mistakes.

Here is the Github link: https://github.com/yassouali/ML_paper_notes",75,5,youali,2019-11-29 15:11:10,https://www.reddit.com/r/deeplearning/comments/e3fwqt/ml_paper_notes_my_notes_of_various_ml_research/,0,deeplearning
17whz6e,Elon Musk's xAI Unveils Grok: The New AI Challenger to OpenAI's ChatGPT,,70,7,Webglobic_tech,2023-11-16 08:28:46,https://v.redd.it/qx68wbuf7o0c1,0,deeplearning
10fw22o,GPT-4 Will Be 500x Smaller Than People Think - Here Is Why,"&#x200B;

[Number Of Parameters GPT-3 vs. GPT-4](https://preview.redd.it/xvpw1erngyca1.png?width=575&format=png&auto=webp&s=d7bea7c6132081f2df7c950a0989f398599d6cae)

The rumor mill is buzzing around the release of GPT-4.

People are predicting the model will have 100 trillion parameters. That‚Äôs a *trillion* with a ‚Äút‚Äù.

The often-used graphic above makes GPT-3 look like a cute little breadcrumb that is about to have a live-ending encounter with a bowling ball.

Sure, OpenAI‚Äôs new brainchild will certainly be mind-bending and language models have been getting bigger ‚Äî fast!

But this time might be different and it makes for a good opportunity to look at the research on scaling large language models (LLMs).

*Let‚Äôs go!*

Training 100 Trillion Parameters

The creation of GPT-3 was a marvelous feat of engineering. The training was done on 1024 GPUs, took 34 days, and cost $4.6M in compute alone \[1\].

Training a 100T parameter model on the same data, using 10000 GPUs, would take 53 Years. To avoid overfitting such a huge model the dataset would also need to be much(!) larger.

So, where is this rumor coming from?

The Source Of The Rumor:

It turns out OpenAI itself might be the source of it.

In August 2021 the CEO of Cerebras told [wired](https://www.wired.com/story/cerebras-chip-cluster-neural-networks-ai/): ‚ÄúFrom talking to OpenAI, GPT-4 will be about 100 trillion parameters‚Äù.

A the time, that was most likely what they believed, but that was in 2021. So, basically forever ago when machine learning research is concerned.

Things have changed a lot since then!

To understand what happened we first need to look at how people decide the number of parameters in a model.

Deciding The Number Of Parameters:

The enormous hunger for resources typically makes it feasible to train an LLM only once.

In practice, the available compute budget (how much money will be spent, available GPUs, etc.) is known in advance. Before the training is started, researchers need to accurately predict which hyperparameters will result in the best model.

*But there‚Äôs a catch!*

Most research on neural networks is empirical. People typically run hundreds or even thousands of training experiments until they find a good model with the right hyperparameters.

With LLMs we cannot do that. Training 200 GPT-3 models would set you back roughly a billion dollars. Not even the deep-pocketed tech giants can spend this sort of money.

Therefore, researchers need to work with what they have. Either they investigate the few big models that have been trained or they train smaller models in the hope of learning something about how to scale the big ones.

This process can very noisy and the community‚Äôs understanding has evolved a lot over the last few years.

What People Used To Think About Scaling LLMs

In 2020, a team of researchers from OpenAI released a [paper](https://arxiv.org/pdf/2001.08361.pdf) called: ‚ÄúScaling Laws For Neural Language Models‚Äù.

They observed a predictable decrease in training loss when increasing the model size over multiple orders of magnitude.

So far so good. But they made two other observations, which resulted in the model size ballooning rapidly.

1. To scale models optimally the parameters should scale quicker than the dataset size. To be exact, their analysis showed when increasing the model size 8x the dataset only needs to be increased 5x.
2. Full model convergence is not compute-efficient. Given a fixed compute budget it is better to train large models shorter than to use a smaller model and train it longer.

Hence, it seemed as if the way to improve performance was to scale models faster than the dataset size \[2\].

And that is what people did. The models got larger and larger with GPT-3 (175B), [Gopher](https://arxiv.org/pdf/2112.11446.pdf) (280B), [Megatron-Turing NLG](https://arxiv.org/pdf/2201.11990) (530B) just to name a few.

But the bigger models failed to deliver on the promise.

*Read on to learn why!*

What We know About Scaling Models Today

It turns out you need to scale training sets and models in equal proportions. So, every time the model size doubles, the number of training tokens should double as well.

This was published in DeepMind‚Äôs 2022 [paper](https://arxiv.org/pdf/2203.15556.pdf): ‚ÄúTraining Compute-Optimal Large Language Models‚Äù

The researchers fitted over 400 language models ranging from 70M to over 16B parameters. To assess the impact of dataset size they also varied the number of training tokens from 5B-500B tokens.

The findings allowed them to estimate that a compute-optimal version of GPT-3 (175B) should be trained on roughly 3.7T tokens. That is more than 10x the data that the original model was trained on.

To verify their results they trained a fairly small model on vastly more data. Their model, called Chinchilla, has 70B parameters and is trained on 1.4T tokens. Hence it is 2.5x smaller than GPT-3 but trained on almost 5x the data.

Chinchilla outperforms GPT-3 and other much larger models by a fair margin \[3\].

This was a great breakthrough!The model is not just better, but its smaller size makes inference cheaper and finetuning easier.

*So What Will Happen?*

What GPT-4 Might Look Like:

To properly fit a model with 100T parameters, open OpenAI needs a dataset of roughly 700T tokens. Given 1M GPUs and using the calculus from above, it would still take roughly 2650 years to train the model \[1\].

So, here is what GPT-4 could look like:

* Similar size to GPT-3, but trained optimally on 10x more data
* ‚Äã[Multi-modal](https://thealgorithmicbridge.substack.com/p/gpt-4-rumors-from-silicon-valley) outputting text, images, and sound
* Output conditioned on document chunks from a memory bank that the model has access to during prediction \[4\]
* Doubled context size allows longer predictions before the model starts going off the rails‚Äã

Regardless of the exact design, it will be a solid step forward. However, it will not be the 100T token human-brain-like AGI that people make it out to be.

Whatever it will look like, I am sure it will be amazing and we can all be excited about the release.

Such exciting times to be alive!

If you got down here, thank you! It was a privilege to make this for you. At **TheDecoding** ‚≠ï, I send out a thoughtful newsletter about ML research and the data economy once a week. No Spam. No Nonsense. [Click here to sign up!](https://thedecoding.net/)

**References:**

\[1\] D. Narayanan, M. Shoeybi, J. Casper , P. LeGresley, M. Patwary, V. Korthikanti, D. Vainbrand, P. Kashinkunti, J. Bernauer, B. Catanzaro, A. Phanishayee , M. Zaharia, [Efficient Large-Scale Language Model Training on GPU Clusters Using Megatron-LM](https://arxiv.org/abs/2104.04473) (2021), SC21

\[2\] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,‚Ä¶ & D. Amodei, [Scaling laws for neural language model](https://arxiv.org/abs/2001.08361)s (2020), arxiv preprint

\[3\] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. Casas, L. Hendricks, J. Welbl, A. Clark, T. Hennigan, [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (2022). *arXiv preprint arXiv:2203.15556*.

\[4\] S. Borgeaud, A. Mensch, J. Hoffmann, T. Cai, E. Rutherford, K. Millican, G. Driessche, J. Lespiau, B. Damoc, A. Clark, D. Casas, [Improving language models by retrieving from trillions of tokens](https://arxiv.org/abs/2112.04426) (2021). *arXiv preprint arXiv:2112.04426*.Vancouver",71,11,LesleyFair,2023-01-19 07:55:49,https://www.reddit.com/r/deeplearning/comments/10fw22o/gpt4_will_be_500x_smaller_than_people_think_here/,0,deeplearning
wsqr58,Building a App for Stable Diffusion: Text to Image generation in Python,,69,15,Illustrious_Row_9971,2022-08-19 22:22:22,https://i.redd.it/53u2kdsuwqi91.jpg,0,deeplearning
urbfv8,Latent Space Interpolation of an ASCII Art Autoencoder,,72,3,ghost_teimo,2022-05-17 01:37:33,https://v.redd.it/7cfpr10zwxz81,0,deeplearning
s61hf1,Sensing Depth with 3D Computer Vision - Link to a free online lecture by the author in comments,,69,3,dataskml,2022-01-17 11:01:39,https://i.redd.it/06yh8v20c8c81.gif,0,deeplearning
gv05bs,2D-3D Pose Estimation and Action Recognition using Multitask Deep Learning Code: Given in the Comment..,,69,4,TheInsaneApp,2020-06-02 04:05:55,https://v.redd.it/2qw7vajm8f251,0,deeplearning
bcuvl5,Which feature detection is used here?,,69,0,treguess,2019-04-13 20:29:42,https://i.imgur.com/rgQIA1V.gifv,0,deeplearning
8kgxg3,New AI tool controls people in videos!,,72,1,NicoleK1993,2018-05-18 22:09:56,https://www.youtube.com/watch?v=qc5P2bvfl44&feature=youtu.be&t=59s,0,deeplearning
18i1lfw,I took the AMD plunge!,"Hi All,

I am one of those few naiive hopeful idiots who switched to AMD in hopes of getting better performance compared to mid level Nvidia cards for personal research into dl models. I was on a RTX 3070 and recently switched to a RX 7900 XTX. And counter to popular opinion I was able to setup ROCm fairly easily on native linux (Ubuntu 22.04). 

However, the experience is below par. I am running into OOM issues while training a custom architecture for transformer models even with 320M parameters on fp32. And my Ubuntu deployment just gets completely frozen if my GPU is about to go into OOM error.

My work can be found here: https://github.com/kjhanjee/LLM_Release

Note: I have scaled down the given model from 1024 embedding dim to 512, and to 1x feed forward scaling instead of 4x and 10 stacks in serial while 4 layers in parallel. If you go through the Readme and model architecture on the git it will be easier to understand. Also, I switched to llama 2 tokenizer (32k token vocab) instead of a custom trained tokenizer (110000).

I have a few questions for the community here and for anybody who can help me be at a better stage than now. 

1. Is there a way to do better at the architecture so that I don't get OOM even for smaller parameter scope like this?

2. Is there a way to get Pytorch working on windows now that ROCm 5.7.1 has been released on windows?

3. I am in two minds about this but should I just move to C++ for deep learning and try to work with HIP libraries directly for coding the nwtwork and getting a better performance?

Please let me know what all can I do better.

Edit:

** I figured out the issue. ** 

### Issue:

It was the bloody Lmhead layer as it is expanding from 4096 dims to 110000 for each token. THIS LAYER EVEN WITH 3070 WAS ALWAYS ON THE CPU (I have 32 gigs ram so the cpu was able to handle it). That creates a whopping large matrix. Also Adam has 2xP size in the memory so it is one another bugger.

### Solution: 

I am now trying to do half and half. I will be Offloading lmhead layer and only a few decoder layers to the gpu and the rest remain on cpu. I've also reduced the dims of it to 2048x110000 so that should be an additional help. And feed forward dims for internal layers to 2xEmbedding instead of 4xEembedding. Serialized a few more layers instead of parallel compute.

I've switched gradient accumulation instead of half precision. Half precision overflows are a problem for a different time.

I will try to switch to SGD with a higher learning rate to see if it can accommodate the loss reduction, I have doubts on it though. If Windows Pytorch comes into play this will be a much easier problem to solve.

I do want to reduce my vocab size but cannot give another 24 hours for tokenizer training. 

Query: Can someone also suggest a fast BPE trainer (not the hf one, it is quite slow)

# UPDATE: 
AMD is good value for money but a pain to work on and honestly, I don't think it is AMD's fault completely. It is a combined fault from the community and the company. There isn't enough traction from the community for the company to actually make legible efforts towards making their software better. The community size for Data Scientists actually trying to use AMD for their work is fairly small.
The other day I posted a comment on the Pytorch GITHUB to check if there are any plans on releasing the lib for Windows as ROCm is now on windows as well. There were about 10 or so responses but from the same 3 people (mine included). Not many were interested in it, and that is leading me to think, maybe we cannot blame AMD for not being good with their software when the community doesn't want it as a whole and there is very less demand for it. I am eagerly waiting for ROCm 6 Pytorch on windows soon, even though there is a possibility it might never happen.",69,42,jhanjeek,2023-12-14 05:39:35,https://www.reddit.com/r/deeplearning/comments/18i1lfw/i_took_the_amd_plunge/,0,deeplearning
m4b7ev,"NEW PYTHON PACKAGE: Sync GAN Art to Music with ""Lucid Sonic Dreams""! (Link in Comments)",,70,9,mencil47,2021-03-13 17:43:24,https://youtu.be/iEFqcMrszH0,0,deeplearning
ldcrq0,Visual Perception Models for Multi-Modal Video Understanding - Dr. Gedas Bertasius (NeurIPS 2020) - Link to free zoom lecture in comments,,68,1,dataskml,2021-02-05 17:50:05,https://i.redd.it/5a6us2cs5pf61.png,0,deeplearning
jn895b,Trump the rocket man (First try with deep face lab),,70,14,BuzzLightr,2020-11-03 10:51:53,https://v.redd.it/51q0q3zh90x51,0,deeplearning
hr1ipd,Deep Learning explained with paper folding analogy (Art of the Problem),,69,1,britcruise,2020-07-14 13:28:47,https://www.youtube.com/watch?v=e5xKayCBOeU,0,deeplearning
gxr9id,AI Generates Real Faces From Sketches! DeepFaceDrawing Overview | Image-to-image translation in 2020,,70,8,OnlyProggingForFun,2020-06-06 13:45:58,https://www.youtube.com/watch?v=djXdgCVB0oM,0,deeplearning
ghh85s,The Ultimate Learning Path for Deep Learning in 2020,,68,16,TheInsaneApp,2020-05-11 05:03:35,https://i.redd.it/4ke1jp6yi2y41.jpg,0,deeplearning
1bpbowc,The shift from custom NLP models to LLM providers,"As a senior ML Engineer, I've been noticing some interesting trends lately, especially over the past 1.5 years or so. It seems like some companies are moving away from using custom downstream NLP models. Instead, they're leaning into these LLMs, especially after all the hype around ChatGPT.

It's like companies are all about integrating these LLMs into their systems and then fine-tuning them with prompts or their data. And honestly, it's changing the game. With this approach, companies don't always need to build custom models anymore. And it cuts down on costs - i.e. wage costs for custom model development or renting VMs for training and hosting.

But, of course, this shift isn't one-size-fits-all. It depends on the type of company, what they offer, their budget, and so. But I'm curious, have you noticed similar changes in your companies? And if so, how has it affected your day-to-day tasks and responsibilities?",68,23,Mr-Venture-Voyager,2024-03-27 20:12:01,https://www.reddit.com/r/deeplearning/comments/1bpbowc/the_shift_from_custom_nlp_models_to_llm_providers/,0,deeplearning
ys71vj,WIP Demo - Snake agents learn through the NEAT algorithm,,69,9,hahaMemesFunny,2022-11-11 10:48:00,https://v.redd.it/0ngj5qlfxaz91,0,deeplearning
otf0fs,"OpenAI Releases Triton, An Open-Source Python-Like GPU Programming Language For Neural Networks","OpenAI released their newest language, [Triton](https://github.com/openai/triton). This open-source programming language that enables researchers to write highly efficient GPU code for AI workloads is Python-compatible and comes with the ability of a user to write in as few as 25 lines, something on par with what an expert could achieve. OpenAI claims this makes it possible to reach peak hardware performance without much effort, making creating more complex workflows easier than ever before!

Researchers in the field of Deep Learning often rely on native framework operators. However, this can be problematic because it requires many temporary tensors to work, which may hurt performance at scale for neural networks. Writing specialized GPU kernels is a more convenient solution, but surprisingly difficult due to intricacies when programming them according to GPUs. It was challenging to find a system that provides the flexibility and speed required while also being easy enough for developers to understand. This has led researchers at OpenAI in improving Triton, which was initially founded by one of their teammates.

Quick Read: [https://www.marktechpost.com/2021/07/28/openai-releases-triton-an-open-source-python-like-gpu-programming-language-for-neural-networks/](https://www.marktechpost.com/2021/07/28/openai-releases-triton-an-open-source-python-like-gpu-programming-language-for-neural-networks/) 

Paper: http://www.eecs.harvard.edu/\~htk/publication/2019-mapl-tillet-kung-cox.pdf

Github: https://github.com/openai/triton",68,5,techsucker,2021-07-28 17:45:57,https://www.reddit.com/r/deeplearning/comments/otf0fs/openai_releases_triton_an_opensource_pythonlike/,0,deeplearning
nyed8t,AI will fake your handwriting using just a single word,,68,4,cmillionaire9,2021-06-12 19:28:31,https://youtu.be/Hc5_M7ziy-Q,0,deeplearning
m24d9d,Computer vision and deep learning used to handpick tomatoes,,70,5,Parth_varma,2021-03-10 18:15:43,https://v.redd.it/wgeub1s804m61,0,deeplearning
kry90r,Nvidia deep inpainting gone wild (I just masked out the dude on the right),,64,11,OneArmPullUpGumby,2021-01-06 21:59:14,https://i.redd.it/cv0ivovsas961.png,0,deeplearning
d003b3,AI Learns to Park - Deep Reinforcement Learning with Unity ML-Agents,,70,11,SamuelArzt,2019-09-05 12:22:48,https://youtu.be/VMp6pq6_QjI,0,deeplearning
y0ftfe,Generation of high fidelity videos from text using Imagen Video,,67,1,imapurplemango,2022-10-10 14:12:23,https://v.redd.it/mmo0mt4hkzs91,0,deeplearning
vo6sqf,Codeformer - Face Image Restoration model,,68,20,imapurplemango,2022-06-30 12:06:46,https://v.redd.it/hbbf9ucf1r891,0,deeplearning
q9pxfi,[OC] How Support Vector Machines (SVM) separates data that is not linearly separable (Full video + .Blend file in the comment),,67,2,Impressive_Path2037,2021-10-17 02:27:52,https://v.redd.it/9241e9s0kjt71,0,deeplearning
nnhdz3,[D] Nice paper showcasing many fundamental ideas on Mathematics of Deep Learning to answer concrete questions.,"¬´[The Modern Mathematics of Deep Learning](https://arxiv.org/pdf/2105.04026v1.pdf)¬ª is a 78 pages paper to become a chapter in a book entitled ¬´Theory of Deep Learning¬ª to be published by Cambridge University Press. After usual definitions and theorems about learning, NN, optimization, approximation, generalization, VC-dimension, etc. the paper provides some math guidances about fundamental ideas in order to answer many concrete questions. Why DNN don't overfit? What is the role of depth? How DNN are overcoming the curse of dimensionality? Why does SGD succeed despite the non-convexity of the problem? Which aspects of an DNN architecture affect the performance of the models and how? Which features of data are learned by DNN? Why DNN perform as well or better than specialized numerical  tools?",68,6,ClaudeCoulombe,2021-05-29 06:34:54,https://www.reddit.com/r/deeplearning/comments/nnhdz3/d_nice_paper_showcasing_many_fundamental_ideas_on/,0,deeplearning
i7vq1r,We built an interactive learning tool to help people ace their machine learning and data science interviews,,68,21,MusingEtMachina,2020-08-11 17:13:33,http://www.confetti.ai,0,deeplearning
golbq4,Open AI and Microsoft Can Generate Python Code,,67,6,cmillionaire9,2020-05-22 15:23:28,https://youtu.be/y5-wzgIySb4,0,deeplearning
f8t2cf,Everything you need to know about computer vision in one repo,"*This post was co-authored by JS Tan, Patrick Buehler, Anupam Sharma and Jun Ki Min.*

In recent years, we‚Äôve seen extraordinary growth in Computer Vision, with applications in image understanding, search, mapping, semi-autonomous or autonomous vehicles and many more .

The ability for models to understand actions in a video , a task that was unthinkable just a few years ago , is now something that we can achieve with relatively high accuracy and in near real-time.

However, the field is not particularly welcoming for newcomers. Without prior experience or guidance, building an accurate classifier can easily take weeks. Unless you‚Äôre ready to spend a long-time learning computer vision, it‚Äôs extremely hard to master the basics, let alone begin to explore some of the cutting-edge technologies in the field. Even for computer vision experts, building a quick Proof of Concept (POC) can be non trivial and could easily end up taking many days to put together.

At [Microsoft ](https://docs.microsoft.com/en-us/azure/machine-learning/?WT.mc_id=medium-article-lazzeri), we have been working for many years on diverse Computer Vision solutions for our customers and collected our learning into our new public [Microsoft](https://docs.microsoft.com/en-us/azure/machine-learning/?WT.mc_id=medium-article-lazzeri) repository: [Custom vision repo](https://github.com/microsoft/ComputerVision-recipes?WT.mc_id=medium-article-lazzeri).

The goal of [this repository](https://github.com/microsoft/ComputerVision-recipes?WT.mc_id=medium-article-lazzeri) is to provide examples and best practice guidelines for building computer vision systems on [Azure](https://docs.microsoft.com/en-us/azure/machine-learning/?WT.mc_id=medium-article-lazzeri) , and to share this with the open-source community . More specifically, our goal was to create a [repository](https://docs.microsoft.com/en-us/azure/machine-learning/?WT.mc_id=medium-article-lazzeri) that will help us to provide solutions rapidly to the community and to customers that we work with , or with on-boarding new team members who may have expertise in data science, but not specifically in computer vision. From mastering some of the most common scenarios in the field, like image classification, object detection , and image similarity, to exploring cutting edge scenarios like activity recognition and crowd counting, [this repo](https://docs.microsoft.com/en-us/azure/machine-learning/?WT.mc_id=medium-article-lazzeri) will guide you through building models, fine-tuning them, and using them in real-world scenarios.

We‚Äôre kicking off our repo with **5 scenarios.** You can find the links to the repos here:

* [Classification](https://github.com/microsoft/computervision-recipes/tree/master/scenarios/classification?WT.mc_id=medium-article-lazzeri)
* [Similarity](https://github.com/microsoft/computervision-recipes/tree/master/scenarios/similarity?WT.mc_id=medium-article-lazzeri)
* [Detection](https://github.com/microsoft/computervision-recipes/tree/master/scenarios/detection?WT.mc_id=medium-article-lazzeri)
* [Action Recognition](https://github.com/microsoft/computervision-recipes/tree/master/contrib/action_recognition?WT.mc_id=medium-article-lazzeri)
* [Crowd Counting](https://github.com/microsoft/computervision-recipes/tree/master/contrib/crowd_counting?WT.mc_id=medium-article-lazzeri)

Rather than creating implementations from scratch, we draw from popular state-of-the-art libraries (e.g. fast.ai and [torchvision ](https://pytorch.org/docs/stable/torchvision/index.html)), and we build additional utility around loading image data, optimizing models , and evaluating models. In addition, we aim to answer the frequently asked questions, try to explain the deep learning intuitions, and highlight common pitfalls.

Whether you a re an expert in computer vision or just getting your hands wet, we believe [this repository](https://docs.microsoft.com/en-us/azure/machine-learning/?WT.mc_id=medium-article-lazzeri) offers something for you . For the beginner, [this repo](https://docs.microsoft.com/en-us/azure/machine-learning/?WT.mc_id=medium-article-lazzeri) will guide you through building a state-of-the-art model and help you develop an intuition for the craft. For the experts, this repository can quickly get you to a strong baseline model which is easy to extend using custom Python/PyTorch code. In addition, the repository also aims to provide support with:

1. [The full data science process](https://docs.microsoft.com/azure/machine-learning/team-data-science-process/overview?WT.mc_id=medium-article-lazzeri).
2. [The tooling to succeed on Azure](https://docs.microsoft.com/en-us/azure/machine-learning/?WT.mc_id=medium-article-lazzeri).

We hope that these examples and utilities will make it easier and faster for developers to create custom vision applications.

# The Data Science Process

The [Computer Vision Recipes GitHub repository](https://github.com/microsoft/ComputerVision-recipes?WT.mc_id=medium-article-lazzeri) shows you how to approach the five key steps of the data science process and provides utilities to enrich each of the steps :

1. **Evaluating** ‚Äî Evaluate your model. Depending on the metric you‚Äôre interested in optimizing, you may want to explore different methods of evaluation.
2. **Model selection and optimization** ‚Äî Tun e and optimize hyperparameters to get the highest performing model. Because Computer Vision models are often computationally costly, we show you how to seamlessly scale your parameter tuning into Azure .
3. **Operationalizing** ‚Äî Operationalize models in a production environment on Azure by deploying it onto Kubernetes.

Inside the computer vision recipes [repo,](https://github.com/microsoft/ComputerVision-recipes?WT.mc_id=medium-article-lazzeri) we have added a lot of utility to support common tasks such as loading data sets in the format expected by different algorithms, splitting training/test data, and evaluating model outputs .

This computer vision repository also has deep integration with the [Azure Machine Learning](https://docs.microsoft.com/en-us/azure/machine-learning/?WT.mc_id=medium-article-lazzeri) to complement your work locally. We provide code examples on how you can optionally and easily scale your training into the cloud, and how you can deploy your models for production workloads.

**Azure Cognitive Services**

Note that for certain computer vision problems, you may not need to build your own models. Instead, pre-built or easily customizable solutions exist which do not require any custom coding or machine learning expertise.

* [Vision Services](https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/?WT.mc_id=medium-article-lazzeri) are a set of pre-trained REST APIs which can be called for image tagging, OCR, video analytics, and more. These APIs work out of the box and require minimal expertise in machine learning but have limited customization capabilities. See the various demos available to get a feel for the functionality (e.g. Computer Vision).
* [Custom Vision](https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/?WT.mc_id=medium-article-lazzeri) is a SaaS service to train and deploy a model as a REST API given a user-provided training set. All steps including image upload, annotation, and model deployment can be performed using either the UI or a Python SDK. Training image classification or object detection models can be achieved with minimal machine learning expertise. The Custom Vision offers more flexibility than using the pre-trained cognitive services APIs but requires the user to bring and annotate their own data.

Before using the Computer Vision repository, we strongly recommend evaluating if these can sufficiently solve your problem.

To give you a sense of how you can use our repo to build a state of the art (SOTA) model, here is a preview of how simple it is to create an Object Detection model. Of course, you can go much deeper and add custom PyTorch code, but getting started is as simple as this :

**1. Load your data**

The first step is to load your data ‚Äî we help you do this with a simple object that automatically parses your data and the annotations:

`from utils_cv.detection.data import DetectionLoader data = DetectionLoader(""path/to/data"")`

**2. Train/fine-tune your model**

Then we create a ‚Äòlearner‚Äô object that helps you manage and train your model. By default, it will use torchvision‚Äôs Faster R-CNN model. But you can easily switch it out.

`from utils_cv.detection.model import DetectionLearner detector = DetectionLearner(data) detector.fit()`

**3. Evaluate**

Finally, lets evaluate our model using the built-in helper functions. We can look at the precision and recall curves to give us a sense of how our model is performing.

`from utils_cv.detection.plot import plot_pr_curves eval = detector.evaluate() plot_pr_curves(eval)`

As we continue to build out of repository, we will be looking for new computer vision scenarios to unlock . Feel free to reach out to [cvbp@microsoft.com](mailto:cvbp@microsoft.com) or post an issue if you wish to see us cover a scenario .

# Additional resources to learn more

To learn more, you can read the following articles and notebooks:

* [Custom vision repo](https://github.com/microsoft/ComputerVision-recipes?WT.mc_id=medium-article-lazzeri)
* Original article: [https://techcommunity.microsoft.com/t5/azure-ai/nearly-everything-you-need-to-know-about-computer-vision-in-one/ba-p/1070311](https://techcommunity.microsoft.com/t5/azure-ai/nearly-everything-you-need-to-know-about-computer-vision-in-one/ba-p/1070311)
* [Vision Services](https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/?WT.mc_id=medium-article-lazzeri) on Azure
* [Custom Vision](https://docs.microsoft.com/en-us/azure/cognitive-services/custom-vision-service/?WT.mc_id=medium-article-lazzeri) on Azure
* Portfolio of Azure Machine Learning Notebooks: [aka.ms/AzureMLServiceGithub](https://aka.ms/AzureMLServiceGithub)
* Azure Machine Learning: [aka.ms/AzureMLservice](https://aka.ms/AzureMLservice)
* Get started with Azure ML: [aka.ms/GetStartedAzureML](https://aka.ms/GetStartedAzureML)
* Automated Machine Learning Documentation: [aka.ms/AutomatedMLDocs](https://aka.ms/AutomatedMLDocs)
* What is Automated Machine Learning? [aka.ms/AutomatedML](https://aka.ms/AutomatedML)
* Python Microsoft: [aka.ms/PythonMS](https://aka.ms/PythonMS)
* Azure ML for VS Code: [aka.ms/AzureMLforVSCode](https://aka.ms/AzureMLforVSCode)",66,5,frlazzeri,2020-02-24 15:44:25,https://www.reddit.com/r/deeplearning/comments/f8t2cf/everything_you_need_to_know_about_computer_vision/,0,deeplearning
eiu9pn,MIT 6.S191 Introduction to Deep Learning | New 2019 Edition,,64,0,newworld-ai,2020-01-02 05:57:56,https://www.newworldai.com/mit-6-s191-introduction-deep-learning-new-2019-edition/,0,deeplearning
ch5cre,Found on GitHub a blazingly fast implementation of Byte Pair Encoding (BPE) algorithm. Much faster than Google SentencePiece.,,66,3,Yutkin,2019-07-24 08:12:33,https://github.com/VKCOM/YouTokenToMe,0,deeplearning
1243xe7,Video To Anime Tutorial - Full Workflow Included - Generate An EPIC Animation From Your Phone Recording By Using Stable Diffusion AI - Consistent - Minimal DeFlickering - 5 Days of Research and Work - Ultra HD,,66,1,CeFurkan,2023-03-27 22:55:32,https://v.redd.it/0l10ix9t1dqa1,0,deeplearning
11mnw1m,this is reality.,,68,7,Genius_feed,2023-03-09 09:28:35,https://i.redd.it/tf2uhp1smoma1.png,0,deeplearning
10okyg3,[P] We built a browser extension that unlocks browser mode capabilities using ChatGPT: MULTI¬∑ON: AI Web Co-Pilot powered by ChatGPT,,67,8,DragonLord9,2023-01-29 22:39:07,https://v.redd.it/2hw47h0b82fa1,0,deeplearning
tr1nxc,Pastiche Master: Exemplar-Based High-Resolution Portrait Style Transfer,,67,3,Illustrious_Row_9971,2022-03-29 14:39:34,https://v.redd.it/acnj1ept3cq81,0,deeplearning
jz0e4l,Transformers are better than CNNs even in computer vision! (big data regime),,66,12,gordicaleksa,2020-11-22 18:15:58,https://youtu.be/j6kuz_NqkG0,0,deeplearning
ix4m8i,Smartphone Videos Produce Highly Realistic 3D Face Reconstructions,,69,0,Parth_varma,2020-09-21 17:11:28,https://v.redd.it/3tknn16hyzn51,0,deeplearning
fmf5vg,AI learned to realistically change the time of day in the photo,,68,4,cmillionaire9,2020-03-21 13:43:57,https://youtu.be/4etgOxaIxdI,0,deeplearning
d0rvz3,AI Institute ‚ÄúGeometry of Deep Learning‚Äù 2019 [Day 1 | Session 1],,62,2,ai-lover,2019-09-07 05:02:14,https://www.youtube.com/watch?v=d9YJJH86ERw,0,deeplearning
bgj8t9,Respected AI pioneer and visionary Nils John Nilsson passed away early this morning,,66,0,gwen0927,2019-04-23 17:35:55,https://medium.com/syncedreview/ai-visionary-nils-nilsson-dies-9113dfcd520,0,deeplearning
ap2dm6,NVIDIA Open-Sources Hyper-Realistic Face Generator StyleGAN,,67,9,gwen0927,2019-02-10 09:06:08,https://medium.com/syncedreview/nvidia-open-sources-hyper-realistic-face-generator-stylegan-f346e1a73826,0,deeplearning
1b7mf2m,Can old people learn and get hired?,"I am 71 with an all but phd dissertation math background, several years of teaching experience (up through Calculus and Prob/Stat). My programming skills are modest but improving. I have taken a number of machine learning and deep learning courses on Coursera and done quite well. Is it possible for me to get a bachelor‚Äôs or master‚Äôs degree in computer science or data analytics online and then get a job with an AI company?

If not, what are the best ways to make a positive impact on the field?

I am not in this for the big bucks, as I am comfortably retired, but rather to show that it can be done. ",66,29,Math_Evangelist,2024-03-06 01:06:11,https://www.reddit.com/r/deeplearning/comments/1b7mf2m/can_old_people_learn_and_get_hired/,0,deeplearning
13w7gzp,Full Tutorial For DeepFake + CodeFormer Face Improvement With Auto1111 - Video Link On Comments + Free Google Colab Script,,65,9,CeFurkan,2023-05-31 00:46:58,https://v.redd.it/f9hu79z0v33b1,0,deeplearning
112sunq,Physics-Informed Neural Networks,,63,29,vadhavaniyafaijan,2023-02-15 08:03:18,https://v.redd.it/grjijnsli5ia1,0,deeplearning
1096byl,What do you all think about these ‚ÄúSEO is Dead‚Äù articles?,"I keep seeing [articles](https://jina.ai/news/seo-is-dead-long-live-llmo/) like this over the years and it made me wonder. Is SEO really dead? Or will it evolve? Back then I kept wondering if it‚Äôs true or not. Some believe SEO is dead, some don‚Äôt. But now with tools like Chat GPT and Midjourney, I think it‚Äôs time to take a look back and see how this might change SEO or if it will ‚Äúkill‚Äù SEO.

I keep seeing threads and discussions seeing how people are excited and worried at the same time with how AI might be able to do a better job. But the way I see it, AI content still needs a person to tell it what to do and make the writing look nice. And also I think that the internet will have a lot of writing that was made by AI and that might change how we find things online. You might also see a ton of content being written by AI and trigger some plagiarism detectors and have a lot of websites get penalized. Hopefully the internet won‚Äôt be filled with boilerplate copy/pasted content coming from Chat GPT.

Well we have Google to filter out trash content anyway. But I know Google has some issues lately that they need to fix. One is that they also have AI that can help people find things on the internet with their search engine, and they need to make sure they are still the best in terms of search. 

The second is that Google needs to find a way to tell if something is really good or not, like how some websites that show art do. Google wants to show the best thing first, but it's hard because sometimes the thing that is the best is also something that Google's customers want people to see. It‚Äôs possible that some AI generated contentSo it's kind of tricky.

I have a feeling companies that already make SEO-writing and checking bots are gonna roll out some fresh new models soon. They're gonna be even better than before. These bots are going to write some good articles and product descriptions that are almost perfect. It almost looks like a human wrote the article or description. And all a human will do is quickly check for any false claims and write a headline that doesn't sound like a robot wrote it. 

We can only really tell 5-10 years from now. In the meantime, I‚Äôll probably go back practicing some handyman skills and also go back teaching people how to drive and also be a service driver. These jobs I had in the past were way different from what I am earning now but if the worst comes to worst, at least I have these physical skills ready.",68,3,Aggressive-Twist-252,2023-01-11 14:41:25,https://www.reddit.com/r/deeplearning/comments/1096byl/what_do_you_all_think_about_these_seo_is_dead/,0,deeplearning
w5jk8v,Some of my favorite DALL. E artworks,,65,7,Blasphemer666,2022-07-22 19:48:05,https://www.reddit.com/gallery/w5jk8v,0,deeplearning
q61vs3,"True to life, highly accurate AI generated pictures",,64,6,Sublevel33,2021-10-11 18:09:18,https://www.reddit.com/gallery/q61vs3,0,deeplearning
mynzph,Search images with text - An Open-Source project for cross-modal search,,64,5,opensourcecolumbus,2021-04-26 02:52:54,https://i.redd.it/c79an1xcmfv61.jpg,0,deeplearning
msrsc4,*Semantic* Video Search with OpenAI‚Äôs CLIP Neural Network (link in comments!),,65,9,designer1one,2021-04-17 14:31:07,https://i.redd.it/as278qmzuqt61.gif,0,deeplearning
li6qjb,"A Curated List of 100+ Free Deep Learning and Machine Learning Courses by Kaggle, FastAI, DeepMind, MIT, Google, and other Biggies",,65,0,TheInsaneApp,2021-02-12 08:10:47,https://www.theinsaneapp.com/2021/02/best-free-machine-learning-courses.html,0,deeplearning
efuzhp,[off-topic],,67,10,prpereiras89,2019-12-26 12:39:47,https://i.redd.it/tc4xg0ng3z641.jpg,0,deeplearning
c67539,Geoffrey Hinton‚Äôs Unsupervised Capsule Networks Achieve SOTA Results on SVHN - Medium,,66,1,Yuqing7,2019-06-27 15:48:54,https://medium.com/syncedreview/geoffrey-hintons-unsupervised-capsule-networks-achieve-sota-results-on-svhn-ffe05e871249,0,deeplearning
10gs1ik,Gotcha,,65,5,actual_rocketman,2023-01-20 08:53:58,https://i.redd.it/yyh41pnje7da1.jpg,0,deeplearning
ifun56,Best Image Colorization AI as of 2020,,67,1,cloud_weather,2020-08-24 18:24:49,https://youtu.be/mUXpxxyThr8,0,deeplearning
gu061q,"The YOLOv4 algorithm. Introduction to You Only Look Once, Version 4. Real Time Object Detection in 2020",,63,5,OnlyProggingForFun,2020-05-31 14:34:25,https://youtu.be/CtjZFkO5RPw,0,deeplearning
ewa9jc,OpenAI goes all-in on Facebook's Pytorch machine learning framework,,63,0,emptyplate,2020-01-30 18:53:20,https://venturebeat.com/2020/01/30/openai-facebook-pytorch-google-tensorflow/,0,deeplearning
errxzn,A Unified Framework for Robust Image-Based Virtual Try-On,,66,6,cmillionaire9,2020-01-21 08:46:54,https://youtu.be/X6d9pQ7Sreo,0,deeplearning
89e8a2,How I train my models,,66,7,csyrup,2018-04-03 14:19:19,https://i.redd.it/inrxzjj5cpp01.jpg,0,deeplearning
my64sd,Deep Learning Certificate -University of SAN FRANCISCO by FastAI (Jeremy Howard),"The fastai Deep Learning Certificate  with the University of SAN FRANCISCO , is now free in Github

Course content covers an introduction to deep learning, fastai, and PyTorch.

fastai is a layered API for deep learning

fastbook project: [https://github.com/fastai/fastbook](https://github.com/fastai/fastbook)

Course: [https://www.usfca.edu/data-institute/certificates/deep-learning-part-one](https://www.usfca.edu/data-institute/certificates/deep-learning-part-one)

Added on 26 April:

The university certificate is worth 2K

but you can get all the python code/ ipynb  files free in the github link

fastbook project: [https://github.com/fastai/fastbook](https://github.com/fastai/fastbook)

Most of us are more keen on learning than the certificate, so thought this would be useful

The course link is to get some context to course outline/details.",63,0,QuackSK,2021-04-25 11:07:55,https://www.reddit.com/r/deeplearning/comments/my64sd/deep_learning_certificate_university_of_san/,0,deeplearning
kpbepx,Trained an AI with ML to do the obstacle course level super fast,,60,0,Roboserg,2021-01-03 02:16:09,https://gfycat.com/oldfashionedhorriblegreathornedowl,0,deeplearning
g8zz6w,"[R] Clova AI Research's StarGAN v2 (CVPR 2020 + code, pre-trained models, datasets)",,64,3,buaawht,2020-04-27 12:42:48,https://v.redd.it/t940o9jjv9v41,0,deeplearning
g2z05r,Project: Using Deep Learning to Track Deforestation in the Amazon Forest,,61,4,TheInsaneApp,2020-04-17 09:54:30,https://i.redd.it/aiq0o84voct41.png,0,deeplearning
b1htwf,Keras for Beginners,"I made a 15 videos series on Keras for beginners, when I was starting learning I thought that there was a lack on how to start using keras, so I did this series help this can be useful for you too. [https://www.youtube.com/playlist?list=PLJ1jRXwHYGNpSKcSVm117e5hy\_xTwsNrS](https://www.youtube.com/playlist?list=PLJ1jRXwHYGNpSKcSVm117e5hy_xTwsNrS)",61,3,limapedro,2019-03-15 17:41:34,https://www.reddit.com/r/deeplearning/comments/b1htwf/keras_for_beginners/,0,deeplearning
18ij68y,Which book to start?,"I have no background in ML/AI. My background is a backend-focused senior software engineer  at a FAANG company, no degree. I have nominal knowledge of linear algebra.

I recently decided I want to learn deep learning. Not necessarily for work but out of personal interest, particularly in the developing field of generative AI. Historically I‚Äôve been good at learning via reading so I impulse bought a bunch of books on the subject and would like thoughts on which to start with.

Pictured:
- Inside Deep Learning
- Learning Deep Learning
- Generative Deep Learning
- Deep Learning with Python
- Deep Learning with PyTorch

Not pictured:
- Python for Data Analysis (thought this would be useful)
- Deep Learning for Vision Systems
- Deep Learning for Coders with fastai and PyTorch
- Deep Learning and the Game of Go (I play this game and followed AlphaGo‚Äôs release heavily)

I was thinking of starting with either Inside Deep Learning or Learning Deep Learning, as I want to be able to understand the theory behind the networks, agnostic of framework. I briefly started on the fastai book, which seems targeted exactly at my persona, but was turned off slightly by the use of their own libraries‚Äîwhat info am I losing, how would I translate to Keras, etc‚Äîand how much fluff is given to celebrating the people behind ideas‚Äîit reads like 50-50 academic praise vs practical knowledge.

If you‚Äôve read any of these and particularly if you don‚Äôt have an academic background in ML, could you recommend which to start on? (I plan to read all or most, eventually)",60,49,zac_attack_,2023-12-14 21:27:52,https://i.redd.it/38thv7j1wb6c1.jpeg,0,deeplearning
tfqyrr,"54392 real-world Food Images with 100,256 annotations",,63,2,haseen-sapne,2022-03-16 19:36:45,https://i.redd.it/1651tlk3tsn81.png,0,deeplearning
rjq6iy,"the r2 score at the end, terrible, possible world record here",,64,3,CielNoiRr_,2021-12-19 05:51:29,https://i.redd.it/ike67sa4uf681.png,0,deeplearning
imd41p,Accurately Lip-syncing Videos,,63,2,Independent-Square32,2020-09-04 09:50:55,https://youtu.be/jGRKzDvmBNo,0,deeplearning
1alyiic,Is overfitting always a bad thing?,"As I understand, overfitting occurs when a model learns noise in the training data, so that it performs on training data higher than validation data. Overfitting is bad because overfit models do not generalize well on unseen data. So we use early stopping to prevent overfitting.

Now, I am training a CNN for image classification. At first, till the training accuracy reaches 95%, I see the same trend in validation accuracy. So till this point, there is no overfitting. But as I train the model from 95% to 99%, validation accuracy moves from 95% to 96%. By definition, this is overfitting, but the validation performance of the model is still improving. Is this kind of overfitting also considered bad?",61,34,MrXDawood,2024-02-08 15:39:55,https://www.reddit.com/r/deeplearning/comments/1alyiic/is_overfitting_always_a_bad_thing/,0,deeplearning
a6xvne,Current feel a few months into my research,,60,1,bossk91,2018-12-17 08:02:53,https://i.redd.it/vo63jcs0ps421.png,0,deeplearning
9sglwt,Decensoring Hentai with Deep Neural Networks,,64,16,allthingsvr,2018-10-29 19:55:11,https://github.com/deeppomf/DeepCreamPy,0,deeplearning
147kh35,Stylize Animation using Temporalnet,,60,6,oridnary_artist,2023-06-12 10:13:47,https://v.redd.it/o19rn584bk5b1,0,deeplearning
141282u,How Open Ai‚Äôs Andrej Karpathy Made One of the Best Tutorials in Deep Learning,"I want you to check [my review](https://medium.com/@0ssamaak0/how-open-ais-andrej-karpathy-made-one-of-the-best-tutorials-in-deep-learning-e6b6445a2d05) on Andrej Karpathy amazing work on explaining how GPT is built

[GitHub Repo](https://github.com/0ssamaak0/Karpathy-Neural-Networks-Zero-to-Hero) for code & more details

&#x200B;

https://preview.redd.it/z204zwtzn44b1.png?width=720&format=png&auto=webp&s=095ea00991ebb295f48b70436456b1f283a50df1",60,2,0ssamaak0,2023-06-05 04:33:14,https://www.reddit.com/r/deeplearning/comments/141282u/how_open_ais_andrej_karpathy_made_one_of_the_best/,0,deeplearning
zvw7dg,Insane Inkpunk Animation using Deforum,,62,3,oridnary_artist,2022-12-26 20:35:13,https://v.redd.it/pg7f7j7oya8a1,0,deeplearning
lc6t26,Neural Networks Generate New Dwight Schrute Quotes,,59,6,Snoo28889,2021-02-04 03:51:32,https://youtu.be/VSxcfD2lGnM,0,deeplearning
j6lkrd,NVIDIA Releases Imaginaire: A Universal PyTorch Library Designed For Various GAN-Based Tasks And Methods,"NVIDIA has developed a universal PyTorch library,¬†**Imaginaire,**¬†with an optimized implementation of various GAN images and video synthesis.¬†

The¬†**Imaginaire**¬†library currently covers three types of models, providing tutorials for each of them:

* Supervised Image-to-image translation
* Unsupervised Image-to-image translation
* Video-to-video translation¬†

Summary: https://www.marktechpost.com/2020/10/06/nvidia-releases-imaginaire-a-universal-pytorch-library-designed-for-various-gan-based-tasks-and-methods/

Github: [https://github.com/NVlabs/imaginaire#supervised-image-to-image-translation](https://github.com/NVlabs/imaginaire#supervised-image-to-image-translation)

&#x200B;

https://i.redd.it/99wdtefy3mr51.gif",60,2,ai-lover,2020-10-07 05:55:05,https://www.reddit.com/r/deeplearning/comments/j6lkrd/nvidia_releases_imaginaire_a_universal_pytorch/,0,deeplearning
eaxka9,[D] Anti Money Laundering with GANs and Graph Embeddings," 

We have worked on a 40 TB dataset to predict money laundering (and fraud), and it works incredibly well. We shared some of the results here in a blog. The TLDR is that unsupervised learning and Generative Adverserial Networks are very promising techniques (as well as graph embeddings):

[https://www.logicalclocks.com/blog/ai-deep-learning-for-anti-money-laundering](https://www.logicalclocks.com/blog/ai-deep-learning-for-anti-money-laundering)

Some more results are available here in this video:  
[https://databricks.com/session\_eu19/deep-anomaly-detection-from-research-to-production-leveraging-spark-and-tensorflow](https://databricks.com/session_eu19/deep-anomaly-detection-from-research-to-production-leveraging-spark-and-tensorflow)",58,5,jpdowlin,2019-12-15 10:37:58,https://www.reddit.com/r/deeplearning/comments/eaxka9/d_anti_money_laundering_with_gans_and_graph/,0,deeplearning
dk6wyb,"Neural networks taught to ""read minds"" in real time",,59,12,cmillionaire9,2019-10-19 17:34:00,https://youtu.be/mJct6RUETh0,0,deeplearning
c5cnpv,Mask R-CNN Instance Segmentation with PyTorch,,60,2,spmallick,2019-06-25 18:11:49,https://i.redd.it/aq5xjd6umj631.png,0,deeplearning
bsq6ry,"Turning a Semantically Labeled UnrealEngine Scene into ""Photo-real"" Video",,62,4,rozgo,2019-05-25 03:42:18,https://v.redd.it/81672pok2a031,0,deeplearning
10iyx52,"arXiv Feed: Keep up with AI research, the easy way.","Hey Reddit!

As someone working in AI, I've always found it hard to keep up with the fast pace of AI research going on.

So, I built **arXiv Feed** as a fun side project ([https://arxiv-feed.vercel.app/](https://arxiv-feed.vercel.app/)).

It's a feed of recent AI papers with a **one-liner** summarizing what problem each one is solving.

It offers ***semantic search*** for finding AI papers covering particular topics (e.g., ""connecting LLMs to external data"").

You can also use it to find papers that are similar to a given paper.

If you'd like this content as a free weekly newsletter, subscribe here: [https://arxiv-feed.beehiiv.com/subscribe](https://arxiv-feed.beehiiv.com/subscribe)

Hope you find this project useful, and would love to hear the community's thoughts & feedback!

PS: I've only indexed \~9K+ papers so far (with more added daily), and currently most of the papers are around LLMs. Will add papers in other research areas as well, lmk if you have any favorites I should prioritize!",60,21,BullyMaguireJr,2023-01-23 00:25:24,https://www.reddit.com/r/deeplearning/comments/10iyx52/arxiv_feed_keep_up_with_ai_research_the_easy_way/,0,deeplearning
mpx8tt,Real-time recognition of handwritten math functions and drawing their graphs,,56,3,cmillionaire9,2021-04-13 07:17:33,https://youtu.be/jcoB61viBnk,0,deeplearning
ksguyc,"500 AI, Machine learning, Deep learning, Computer vision, and NLP Projects with code",,58,4,binaryfor,2021-01-07 16:33:59,https://github.com/ashishpatel26/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code,0,deeplearning
huovy1,AI will generate a full function React app,,62,11,cmillionaire9,2020-07-20 16:57:22,https://youtu.be/RyiWFbSdk78,0,deeplearning
grx13u,What it's like reading about a new architecture,,60,2,cynoelectrophoresis,2020-05-28 01:45:09,https://www.youtube.com/watch?v=eMJk4y9NGvE,0,deeplearning
bctx11,Katie Bauman shows how the black hole imaging reduces to a computer vision problem,,57,0,treguess,2019-04-13 19:02:09,https://www.youtube.com/watch?v=YgB6o_d4tL8,0,deeplearning
1aijx5w,Why do we require a layer structure?,"Sorry if this question might sound stupid, I recently started learning about neural networks in deep learning.
And I noticed that every deep learning network seemed to have fully connected layer structure.
Is these a reason for having neurons in fully connected structure?  I mean if an artificial neuron is analogous to a biological neuron then why don't we have mesh networks like neurons make inside the brain?",56,21,AksHz,2024-02-04 09:16:57,https://i.redd.it/lhbsrlf1djgc1.jpeg,0,deeplearning
onlxeq,MIT Introduction To Deep Learning : (New 2021 Edition),,58,0,newworld-ai,2021-07-19 20:00:13,https://www.newworldai.com/mit-introduction-to-deep-learning-new-2021-edition/,0,deeplearning
kayana,open source face recognition on raspberry pi,,60,2,solderzzc,2020-12-11 07:34:34,https://v.redd.it/p0iy4ihogi461,0,deeplearning
jx4lc1,TorchXRayVision is a library of pre-trained machine learning models that can predict 18 different pathologies from a single chest XRay. It is developed by researchers from Mila (Quebec AI Institute) and Stanford's Center for Artificial Intelligence in Medicine & Imaging (AIMI).,,55,0,Snoo_85410,2020-11-19 15:22:28,https://crossminds.ai/video/5fb57cf21f2b03bb6032fdf6/?playlist_id=5f07c51e2de531fe96279ccb,0,deeplearning
ju5hii,Reinforcement Learning Course by DeepMind,,58,2,OneUpWallStreet,2020-11-14 17:21:24,https://youtu.be/2pWv7GOvuf0,0,deeplearning
ieofwo,Fast.ai has made pytorch jupyter version notebook for free,,57,1,absurd234,2020-08-22 19:11:22,https://www.fast.ai/2020/08/20/soumith-forward/,0,deeplearning
hgttf3,This AI translates code from a programming language to another | Facebook TransCoder Explained,,58,2,OnlyProggingForFun,2020-06-27 13:49:10,https://youtu.be/u6kM2lkrGQk,0,deeplearning
h9erz6,AI transforms a Low-Resolution Image to a High-Res,,59,11,cmillionaire9,2020-06-15 11:49:23,https://youtu.be/RVQfSChtpqI,0,deeplearning
e657fi,Mid-Build on a 4 GPU Deep Learning Machine (GPUs not in the machine until I finalize radiator placement),,56,23,betaJump3r,2019-12-04 20:21:41,https://i.redd.it/b8v6n17tdo241.jpg,0,deeplearning
e4w1tc,"Dive into Deep Learning (Book) by Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola [Git, Book, Course link included below]","&#x200B;

**Download Link:** [https://d2l.ai/d2l-en.pdf](https://d2l.ai/d2l-en.pdf)

**Github:** [https://github.com/d2l-ai/d2l-en](https://github.com/d2l-ai/d2l-en)

**STAT 157, UC Berkeley:** http://courses.d2l.ai/berkeley-stat-157/index.html 

  
Find The Most Updated and Free Artificial Intelligence, Machine Learning, Data Science, Deep Learning, Mathematics, Python Programming Resources [https://www.marktechpost.com/free-resources/](https://www.marktechpost.com/free-resources/)

&#x200B;

https://preview.redd.it/gv9benjki6241.png?width=708&format=png&auto=webp&s=2f4da82e12e790da4fb8be94e599673abf24a056",60,4,ai-lover,2019-12-02 08:16:28,https://www.reddit.com/r/deeplearning/comments/e4w1tc/dive_into_deep_learning_book_by_aston_zhang/,0,deeplearning
a8p87g,Information Theory of Deep Learning - Explained,"I wrote a blog post on the research done by Prof. Naftaly Tishby on Information Theory of Deep Learning ([https://adityashrm21.github.io/Information-Theory-In-Deep-Learning/](https://adityashrm21.github.io/Information-Theory-In-Deep-Learning/)).

He recently gave a talk on the topic at Stanford University. It gave me a new perspective to look at Deep Neural Networks. Tishby's claims were disregarded for Deep Neural Networks with Rectified Linear Units but a recent paper supports his research on using Mutual Information in Neural Networks with Rectified Linear Units. [https://arxiv.org/abs/1801.09125](https://arxiv.org/abs/1801.09125)

Hope this helps someone else too and will give you an overview of the research in a lesser time.

PS: I am new to information theory.",54,6,adityashrm21,2018-12-22 22:35:09,https://www.reddit.com/r/deeplearning/comments/a8p87g/information_theory_of_deep_learning_explained/,0,deeplearning
17z2om2,I don't think there is much to do for the small guys in deep learning anymore.,It's common sense that the intelligence will require extremely large amount of parameters to be of good use which is quite not possible to get hands on by small guys of some some research labs,57,53,devilex94,2023-11-19 17:53:18,https://www.reddit.com/r/deeplearning/comments/17z2om2/i_dont_think_there_is_much_to_do_for_the_small/,0,deeplearning
12v1hrr,Using DALL-E to make an animated short film!,,57,3,Lewenhart87,2023-04-22 10:11:54,https://v.redd.it/jgi65u8lleva1,0,deeplearning
z1ou3w,"In this work, researchers introduce Editable Dance GEneration (EDGE), a state-of-the-art method for editable dance generation that is capable of creating realistic, physically-plausible dances while remaining faithful to the input music.",,57,1,ai-lover,2022-11-22 08:59:03,https://v.redd.it/64zise5vtg1a1,0,deeplearning
y81lii,6D pose estimation in the wild with this self-supervised approach,,55,1,imapurplemango,2022-10-19 12:36:27,https://v.redd.it/ipov9luubru91,0,deeplearning
okx5hm,"EleutherAI Researchers Open-Source GPT-J, A Six-Billion Parameter Natural Language Processing (NLP) AI Model Based On GPT-3","[GPT-J](https://www.eleuther.ai/), a six-billion-parameter natural language processing (NLP) AI model based on GPT-3, has been open-sourced by a team of EleutherAI researchers. The model was trained on an open-source text [dataset of 800GB](https://pile.eleuther.ai/) and was comparable with a GPT-3 model of similar size.

The model was trained using Google Cloud‚Äôs v3-256 TPUs using EleutherAI‚Äôs Pile dataset, which took about five weeks. GPT-J achieves accuracy similar to OpenAI‚Äôs reported findings for their 6.7B parameter version of GPT-3 on standard NLP benchmark workloads. The model code, pre-trained weight files, a Colab notebook, and a sample web page are included in EleutherAI‚Äôs release.

Story: [https://www.marktechpost.com/2021/07/15/eleutherai-researchers-open-source-gpt-j-a-six-billion-parameter-natural-language-processing-nlp-ai-model-based-on-gpt-3/](https://www.marktechpost.com/2021/07/15/eleutherai-researchers-open-source-gpt-j-a-six-billion-parameter-natural-language-processing-nlp-ai-model-based-on-gpt-3/) 

Github repository for GPT-J: https://github.com/kingoflolz/mesh-transformer-jax

Colab Notebook: https://colab.research.google.com/github/kingoflolz/mesh-transformer-jax/blob/master/colab\_demo.ipynb

Web Demo: https://6b.eleuther.ai/",59,5,techsucker,2021-07-15 17:06:55,https://www.reddit.com/r/deeplearning/comments/okx5hm/eleutherai_researchers_opensource_gptj_a/,0,deeplearning
hbouoy,I made a simulation of the Deep Double Descent: The reason why deep enough networks do not overfit. Hope you like it:),,56,9,Giacobako,2020-06-18 22:50:15,https://www.youtube.com/watch?v=Kih-VPHL3gA,0,deeplearning
ck65xj,Is it weird when a 14 year old publishes a paper ?,"Hi everyone, 

is it weird when a 14 year old wants to publish a paper ? I've been working on and with computers for 8 years or and I have been working on a lot of stuff in Machine Learning for 4 years now and wrote several models and algorithms. Now I am working on a Self Driving Car Simulator and I want to publish a paper on it. Is there anything wrong with it or can you recommend me something ? Or give me some tips",59,38,nowsden,2019-07-31 09:34:42,https://www.reddit.com/r/deeplearning/comments/ck65xj/is_it_weird_when_a_14_year_old_publishes_a_paper/,0,deeplearning
b8wfop,"Google open-sources GPipe, a library for efficiently training large deep neural networks",,57,1,techgig11,2019-04-03 10:55:11,https://venturebeat.com/2019/03/04/google-open-sources-gpipe-a-library-for-efficiently-training-deep-neural-networks/amp/,0,deeplearning
b3ozbm,NVIDIA Jetson Nano is a $99 Computer Built for AI,,57,12,jaja123789,2019-03-21 10:39:01,https://www.omgubuntu.co.uk/2019/03/nvidia-jetson-nano-99-computer-for-ai,0,deeplearning
7kdlv5,New YouTube channel on Deep Learning,Check out my new YouTube channel on Deep Learning (inspired by Siraj & Two Min Papers): https://youtu.be/McgxRxi2Jqo,60,7,tr1pzz,2017-12-17 12:47:06,https://www.reddit.com/r/deeplearning/comments/7kdlv5/new_youtube_channel_on_deep_learning/,0,deeplearning
pi59p7,Baby Action Detection Prototype - MediaPipe & LSTM [Github in Comments],,57,5,oFlamingo,2021-09-05 03:05:34,https://www.reddit.com/gallery/pi59p7,0,deeplearning
jepjyg,[R] Introduction to Continual Learning - Davide Abati (Link to free zoom lecture by the author in comments),,57,1,dataskml,2020-10-20 13:33:08,https://i.redd.it/3tdofxfd59u51.png,0,deeplearning
ja5sct,Understanding Deep Learning Theory Papers,"Could you recommend a good textbook or source that will help engineering majors (like me) understand deep learning theory papers?

I know somewhat about Bayesian inference, MLE/MAP, basics of Monte Carglo estimation of expectation, that we are trying to learn ‚Äúgood‚Äù representations, and also multivariate calculus.

Yet, when I meet terms such as point estimates, Lipschitz smoothness, universality, or Riemann manifolds, I need to consult Wikipedia, which often talks such gibberish that I am left thinking ‚ÄúI‚Äôd rather study a textbook than crawl through this‚Äù.

Thanks!",54,19,jaywonchung,2020-10-13 03:35:34,https://www.reddit.com/r/deeplearning/comments/ja5sct/understanding_deep_learning_theory_papers/,0,deeplearning
e9qic4,[Project] I created 3D reconstruction using single X-ray image for Pediatric Orthodontics applications,,57,11,coolwulf,2019-12-12 17:20:09,https://i.redd.it/94343o5ig8441.gif,0,deeplearning
c2f8df,Interviewing for Google AI Residency: My ML Journey,"Hi Everyone! 

The title really says it, I recently made it to the final rounds of the Google AI Residency interviews. This post describes my journey and experience:

&#x200B;

Link to post: [https://medium.com/@init\_27/interviewing-for-google-ai-residency-a-kaggle-gold-finish-dsnet-launch-c621930b043d](https://medium.com/@init_27/interviewing-for-google-ai-residency-a-kaggle-gold-finish-dsnet-launch-c621930b043d)",56,3,init__27,2019-06-19 10:10:30,https://www.reddit.com/r/deeplearning/comments/c2f8df/interviewing_for_google_ai_residency_my_ml_journey/,0,deeplearning
10ikg25,Editing an Image with Visuali AI Editor,,58,1,aigeneration,2023-01-22 14:07:33,https://v.redd.it/o8aenyr8ufda1,0,deeplearning
y9w2li,Generate high-quality 3D textured meshes with GET3D model,,58,3,imapurplemango,2022-10-21 15:05:28,https://v.redd.it/puyr9ekac6v91,0,deeplearning
wv1lbv,Huggingface has published a Stable Diffusion model,,58,8,roycoding,2022-08-22 18:41:57,https://huggingface.co/blog/stable_diffusion,0,deeplearning
uwhvl3,Google Brain's new model Imagen is even more impressive than Dall-E 2!,,55,7,OnlyProggingForFun,2022-05-24 03:41:48,https://youtu.be/qhtYPhPWCsI,0,deeplearning
s9w2jh,Documentation generated using Codex,,57,7,infinitlybana,2022-01-22 06:26:10,https://v.redd.it/xfqje77pn6d81,0,deeplearning
qsbln9,When does k-Means clustering fail? Just take 2 bananas!,,57,10,Va_Linor,2021-11-12 13:51:25,https://v.redd.it/h2keejc966z71,0,deeplearning
qd2j4y,Deepfaking Genitalia Into Blurred Porn Leads to Man's Arrest in Japan,"[https://www.gizmodo.com.au/2021/10/deepfaking-genitalia-into-blurred-porn-leads-to-mans-arrest-in-japan/](https://www.gizmodo.com.au/2021/10/deepfaking-genitalia-into-blurred-porn-leads-to-mans-arrest-in-japan/)

If you want to try out the neural network yourself, you can check out my fork of the code: [https://github.com/tom-doerr/TecoGAN-Docker](https://github.com/tom-doerr/TecoGAN-Docker)

The fork adds a docker environment, which makes it much easier to get the code running.",54,4,tomd_96,2021-10-21 22:01:05,https://www.reddit.com/r/deeplearning/comments/qd2j4y/deepfaking_genitalia_into_blurred_porn_leads_to/,0,deeplearning
mz1v2c,[R] Google and UC Berkeley Propose Green Strategies for Large Neural Network Training,"A research team from Google and the University of California, Berkeley calculates the energy use and carbon footprint of large-scale models T5, Meena, GShard, Switch Transformer and GPT-3, and identifies methods and publication guidelines that could help reduce their CO2e footprint.

Here is a quick read: [Google and UC Berkeley Propose Green Strategies for Large Neural Network Training](https://syncedreview.com/2021/04/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-5/).

The paper *Carbon Emissions and Large Neural Network Training* is on [arXiv](https://arxiv.org/ftp/arxiv/papers/2104/2104.10350.pdf).",58,1,Yuqing7,2021-04-26 16:38:23,https://www.reddit.com/r/deeplearning/comments/mz1v2c/r_google_and_uc_berkeley_propose_green_strategies/,0,deeplearning
j1hq38,AI removes any object in the video.,,56,8,Independent-Square32,2020-09-28 18:29:18,https://youtu.be/kN6R9S-R_CQ,0,deeplearning
ichz5i,Now AI generates Python Code,,58,10,Independent-Square32,2020-08-19 05:45:36,https://youtu.be/obhzvcNfptE,0,deeplearning
hzdthe,GPT-3 writes my SQL queries for me,,56,5,Independent-Square32,2020-07-28 12:31:26,https://youtu.be/WlMHYEFt2uA,0,deeplearning
fuuyfs,Augmented Reality + AI,,53,2,cmillionaire9,2020-04-04 14:51:28,https://youtu.be/6bTzsBFnGOg,0,deeplearning
elg73a,Invisible AI keyboard,,54,2,cmillionaire9,2020-01-07 19:19:03,https://youtu.be/Y-HmL1pFxXI,0,deeplearning
bw74nd,CS 294-112. Deep Reinforcement Learning by Sergey Levine. UC Berkeley. Fall 2018,"**Video Lectures:** https://www.youtube.com/playlist?list=PLkFD6\_40KJIxJMR-j5A1mkxK26gh\_qg37

**Lecture Slides:** http://rail.eecs.berkeley.edu/deeprlcourse/ 

&#x200B;

https://preview.redd.it/njnwdbkxv2231.png?width=944&format=png&auto=webp&s=2df0e994065f02e65eb6b6ce821a28d784838817",54,1,ai-lover,2019-06-03 05:35:32,https://www.reddit.com/r/deeplearning/comments/bw74nd/cs_294112_deep_reinforcement_learning_by_sergey/,0,deeplearning
a5thdm,Try run super-fast deep learning inference on Raspberry Pi in your hand!,,57,4,9_ties,2018-12-13 13:26:59,https://v.redd.it/wkucl4frwx321,0,deeplearning
xlb8z8,Gotta Catch ‚ÄòEm All: Fine Tuning Stable Diffusion to Make Pokemon,,56,1,mippie_moe,2022-09-22 19:46:05,https://i.redd.it/yx3xntdyrgp91.png,0,deeplearning
wwflc8,I made an Image classifier that tells if something's huggable or not? (links in comments),,54,4,None,2022-08-24 10:09:38,https://www.reddit.com/gallery/wwflc8,0,deeplearning
ohqefp,Cornell and Harvard University Researchers Develops Correlation Convolutional Neural Networks (CCNN): To Determine Which Correlations Are Most Important,"A team of researchers from Cornell and Harvard University introduces a novel approach to parse quantum matter and make crucial data distinctions. This proposed technique will enable researchers to decipher the most perplexing phenomena in the subatomic realm.

In their paper, ‚ÄúCorrelator Convolutional Neural Networks as an Interpretable Architecture for Image-like Quantum Matter Data,‚Äù the team discusses ways to extract new information about quantum systems from snapshots of image-like data. They are now thus developing ML tools to identify relationships between microscopic properties in data that would otherwise be impossible to determine at that scale.

Summary: [https://www.marktechpost.com/2021/07/10/cornell-and-harvard-university-researchers-develops-correlation-convolutional-neural-networks-ccnn-to-determine-which-correlations-are-most-important/](https://www.marktechpost.com/2021/07/10/cornell-and-harvard-university-researchers-develops-correlation-convolutional-neural-networks-ccnn-to-determine-which-correlations-are-most-important/) 

Paper: https://www.nature.com/articles/s41467-021-23952-w.pdf",52,0,techsucker,2021-07-10 20:37:24,https://www.reddit.com/r/deeplearning/comments/ohqefp/cornell_and_harvard_university_researchers/,0,deeplearning
o67mo5,This feels like a dream!! GAN is indeed most fascinating discovery,,56,4,None,2021-06-23 07:02:48,https://youtu.be/udPY5rQVoW0,0,deeplearning
nbjtgv,[R] DeepMind Presents Neural Algorithmic Reasoning: The Art of Fusing Neural Networks With Algorithmic Computation,"A research team from DeepMind explores how neural networks can be fused with algorithmic computation and demonstrates an elegant neural end-to-end pipeline that goes straight from raw inputs to general outputs while emulating an algorithm internally.

Here is a quick read: [DeepMind Presents Neural Algorithmic Reasoning: The Art of Fusing Neural Networks With Algorithmic Computation.](https://syncedreview.com/2021/05/13/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-18/)

 The paper *Neural Algorithmic Reasoning* is on [arXiv](https://arxiv.org/pdf/2105.02761.pdf).",54,1,Yuqing7,2021-05-13 15:52:11,https://www.reddit.com/r/deeplearning/comments/nbjtgv/r_deepmind_presents_neural_algorithmic_reasoning/,0,deeplearning
isqjgd,"RTX 3090, 3080, and 3070 Deep Learning Workstation Guide",,54,41,mippie_moe,2020-09-14 18:15:16,https://lambdalabs.com/blog/deep-learning-hardware-deep-dive-rtx-30xx/,0,deeplearning
irznyg,"[P] Open-sourcing ""beginner-friendly"" PyTorch GANs repo (DCGAN, cGAN, vGAN for now)",,53,13,gordicaleksa,2020-09-13 14:56:25,https://i.redd.it/lgo2nj3mixm51.gif,0,deeplearning
ijvslr,PyTorch Performance Tuning Guide,,54,1,Dawny33,2020-08-31 10:51:31,https://www.youtube.com/watch?v=9mS1fIYj1So&feature=youtu.be,0,deeplearning
h7ooxe,"NASA JPL lets anyone annotate Mars rover images to enable deep learning in space. This dataset will be publicly available, becoming the first benchmark for planetary navigation algorithms",,55,3,tango_delta_nominal,2020-06-12 17:06:16,https://www.zooniverse.org/projects/hiro-ono/ai4mars,0,deeplearning
edtn7l,#AI makes us more creative with Mix-and-Match Image Generation,,55,2,cmillionaire9,2019-12-21 18:48:26,https://youtu.be/Zt7YsgUOOPA,0,deeplearning
ci1er6,DeepSORT: Deep Learning to Track Custom Objects in a Video,"Object Detection has seen several recent developments and reached a wide audience but a very important and not widely known extension of the OD is its applications in Object Tracking.

Here is the blog about the theory and challenges in object tracking, how to use pre-trained object detection models to identify and count unique objects and track their trajectories over several frames using the #DeepSORT algorithm! - [https://nanonets.com/blog/object-tracking-deepsort/](https://nanonets.com/blog/object-tracking-deepsort/)

&#x200B;

&#x200B;

[Object tracking using deep learning](https://i.redd.it/fx5fa9jtpmc31.gif)",55,1,manneshiva,2019-07-26 10:58:24,https://www.reddit.com/r/deeplearning/comments/ci1er6/deepsort_deep_learning_to_track_custom_objects_in/,0,deeplearning
bpe4xo,"Google AI yesterday released its latest research result in speech-to-speech translation, the futuristic-sounding ‚ÄúTranslatotron‚Äù",,54,4,Yuqing7,2019-05-16 15:43:31,https://medium.com/syncedreview/google-ai-translatotron-can-make-anyone-a-real-time-polyglot-e7b6d616f5d2,0,deeplearning
ahbid2,Deep Learning State of the Art (2019) - MIT,,55,2,keghn,2019-01-18 15:24:15,https://www.youtube.com/watch?v=53YvP6gdD7U,0,deeplearning
9c0xpa,Demo: Accelerate Deep Learning Inference on Raspberry Pi (2018 ver.),,54,5,9_ties,2018-09-01 06:17:26,https://www.youtube.com/watch?v=DyR183n0ZXA,0,deeplearning
1awqbsw,Context lengths are now longer than the number of words spoken by a person in a year.,,53,11,rhypple,2024-02-21 23:02:27,https://i.redd.it/ycwtkcl0k0kc1.png,0,deeplearning
10zytb0,from a deepfake project i am working on the target is to transform every actor who played into abraham lincoln into abraham lincoln using deepfake,,51,4,Subject-Cream6001,2023-02-11 21:44:30,https://v.redd.it/abb54y6hkmha1,0,deeplearning
kl6hze,"Explainable, Adaptive, and Cross-Domain Few-Shot Learning - Dr. Leonid Karlinsky (ECCV2020 + AAAI2021) - Link to free zoom lecture by the author in comments",,52,1,dataskml,2020-12-27 16:32:31,https://i.redd.it/ihryymwhbr761.png,0,deeplearning
ke67h8,"Deep Internal Learning - train a signal-specific network, at test-time and on the test-input - Link to zoom lecture by author of 4 papers in comments",,54,1,dataskml,2020-12-16 09:35:47,https://www.reddit.com/gallery/ke67h8,0,deeplearning
k23qxy,"Happy Cakeday, r/deeplearning! Today you're 9","Let's look back at some memorable moments and interesting insights from last year.

**Your top 10 posts:**

* ""[Training Deep NN be like](https://www.reddit.com/r/deeplearning/comments/jrkw6i)"" by [u/alexein777](https://www.reddit.com/user/alexein777)
* ""[Taking code from GitHub and running on your data](https://www.reddit.com/r/deeplearning/comments/gfpdsc)"" by [u/noidiz](https://www.reddit.com/user/noidiz)
* ""[Exploring MNIST Latent Space](https://www.reddit.com/r/deeplearning/comments/jkci6f)"" by [u/goatman12341](https://www.reddit.com/user/goatman12341)
* ""[Holy crap! Some guy shouted ‚ÄúMachine learning is just statistics!‚Äù and then this happened](https://www.reddit.com/r/deeplearning/comments/ipfe2l)"" by [u/lordcris](https://www.reddit.com/user/lordcris)
* ""[I work with models](https://www.reddit.com/r/deeplearning/comments/jwempm)"" by [u/goncaloperes](https://www.reddit.com/user/goncaloperes)
* ""[The merits of having many monitors](https://www.reddit.com/r/deeplearning/comments/g45qwn)"" by [u/abdeljalil73](https://www.reddit.com/user/abdeljalil73)
* ""[The truth üíØ! üòÇ](https://www.reddit.com/r/deeplearning/comments/hu6c0d)"" by [u/aymenSekhri](https://www.reddit.com/user/aymenSekhri)
* ""[GANs](https://www.reddit.com/r/deeplearning/comments/j5n787)"" by [u/prathamesh3099](https://www.reddit.com/user/prathamesh3099)
* ""[Google datasets search](https://www.reddit.com/r/deeplearning/comments/etlds7)"" by [u/theroyakash](https://www.reddit.com/user/theroyakash)
* ""[signal/noise ratio](https://www.reddit.com/r/deeplearning/comments/i3agkp)"" by [u/redmoon\_reddit](https://www.reddit.com/user/redmoon_reddit)",57,0,AutoModerator,2020-11-27 16:00:15,https://www.reddit.com/r/deeplearning/comments/k23qxy/happy_cakeday_rdeeplearning_today_youre_9/,0,deeplearning
j8jfjn,DeepFakes in 5 minutes. Understand how deepfakes work and create your own!,,53,2,OnlyProggingForFun,2020-10-10 12:13:16,https://youtu.be/Upv0kMLx7xI,0,deeplearning
ib70mq,Is deep learning for stock prediction a huge scam?,"The insane amount of papers and articles regarding people using LSTMs, GRUs, CNNs and whatnot for predicting stock prices is driving me mad. At the end of the day all their fancy models just replicate the previous day values. Some papers just conclude with having better RMSE (or some other metric) and don't even bother to acknowledge that their models mean shit when the goal was having a prediction model. Is their anyone out there who can share a decent implementation where there's some sort of trend prediction being done?",52,36,TheDecisiveJEDI,2020-08-17 03:58:05,https://www.reddit.com/r/deeplearning/comments/ib70mq/is_deep_learning_for_stock_prediction_a_huge_scam/,0,deeplearning
hcwikc,CVPR 2020 highlights & some paper summaries (blog post),"The first virtual CVPR conference ended, with 1467 papers accepted, 29 tutorials, 64 workshops, and 7.6k virtual attendees. The huge number of papers and the new virtual version made navigating the conference overwhelming (and very slow) at times. To get a grasp of the general trends of the conference this year, I wrote a blog post where I summarize some papers (& list some) that grabbed my attention. Check it out!

Blog post: https://yassouali.github.io/ml-blog/cvpr2020/

CVPR 2020 papers: http://openaccess.thecvf.com/CVPR2020.py",53,5,youali,2020-06-20 23:48:54,https://www.reddit.com/r/deeplearning/comments/hcwikc/cvpr_2020_highlights_some_paper_summaries_blog/,0,deeplearning
exch5o,Congrats! Web scraping is legal! (US precedent),"Disputes about whether web scraping is legal have been going on for a long time. And now, a couple of months ago, the scandalous case of web scraping between hiQ v. LinkedIn was completed.

You can read about the progress of the case here: [US court fully legalized website scraping and technically prohibited it.](https://parsers.me/us-court-fully-legalized-website-scraping-and-technically-prohibited-it/)

Finally, the court concludes: ""Giving companies like LinkedIn the freedom to decide who can collect and use data ‚Äì data that companies do not own, that is publicly available to everyone, and that these companies themselves collect and use ‚Äì creates a risk of information monopolies that will violate the public interest‚Äù.",52,7,Gill_Chloet,2020-02-01 20:56:21,https://www.reddit.com/r/deeplearning/comments/exch5o/congrats_web_scraping_is_legal_us_precedent/,0,deeplearning
dmwa91,"[R] Netflix just open-sourced Polynote, a cool Machine Learning, and Data Science workflow tool"," Netflix just open-sourced Polynote, a cool Machine Learning, and Data Science workflow tool

Polynote Website: https://polynote.org/

Github:¬†https://github.com/polynote/polynote?fbclid=IwAR1bF4fcoe7R0rqZIrIeV7c5pYTPprMBzhqsmpEgliOGkf4iJ8I6CNuha\_8",52,7,cdossman,2019-10-25 11:46:41,https://www.reddit.com/r/deeplearning/comments/dmwa91/r_netflix_just_opensourced_polynote_a_cool/,0,deeplearning
d8sx8g,Introduction to Reinforcement Learning - Chapter 1 Explained!,[https://youtu.be/4SLGEq\_HZxk](https://youtu.be/4SLGEq_HZxk),49,13,HenryAILabs,2019-09-24 20:28:06,https://www.reddit.com/r/deeplearning/comments/d8sx8g/introduction_to_reinforcement_learning_chapter_1/,0,deeplearning
cmq4ko,"PyTorch Implementation of various Semantic Segmentation models (deeplabV3+, PSPNet, Unet, ...)","To get a handle of semantic segmentation methods, I re-implemented some well known models with a clear structured code (following this [PyTorch template](https://github.com/victoresque/pytorch-template)), in particularly:

- The implemented models are: Deeplab V3+ - GCN - PSPnet - Unet - Segnet and FCN

- Supported datasets: Pascal Voc, Cityscapes, ADE20K, COCO stuff,

- Losses: Dice-Loss, CE Dice loss, Focal Loss and Lovasz Softmax,

with various data augmentations and learning rate schedulers (poly learning rate and one cycle).

I though I share this implementation in case anyone might be interested, and here it is :

**Github**: https://github.com/yassouali/pytorch_segmentation",49,8,youali,2019-08-06 12:45:42,https://www.reddit.com/r/deeplearning/comments/cmq4ko/pytorch_implementation_of_various_semantic/,0,deeplearning
aaghfi,First Titan RTX Benchmarks for Deep Learning ‚Äî Titan RTX vs. V100 vs. 2080 Ti vs. 1080 Ti vs. Titan V vs. Titan Xp TensorFlow Performance,,54,1,mippie_moe,2018-12-29 01:12:02,https://lambdalabs.com/blog/titan-rtx-tensorflow-benchmarks/,0,deeplearning
8vdgx5,"I made a labelling tool to annotate very long and repetitive videos. It shows several clips on screen simultaneously in loop, it's called MuViLab. What do you think?",,54,18,ale152,2018-07-01 22:02:39,https://i.redd.it/l7giel5wse711.gif,0,deeplearning
13s8e6h,Building a 3 layered neural network from scratch using only NumPy https://youtu.be/w7Hn3jmbj1A for full video see the comment section,,53,4,Play-Equal,2023-05-26 09:35:36,https://v.redd.it/fvf4ka4qs62b1,0,deeplearning
12zclny,"Google researchers achieve performance breakthrough, rendering Stable Diffusion images in sub-12 seconds on a mobile phone. Generative AI models running on your mobile phone is nearing reality.","**What's important to know:**

&#x200B;

*  Stable Diffusion is an \\\~1-billion parameter model that is typically resource intensive. DALL-E sits at 3.5B parameters, so there are even heavier models out there.
*  Researchers at Google layered in a series of four GPU optimizations to enable Stable Diffusion 1.4 to run on a Samsung phone and generate images in under 12 seconds. RAM usage was also reduced heavily.
* **Their breakthrough isn't device-specific; rather it's a generalized approach that can add improvements to all latent diffusion models.** Overall image generation time decreased by 52% and 33% on a Samsung S23 Ultra and an iPhone 14 Pro, respectively.
*  Running generative AI locally on a phone, without a data connection or a cloud server, opens up a host of possibilities. This is just an example of how rapidly this space is moving as Stable Diffusion only just released last fall, and in its initial versions was slow to run on a hefty RTX 3080 desktop GPU.

&#x200B;

As small form-factor devices can run their own generative AI models, what does that mean for the future of computing? Some very exciting applications could be possible.

&#x200B;

If you're curious, the paper (very technical) [can be accessed here.](https://arxiv.org/abs/2304.11267)",52,3,Lewenhart87,2023-04-26 09:55:48,https://www.reddit.com/r/deeplearning/comments/12zclny/google_researchers_achieve_performance/,0,deeplearning
n2j2aw,Infinite Nature: Fly into an image and explore it like a bird!,,52,4,OnlyProggingForFun,2021-05-01 14:09:35,https://youtu.be/NIOt1HLV_Mo,0,deeplearning
lochk8,AI lets you talk to NPCs,,52,5,cmillionaire9,2021-02-20 17:52:40,https://youtu.be/xptRECNsZAs,0,deeplearning
ljjd4d,Are people hiding their deep learning code?,"I noticed that there is absolutely nowhere in the internet where I can find a complete training procedure for imagenet (say, a jupyter notebook), with learning rate values and such. Every code sample uses the hyperparameters as command line arguments. This reminds me of what happens in finance, where a paper is published but certain parameters are kept a secret. What is going on? Are people so secretive of their code in the deep learning community?",52,29,None,2021-02-14 06:45:25,https://www.reddit.com/r/deeplearning/comments/ljjd4d/are_people_hiding_their_deep_learning_code/,0,deeplearning
kztphu,How Does Tier IV Robot Taxi See Tokyo?,,55,4,cmillionaire9,2021-01-18 12:25:34,https://youtu.be/MoYZHJ81FbM,0,deeplearning
jsx7lj,Removing objects from videos with deep learning (FGVC 2020 Facebook Research),,52,4,None,2020-11-12 16:04:33,https://youtu.be/uuDHNmdOEA0,0,deeplearning
ifgidf,How the softmax function transforms the input space (the logit space) visualized in 3D,,51,7,elliotwaite,2020-08-24 02:23:38,https://youtu.be/ytbYRIN0N4g,0,deeplearning
gdfp43,What to do after Andrew Ng's Deep Learning Specialization ?,"I have finished the Deep Learning Specialization on Coursera during this quarantine period. I have done some projects before, using Keras, mainly on text data. But I don't  feel confident enough to write low level Tensorflow code or Pytorch code on my own. I feel I don't know enough about Neural Networks still. How to improve my proficiency ?",51,26,rahulseetharaman,2020-05-04 17:16:40,https://www.reddit.com/r/deeplearning/comments/gdfp43/what_to_do_after_andrew_ngs_deep_learning/,0,deeplearning
cjvwug,I Placed 4th in my First AI Competition. Read my write up of my agent on Unity's ObstacleTower AI Challenge.,,50,4,soho-joe,2019-07-30 18:29:09,https://i.redd.it/5720x7l5chd31.gif,0,deeplearning
aiscld,"Geoffrey HintonÔºö I eventually got a Ph.D. in AI, and then I couldn't get a job in Britain.","&#x200B;

[ ](https://preview.redd.it/kfx6krfdu1c21.png?width=1161&format=png&auto=webp&s=3b0a47786d082f5a1ca7337d3a38a90b6eb9c992)

#### Geoffrey Hinton interview by NG

[ ](https://www.coursera.org/learn/neural-networks-deep-learning/discussions/weeks/1)",50,20,alexchauncy,2019-01-22 22:18:54,https://www.reddit.com/r/deeplearning/comments/aiscld/geoffrey_hinton_i_eventually_got_a_phd_in_ai_and/,0,deeplearning
1048oc1,Greg Yang's work on a rigorous mathematical theory for neural networks,"Greg Yang is a mathematician and AI researcher at Microsoft Research who for the past several years has done incredibly original theoretical work in the understanding of large artificial neural networks. In our whiteboard conversation, we get a sample of Greg's work, which goes under the name ""Tensor Programs"" and currently spans five highly technical papers. The route chosen to compress Tensor Programs into the scope of a conversational video is to place its main concepts under the umbrella of one larger, central, and time-tested idea: that of taking a large N limit. This occurs most famously in the Law of Large Numbers and the Central Limit Theorem, which then play a fundamental role in the branch of mathematics known as Random Matrix Theory (RMT). We review this foundational material and then show how Tensor Programs (TP) generalizes this classical work, offering new proofs of RMT.

We conclude with the applications of Tensor Programs to a (rare!) rigorous theory of neural networks. This includes applications to a rigorous proof for the existence of the Neural Network Gaussian Process and Neural Tangent Kernel for a general class of architectures, the existence of infinite-width feature learning limits, and the muP parameterization enabling hyperparameter transfer from smaller to larger networks.

&#x200B;

https://preview.redd.it/y79bih0f7aaa1.png?width=1280&format=png&auto=webp&s=7cf2bde3408e58f3d7dd6e15fbcd3dc103404147

https://preview.redd.it/0hvembyf7aaa1.png?width=1200&format=png&auto=webp&s=9a9889d47630e6c12cd4d192750c63d2bff1e422

Youtube: [https://youtu.be/1aXOXHA7Jcw](https://youtu.be/1aXOXHA7Jcw)

Apple Podcasts: [https://podcasts.apple.com/us/podcast/the-cartesian-cafe/id1637353704](https://podcasts.apple.com/us/podcast/the-cartesian-cafe/id1637353704)

Spotify: [https://open.spotify.com/show/1X5asAByNhNr996ZsGGICG](https://open.spotify.com/show/1X5asAByNhNr996ZsGGICG)

RSS: [https://feed.podbean.com/cartesiancafe/feed.xml](https://feed.podbean.com/cartesiancafe/feed.xml)",51,3,IamTimNguyen,2023-01-05 20:07:38,https://www.reddit.com/r/deeplearning/comments/1048oc1/greg_yangs_work_on_a_rigorous_mathematical_theory/,0,deeplearning
whwgtk,"Gaugan2 has captured a lot of interest. So, I wanted to look into the first version. This is how it turned out.",Here is the link to the repo https://github.com/Shreyz-max/Doodle-to-Image-Generator,51,2,Shreya001,2022-08-06 19:42:16,https://v.redd.it/8uu4wx8gc5g91,0,deeplearning
ucg0pw,arcane style transfer as a python web app,,50,1,Illustrious_Row_9971,2022-04-26 16:05:16,https://i.redd.it/zz20kg5hcwv81.png,0,deeplearning
s6sqrm,I trained every single computer vision SOTA from 2021 and accidentally got a silver medal on Kaggle (Code Inside),"![](https://i.ibb.co/gwpJXBm/lb.png)


I trained every single SOTA model from 2021 and accidentally got a silver medal on an image classification competition on Kaggle recently (Pawpularity Contest). 

> [Here](https://www.kaggle.com/yamqwe/the-nuclear-option-train) If you are interested

The idea was to train every SOTA and then **Nuke the leaderboard with 10 Billion parameters** ensemble of ensembles. 
Some ensembles were also supplemented a bit with catboost 2nd stage model just for the ""why not"". 

**Outline of the approach: https://i.ibb.co/McJ39mW/image-nuke.png**

This stunt was done mainly for the purpose me catching up with the current most recent SOTA vision papers. 

I seriously didn't try to compete on the leaderboard and never had the intention of releasing a public notebook that actually gets a silver medal. 
This came as a complete surprise to me! 
Hope the solution will be useful for many others in the future.

If you got any questions or feedback, I'll be more than happy to discuss!",53,4,yamqwe,2022-01-18 08:31:25,https://www.reddit.com/r/deeplearning/comments/s6sqrm/i_trained_every_single_computer_vision_sota_from/,0,deeplearning
olm3od,For all the machine/deep learning guys and gals: WSL full CUDA on W11 confirmed,,52,1,MountainGoatAOE,2021-07-16 17:51:29,/r/LinusTechTips/comments/okzy8h/for_all_the_machinedeep_learning_guys_and_gals/,0,deeplearning
o9mjsu,I made a graph neural network specifically for graphs with community structure,,51,12,jsonathan,2021-06-28 15:27:06,https://i.redd.it/0tzpqazky0871.png,0,deeplearning
nsggai,High-resolution depth estimation from a single image,,50,13,cmillionaire9,2021-06-04 21:49:28,https://youtu.be/QSxfb-GC0U4,0,deeplearning
jtvujx,Affordable DL Box even back in 2018: (S1070+4xK20 < $500).,,52,19,akhen4ten,2020-11-14 04:33:40,https://i.redd.it/z1a74652w4z51.jpg,0,deeplearning
fdxval,Revolutionary AI Algorithm Speeds Up Deep Learning on CPUs,,51,15,chillinewman,2020-03-05 16:36:12,https://www.psychologytoday.com/us/blog/the-future-brain/202003/revolutionary-ai-algorithm-speeds-deep-learning-cpus,0,deeplearning
f5wm6v,Apollo 16 | 60 FPS and 4K | Gigapixel AI,,52,2,cmillionaire9,2020-02-18 18:50:46,https://youtu.be/elykdWWv7nk,0,deeplearning
e8olbt,NeurIPS Conference talks are available online,"NeurIPS conference is flagship Artificial Intelligence conference currently being held at Canada. 

If anyone couldn't make it to @NeurIPSConf,  the talks are available online.

H/T Suzana Iliƒá 

#machinelearning #deeplearning #AI #neurips #neurips2019

https://slideslive.com/neurips#!feed=latest",52,0,aiforworld2,2019-12-10 09:43:41,https://www.reddit.com/r/deeplearning/comments/e8olbt/neurips_conference_talks_are_available_online/,0,deeplearning
ccc7hy,AI-Based Photo Restoration,,49,2,pvl18,2019-07-12 15:20:28,https://medium.com/@fedor.kitashov/ai-based-photo-restoration-6e41469ce0d7,0,deeplearning
am6vjj,Deep Learning Journal Club,"I am looking for people who would be interested in reading and discussing recent deep learning papers, one a week.

Being part of a journal club is a fast, efficient, way to stay up to date with current research, learn about exciting new applications, and have your technical questions answered.

Meeting new data-scientists is also a great way to learn different approaches to problems and get new ideas for projects!

I'd like to host the club on my site, [blackswans.io](https://blackswans.io), so we can easily write in LaTeX, share images and videos, etc. I'd also like to have Skype calls (with a few members of the club) every so often, to get to know each other better.

Feel free to make other suggestions!

Jack",48,16,jdyr1729,2019-02-01 21:13:42,https://www.reddit.com/r/deeplearning/comments/am6vjj/deep_learning_journal_club/,0,deeplearning
w0fp7z,[Research] BERT-Large: Prune Once for DistilBERT Inference Performance,,52,1,markurtz,2022-07-16 12:35:58,https://i.redd.it/3kp7qgl2dxb91.png,0,deeplearning
oigdgg,"Adding guassian noise to Discriminator layers in GAN helps really stablizing training, generates sharper images and avoid mode collapse.","Very simple tweak which isn't usually seen in basic GAN tutorials. Might be helpful if you are new to GANs and it's just not converging.

[256x256px, results in 3 hours on colab.](https://preview.redd.it/zum8fg2xgoa71.png?width=901&format=png&auto=webp&s=64dd09e02f7c7418a698eab274026d273175211c)

I am also new to GANs and just learning. I first noticed this when learning about GANs last year in tensorflow. I followed the most basic tutorial from tf docs. But results were always smudgy, fuzzy and not convincing, and easily collapsing, especially at resolutions >= 128x128. But adding Gaussian noise to each layer of Discriminator dramatically made the results much better. Inspiration was from some ganhacks and papers adding noise to just the input or generator, but haven't seen results for discriminator.

Found similar results when implementing the same in Pytorch recently. Models with same architecture, config and seed. Only difference is adding of guassian noise to discriminator layers gives much better results. Have had success in training 128x128 and 256x256 face generation in just a few hours on colab.

Below are few results. Using very basic convolutional gan architecture.

[128x128 Results with guassian noise in discriminator layers on celeba](https://preview.redd.it/w6jmzssvgoa71.png?width=1782&format=png&auto=webp&s=94158edc0cf52b6dbe82eae176e49e3334d9fb82)

[128x128 Results without noise on celeba, easily collapsed.](https://preview.redd.it/uqsr8uvugoa71.png?width=1785&format=png&auto=webp&s=ce3dcdcece1893dec277e31eac1eb7734cd7da0d)

Also results on Flickr dataset 256x256 resolution in 3 hours.

[256x256 Flickr dataset with guassian noise in discriminator layers](https://preview.redd.it/vd72llwsgoa71.png?width=1782&format=png&auto=webp&s=8ce6240bf7b8e50e86ad81cc6af5a3e6d2400f99)

Ofcourse results aren't too crazy and still contain artifacts as this is a very basic architecture and trained for a short time. But not bad and much better as compared to without gaussian noise in discriminator.

More results runs and logs of runs with no noise, noise decay, adding noise to only generator layers, adding noise only to input, both generator and discriminator can be found here. Open different runs to see more outputs at different timesteps.: [https://wandb.ai/shivamshrirao/facegan\_pytorch](https://wandb.ai/shivamshrirao/facegan_pytorch)

View more 256px results [here](https://wandb.ai/shivamshrirao/facegan_pytorch/runs/1424g5hk).

Pytorch code: [https://github.com/ShivamShrirao/facegan\_pytorch](https://github.com/ShivamShrirao/facegan_pytorch)

Tensorflow code (bit old): [https://github.com/ShivamShrirao/GANs\_TF\_2.0](https://github.com/ShivamShrirao/GANs_TF_2.0)

[256x256px Flickr dataset](https://preview.redd.it/m8hxbzrqgoa71.png?width=901&format=png&auto=webp&s=24a4abde9496b96a93b7abf85f739d87335229fa)",50,8,0x00groot,2021-07-12 00:39:45,https://www.reddit.com/r/deeplearning/comments/oigdgg/adding_guassian_noise_to_discriminator_layers_in/,0,deeplearning
nk97lg,Roadmap/Resources for getting started with DL and Robotics. (Bonus: Research Paper notes repo also included),"I saw that some people here are new to DL and wants to get started with DL, CV, Robotics, etc. My team has curated a roadmap on how to study these topics. 

Do go through it and let me know how it is. If you feel anything is missing raise an issue. 

https://github.com/IvLabs/resources

We also have a collection of research paper notes in related fields. Do checkout at

https://github.com/IvLabs/ResearchPaperNotes

Do star these repo if you like it. We are inviting collaborators who can contribute to these repos as well. Through this we are trying to contribute to the open source community.",53,2,take2rohit,2021-05-24 21:41:57,https://www.reddit.com/r/deeplearning/comments/nk97lg/roadmapresources_for_getting_started_with_dl_and/,0,deeplearning
k3zvie,[Article] Beginner's Guide to Quantum Machine Learning,"Quantum machine learning explores the application of quantum computing in the fields of ML and DL. This article introduces beginners to the topic, covering the following concepts: 

1. A comparison of classical programming, machine learning, and quantum machine learning paradigms 
2. The fundamental concepts of quantum computing
3. How quantum computing can improve machine learning

Full article (no paywall): [https://blog.paperspace.com/beginners-guide-to-quantum-machine-learning/](https://blog.paperspace.com/beginners-guide-to-quantum-machine-learning/)",50,5,hellopaperspace,2020-11-30 17:03:32,https://www.reddit.com/r/deeplearning/comments/k3zvie/article_beginners_guide_to_quantum_machine/,0,deeplearning
i1f11z,I trained a GAN to generate photorealistic fake penises,,50,7,DicksDontExist,2020-07-31 20:34:23,/r/MachineLearning/comments/i1aafb/p_i_trained_a_gan_to_generate_photorealistic_fake/,0,deeplearning
h91e42,[D] Facebook and Kaggle Face Backlash After Disqualifying Apparent ‚ÄòDeepfake Detection Challenge‚Äô Winner,"Facebook and Kaggle are facing an online backlash after the apparent winners of the Deepfake Detection Challenge (DFDC) were disqualified. Facebook launched the competition last year to encourage the development of new technologies to detect deepfakes and manipulated media, and there were more than 2,000 entries were submitted. The data science and machine learning community site Kaggle hosted the DFDC challenge and leaderboard. 

Here is a quick read:  [Facebook and Kaggle Face Backlash After Disqualifying Apparent ‚ÄòDeepfake Detection Challenge‚Äô Winner](https://syncedreview.com/2020/06/14/facebook-and-kaggle-face-backlash-after-disqualifying-apparent-deepfake-detection-challenge-winner/)",51,4,Yuqing7,2020-06-14 20:45:32,https://www.reddit.com/r/deeplearning/comments/h91e42/d_facebook_and_kaggle_face_backlash_after/,0,deeplearning
emedd1,Object detection and segmentation with amazing accuracy and is blazing fast,,51,7,cmillionaire9,2020-01-09 19:14:35,https://youtu.be/qsgfgj0CpFc,0,deeplearning
dap88w,I've been working on using AI to make music and videos and whatnot. Anyone else into this sort of thing?,,49,32,poingly,2019-09-29 02:08:10,https://youtu.be/gtldQRlsbTg,0,deeplearning
d6bwsm,Google to open AI lab in Bangalore,,50,0,adssidhu86,2019-09-19 10:07:59,https://www.blog.google/around-the-globe/google-asia/google-research-india-ai-lab-bangalore/amp/,0,deeplearning
c1c0q6,NVIDIA's AI that generates photorealistic images from your doodles is now in beta stage and open for all to try out,,50,4,azmodeus99,2019-06-16 16:50:21,https://techunalt.com/gaugan-turns-your-scribbles-into-beautiful-landscapes/,0,deeplearning
bbpikl,Small budget system for data scientists | I will be posting the building guide soon,,48,20,gimel1213,2019-04-10 18:28:55,https://i.redd.it/esinxjeqchr21.jpg,0,deeplearning
1b6ifas,I am heartbroken üíî. Random Forest classifier beat Transformer Encoder classifier by about 2.5% ,"I wanted to learn the transformer from scratch. So I decided to try on a Twitter sentiment classification problem on Kaggle. 

I have been working on it for the last 2 3 weeks. Using the transformer encoder I got training accuracy of about 97% and validation accuracy of Max 95.45%. 

The dataset was big enough and I was overly optimistic. I thought maybe I could get an accuracy of more than 98% on both training and validation. 

Turns out someone tried random forest and got a validation accuracy of 98%. 
This broke my heart a little bit. 

I don't know if it is even now worth trying to improve the accuracy and get beyond 98%. I mean transformer does all these complicated things, but something more simpler performs better. 

But I want to try couple of things. I was using dimension of 128. I will see if by increasing it if I can improve. 

Second. I would like to receive some guidance from you guys. The maximum sequence length of the input text is 311. I didn't truncate it. Instead I made all the sentences match a sequence length to 311. I think I should explore more over here. 

Third. Maybe try glove embeddings and see if I makes any improvement. 

Thanks for listening. 

Edit: but I feel happy that the encoder outperformed the other ml algorithms and lstms by a big margin. ",51,26,mono1110,2024-03-04 18:35:05,https://www.reddit.com/r/deeplearning/comments/1b6ifas/i_am_heartbroken_random_forest_classifier_beat/,0,deeplearning
o221ax,GPEN - Restores Extremely Degraded Faces That Is Previously Impossible,,47,7,cloud_weather,2021-06-17 17:00:55,https://youtu.be/ZzCDFA328-Q,0,deeplearning
nj4ke2,StyleGAN2 implementation with side-by-side notes,"Implemented StyleGAN2 model and training loop from paper ""Analyzing and Improving the Image Quality of StyleGAN"".

Code with annotations: [https://nn.labml.ai/gan/stylegan/index.html](https://nn.labml.ai/gan/stylegan/index.html)

This is a minimalistic implementation with only 425 lines of code and lots of documentations and diagrams explaining the model.

&#x200B;

* [Github](https://github.com/lab-ml/annotated_deep_learning_paper_implementations/tree/master/labml_nn/gan/stylegan)
* [Paper on arXiv](https://arxiv.org/abs/1912.04958)
* [Twitter Thread](https://twitter.com/labmlai/status/1396298504872423425)",49,3,mlvpj,2021-05-23 09:53:13,https://www.reddit.com/r/deeplearning/comments/nj4ke2/stylegan2_implementation_with_sidebyside_notes/,0,deeplearning
ms95ib,AI turns Minecraft into a realistic world !,,46,4,cmillionaire9,2021-04-16 18:18:11,https://youtu.be/8-qU5_ozTu4,0,deeplearning
lzrrfq,michigan-deep-learning-for-computer-vision-2020,,46,6,greakvally,2021-03-07 14:31:09,https://i.redd.it/gzdqc4wm9ml61.png,0,deeplearning
ka050t,[R] This Pizza Does Not Exist: StyleGAN2-Based Model Generates Photo-Realistic Pizza Images,"If your love of pizza is as strong as your imagination, you may want to check out the new AI-powered Multi-Ingredient Pizza Generator (MPG), which can deliver all these mouth-watering pies and many more. There‚Äôs no guarantee of the flavour, though, as the fancy MPG ‚Äúpizzas‚Äù aren‚Äôt baked in an oven; rather they‚Äôre produced by a conditional Generative Adversarial Network (GAN) framework developed by researchers from Rutgers University and Samsung AI Center. Designed for synthesizing multi-label images, MPG combines a new conditioning technique with the StyleGAN2 structure to enforce intermediate feature maps to learn scalewise label information.

Here is a quick read: [This Pizza Does Not Exist: StyleGAN2-Based Model Generates Photo-Realistic Pizza Images](https://syncedreview.com/2020/12/09/this-pizza-does-not-exist-stylegan2-based-model-generates-photo-realistic-pizza-images/)

The team notes that ‚Äî while pizzas are certainly fun ‚Äî their framework can also be extended to other multi-label image generation scenarios. The paper *MPG: A Multi-ingredient Pizza Image Generator with Conditional StyleGANs* is on [arXiv](https://arxiv.org/pdf/2012.02821.pdf).",49,6,Yuqing7,2020-12-09 20:39:21,https://www.reddit.com/r/deeplearning/comments/ka050t/r_this_pizza_does_not_exist_stylegan2based_model/,0,deeplearning
jjrxl1,[R] Amazon‚Äôs BERT Optimal Subset: 7.9x Faster & 6.3x Smaller Than BERT,"In a new paper, a pair of Amazon Alexa researchers extract an optimal subset of architectural parameters for the BERT architecture by applying recent breakthroughs in algorithms for neural architecture search. The proposed optimal subset, ‚ÄúBort,‚Äù is just 5.5 percent the effective size of the original BERT-large architecture (not counting the embedding layer), and 16 percent of its net size.

Here is a quick read: [Amazon‚Äôs BERT Optimal Subset: 7.9x Faster & 6.3x Smaller Than BERT](https://syncedreview.com/2020/10/28/amazons-bert-optimal-subset-7-9x-faster-6-3x-smaller-than-bert/)

The paper *Optimal Subarchitecture Extraction For BERT* is on [arXiv](https://arxiv.org/pdf/2010.10499.pdf), and the code is on [GitHub](https://github.com/alexa/bort).",49,2,Yuqing7,2020-10-28 17:15:21,https://www.reddit.com/r/deeplearning/comments/jjrxl1/r_amazons_bert_optimal_subset_79x_faster_63x/,0,deeplearning
ivp8y0,Beginner-friendly ML projects for 2020 (By Current Microsoft Engineer - NOT an ex-Google engineer),,46,10,gordicaleksa,2020-09-19 09:13:10,https://youtu.be/yhhSYk9zt1w,0,deeplearning
hpeacn,"Now you can put stochastic differential equations in your deep learning models, and neural nets in your SDEs!",,50,1,PopescuG,2020-07-11 17:47:25,https://v.redd.it/6iy3krx9g9a51,0,deeplearning
gs9epp,Yolo implementation in keras and tensorflow 2.2 + Code GitHub,,49,7,cmillionaire9,2020-05-28 16:26:34,https://youtu.be/UeltL6WLU_g,0,deeplearning
fwsmnc,"Deep learning, old film enhancing [4K, 60fps, 3D] 1897 Lumiere brothers snowball fight.",,48,12,Rome_Os-Cousin,2020-04-07 21:02:00,https://youtu.be/GQMMDGd4ciA,0,deeplearning
fsw44n,AI Pushup Challenge,,50,0,cmillionaire9,2020-04-01 08:55:14,https://youtu.be/rX6D7tpiADY,0,deeplearning
fa8op5,5 Papers on CNNs Every Data Scientist Should Read,,48,0,LimarcAmbalina,2020-02-27 07:46:48,https://lionbridge.ai/articles/5-papers-on-cnns-every-data-scientist-should-read/,0,deeplearning
esewvx,Generate video from any given audio source,,49,3,cmillionaire9,2020-01-22 17:09:46,https://youtu.be/fHwKtgwElGU,0,deeplearning
d4l9nq,PyTorch implementation of 17 Deep RL algorithms,"For anyone trying to learn or practice RL, here's a repo with working PyTorch implementations of 17 RL algorithms including DQN, DQN-HER, Double DQN, REINFORCE, DDPG, DDPG-HER, PPO, SAC, SAC Discrete, A3C, A2C etc..

Let me know what you think!

[https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch](https://github.com/p-christ/Deep-Reinforcement-Learning-Algorithms-with-PyTorch)",48,2,__data_science__,2019-09-15 14:39:42,https://www.reddit.com/r/deeplearning/comments/d4l9nq/pytorch_implementation_of_17_deep_rl_algorithms/,0,deeplearning
cn7a87,Illustrated: 10 CNN Architectures,,48,1,raibosome,2019-08-07 15:32:27,https://towardsdatascience.com/illustrated-10-cnn-architectures-95d78ace614d,0,deeplearning
bv6utv,Udacity‚Äôs course on secure and private ML just launched (it‚Äôs free!),,47,0,None,2019-05-31 12:22:53,https://www.udacity.com/course/secure-and-private-ai--ud185,0,deeplearning
9lqtiu,Ultimate List of Youtube Channels for Deep Learning and Computer Vision,,52,3,codingwoman_,2018-10-05 22:10:45,http://www.codingwoman.com/youtube-channels-for-deep-learning-and-computer-vision/,0,deeplearning
9f4pwh,Multi-Person Pose Estimation (Python / C++),,53,3,spmallick,2018-09-12 04:42:31,https://v.redd.it/k1gn3zw7lql11,0,deeplearning
7z1fwd,CMU Deep Learning Course,"Carnegie Mellon's Deep Learning Course is being broadcasted for the first time this semester. So far we have had 9-10 lectures.
The class covers some topics that I haven't really seen in any other online course yet.

Lecturer: Bhiksha Raj

Channel link :https://www.youtube.com/channel/UC8hYZGEkI2dDO8scT8C5UQA/videos

Syllabus and Slides: http://deeplearning.cs.cmu.edu/",49,2,taurish,2018-02-21 01:12:12,https://www.reddit.com/r/deeplearning/comments/7z1fwd/cmu_deep_learning_course/,0,deeplearning
1auyt81,When ML/DL field wil become saturated if it is not already?,"Basically title. I think I joined this field too late and by the time I will be proficient enough, the market will become too saturated. And I feel like every CS/engineering student is learning and applying ML/DL. How justified are ny worries? ",49,14,mal_mal_mal,2024-02-19 21:11:32,https://www.reddit.com/r/deeplearning/comments/1auyt81/when_mldl_field_wil_become_saturated_if_it_is_not/,0,deeplearning
1aqy8i2,How do you keep track of all the math?,"I'm fairly new to deep learning. I've familiarized myself with the basics and I'm currently building my first neural network from scratch. The issue is, while the math itself isn't complicated, there are too many operations happening at once and it's hard to keep track of (especially the things like matrix multiplication and chain rule derivatives).",50,16,Emad_mak,2024-02-14 21:24:41,https://www.reddit.com/r/deeplearning/comments/1aqy8i2/how_do_you_keep_track_of_all_the_math/,0,deeplearning
1af7pny,Is there such a thing as a neural network made up of smaller neural networks?,If we take the brain for example but what if the neurons were actually more complex brains themselves if that makes sense. Is there anything similar in deep learning or are they just the same thing?,48,35,MarshyBars,2024-01-31 03:14:34,https://www.reddit.com/r/deeplearning/comments/1af7pny/is_there_such_a_thing_as_a_neural_network_made_up/,0,deeplearning
193gdgn,Whats the best way to learn more about deep learning for a career? (Books?),"Sorry if this is the wrong place to ask this but just not really sure where is best.  


I graduated this past spring with a bachelors in Computer Science but have been struggling to find a job (like many) but I see there is a lot of traction in ML/DL. I took a Deep learning class in my fourth year but it really just scraped the surface and I did not learn how to write full networks and such myself. I am just wondering what books and frameworks are recommended for learning and finding employment. I do know some pytorch but not enough. I have tons of time currently so reading a lot wouldn't be an issue.  


Thanks in advance for your suggestions!",48,23,FivePlyPaper,2024-01-10 19:13:33,https://www.reddit.com/r/deeplearning/comments/193gdgn/whats_the_best_way_to_learn_more_about_deep/,0,deeplearning
rpwjsl,AWS Launched a Google Colab Competitor,[https://www.youtube.com/watch?v=qFH1MV-yg04](https://www.youtube.com/watch?v=qFH1MV-yg04),47,10,solawulf,2021-12-27 20:30:00,https://www.reddit.com/r/deeplearning/comments/rpwjsl/aws_launched_a_google_colab_competitor/,0,deeplearning
lp5qyv,"Towards the Limits of Binary Neural Networks - Series of Works (CVPR2020, ECCV2020) - Link to free zoom lecture by the author in comments",,49,3,dataskml,2021-02-21 20:24:18,https://i.redd.it/kvod7yww3wi61.png,0,deeplearning
j549ut,Poker + AI + AR,,49,5,Independent-Square32,2020-10-04 18:54:27,https://youtu.be/7RTEwfXkbSY,0,deeplearning
hwxolq,Visualize gradient descent optimization algorithms in Tensorflow.,[https://github.com/Jaewan-Yun/optimizer-visualization](https://github.com/Jaewan-Yun/optimizer-visualization),48,5,mohsintariq10,2020-07-24 07:46:21,https://www.reddit.com/r/deeplearning/comments/hwxolq/visualize_gradient_descent_optimization/,0,deeplearning
em9s2n,"Advanced Deep Learning Course, by DeepMind",,47,13,newworld-ai,2020-01-09 13:40:57,https://www.newworldai.com/advanced-deep-learning-course-deepmind/,0,deeplearning
dz38b7,[P] Our team made an app that will tell you if a specific food is allergic to you just by a picture using deep learning and computer vision. I have attached the Github link in the comments.,,49,18,clean_pegasus,2019-11-20 15:03:51,https://v.redd.it/l863d6kgytz31,0,deeplearning
an0plr,Interview with Twice ‚Å¶kaggle‚Å© GrandMaster and Data Scientist at ‚Å¶h2oai‚Å© : (SRK) ‚Å¶Sudalai Rajkumar‚Å©,[https://hackernoon.com/interview-with-twice-kaggle-grandmaster-and-data-scientist-at-h20-ai-sudalai-rajkumar-cd952ef0c522](https://hackernoon.com/interview-with-twice-kaggle-grandmaster-and-data-scientist-at-h20-ai-sudalai-rajkumar-cd952ef0c522),51,2,init__27,2019-02-04 11:15:44,https://www.reddit.com/r/deeplearning/comments/an0plr/interview_with_twice_kaggle_grandmaster_and_data/,0,deeplearning
1441ypd,A famous Tollywood actor recreated as TikTok video using Deepfake,,45,10,oridnary_artist,2023-06-08 07:01:00,https://v.redd.it/341yxfq2tq4b1,0,deeplearning
125pbbf,AI Startup Cerebras releases open source ChatGPT-like alternative models,,47,14,Time_Key8052,2023-03-29 14:13:46,https://gpt4chatgpt.tistory.com/entry/Cerebras-releases-open-source-ChatGPT-like-alternative-models,0,deeplearning
121agx4,Do we really need 100B+ parameters in a large language model?,"DataBricks's open-source LLM, [Dolly](https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html) performs reasonably well on many instruction-based tasks while being \~25x smaller than GPT-3, challenging the notion that is big always better?

From my personal experience, the quality of the model depends a lot on the fine-tuning data as opposed to just the sheer size. If you choose your retraining data correctly, you can fine-tune your smaller model to perform better than the state-of-the-art GPT-X. The future of LLMs might look more open-source than imagined 3 months back?

Would love to hear everyone's opinions on how they see the future of LLMs evolving? Will it be few players (OpenAI) cracking the AGI and conquering the whole world or a lot of smaller open-source models which ML engineers fine-tune for their use-cases?

P.S. I am kinda betting on the latter and building [UpTrain](https://github.com/uptrain-ai/uptrain), an open-source project which helps you collect that high quality fine-tuning dataset",47,54,Vegetable-Skill-9700,2023-03-25 04:24:49,https://www.reddit.com/r/deeplearning/comments/121agx4/do_we_really_need_100b_parameters_in_a_large/,0,deeplearning
10d85g8,Inpainting with the Visuali editor (beta),,47,0,aigeneration,2023-01-16 07:19:58,https://v.redd.it/4ncbg5mgv3ca1,0,deeplearning
oo3ya3,[R] DeepMind‚Äôs AlphaFold2 Predicts Protein Structures with Atomic-Level Accuracy,"In a new paper published in the prestigious scientific journal Nature, DeepMind presents AlphaFold2, a redesigned neural-network system based on last year‚Äôs AlphaFold that can predict protein structures with atomic-level accuracy. 

Here is a quick read: [DeepMind‚Äôs AlphaFold2 Predicts Protein Structures with Atomic-Level Accuracy.](https://syncedreview.com/2021/07/20/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-65/)

The AlphaFold2 code is available on the project [Github](https://github.com/deepmind/alphafold). The paper *Highly Accurate Protein Structure Prediction with AlphaFold* is on [Nature](https://www.nature.com/articles/s41586-021-03819-2).",48,3,Yuqing7,2021-07-20 15:11:21,https://www.reddit.com/r/deeplearning/comments/oo3ya3/r_deepminds_alphafold2_predicts_protein/,0,deeplearning
mzshau,"[R] Microsoft & Peking U Researchers Identify 'Knowledge Neurons' in Pretrained Transformers, Enabling Fact Editing","A research team from Microsoft Research and Peking University peeps into pretrained transformers and investigates how factual knowledge is stored, proposing a method to identify ‚Äúknowledge neurons,‚Äù which can be utilized to explicitly update and erase facts.

Here is a quick read: [Microsoft & Peking U Researchers Identify 'Knowledge Neurons' in Pretrained Transformers, Enabling Fact Editing.](https://syncedreview.com/2021/04/27/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-6/)

The paper *Knowledge Neurons in Pretrained Transformers* is on [arXiv](https://arxiv.org/pdf/2104.08696.pdf).",47,2,Yuqing7,2021-04-27 16:33:55,https://www.reddit.com/r/deeplearning/comments/mzshau/r_microsoft_peking_u_researchers_identify/,0,deeplearning
mj9cn5,Will Transformers Replace CNNs in Computer Vision?,,48,2,OnlyProggingForFun,2021-04-03 14:16:52,https://youtu.be/QcCJJOLCeJQ,0,deeplearning
kt9ndn,NERFIES: The Selfies of The Future!,,47,1,myyoucef,2021-01-08 19:24:55,https://www.youtube.com/watch?v=IDMiMKWucaI,0,deeplearning
kr5gq0,The tech behind the recommender systems at Pinterest - PinSage (Graph neural net),,46,9,gordicaleksa,2021-01-05 19:18:28,https://youtu.be/ed0NJdqwEyg,0,deeplearning
knt4dz,Graph Convolutional Networks Explained! (Keep an eye out for GNNs next year),,45,3,gordicaleksa,2020-12-31 16:34:47,https://youtu.be/VyIOfIglrUM,0,deeplearning
kj0ycq,Voice Separation with an Unknown Number of Multiple Speakers | Github,,46,5,cmillionaire9,2020-12-23 20:46:34,https://youtu.be/e7QT7dD9-J8,0,deeplearning
hb8wzc,Small research paper reading community,"Hi r/deeplearning,

I have set up a discord server for reading, sharing and discussing research papers and implement them to some kaggle competitions/ datasets. I read my first research paper ([this one](https://arxiv.org/abs/1501.00092)) over the last weekend and implemented it in python. I thought it would be nice to have a small community to do this with. Direct me a message if you are interested. I intend to keep the member count small

P.S.: I used to get daunted by the *greek* in the papers and still do. It is OK if you feel overwhelmed by it.  If such a community already exists kindly direct me to it and ignore this post. And apologies for my bad english.

Edit 3:  Thank you guys for an overwhelming response. We've kinda peaked the planned member count. I'll be back, in a week, if we ~~plan to increase the count~~ get enough moderators. Do send me a message if you wish to join the server, but you'll be put into a waitlist. Thanks again. Apologies if you couldn't make it *this time*.",44,18,poons-san,2020-06-18 06:05:18,https://www.reddit.com/r/deeplearning/comments/hb8wzc/small_research_paper_reading_community/,0,deeplearning
h831yf,Advanced Deep Learning for Computer vision (ADL4CV) (IN2364),"**Lecture:** [https://dvl.in.tum.de/teaching/adl4cv-ss20/](https://dvl.in.tum.de/teaching/adl4cv-ss20/?fbclid=IwAR0KUJFzae6l55xjmaMzqrvDmLg92yhDa8u3iYKMR58jQgEwgRmJibEB6vc)

**Videos:** [https://www.youtube.com/watch?v=utfM\_XK7n\_M&list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39](https://www.youtube.com/watch?v=utfM_XK7n_M&list=PLog3nOPCjKBnjhuHMIXu4ISE4Z4f2jm39&fbclid=IwAR0Q43JbYU3-28vKNABJ5UaA4tGwqbGSyflRdjtLPDE67ktlh4BxyH1-yEU)

&#x200B;

&#x200B;

https://preview.redd.it/wcaedlo5tm451.png?width=1156&format=png&auto=webp&s=3a3e0eaab3176e2509971e51cce94102d268ea33",44,2,ai-lover,2020-06-13 07:41:14,https://www.reddit.com/r/deeplearning/comments/h831yf/advanced_deep_learning_for_computer_vision_adl4cv/,0,deeplearning
a8e4vf,"""Math is forever."" - Interview with NeurIPS 2018 Best Paper team",,47,0,gwen0927,2018-12-21 20:37:22,https://medium.com/syncedreview/neurips-2018-best-paper-team-math-is-forever-55d9b6ead977,0,deeplearning
11ryc3s,"How To Fine-tune LLaMA Models, Smaller Models With Performance Of GPT3","Recently, the LLaMA models by Meta were released. What makes these models so exciting, is that despite being small enough to run on consumer hardware, popular metrics show that the models perform as well or better than GPT3 despite being over 10X smaller!

The reason for this increased performance seems to be due to a larger number of tokens being used for training.

Now, following along with the video tutorial and open-source code, you can now fine-tune these powerful models on your own dataset to further increase the ability of these models!

[https://youtu.be/d4Cnv\_g3GiI](https://youtu.be/d4Cnv_g3GiI)",49,10,l33thaxman,2023-03-15 14:38:49,https://www.reddit.com/r/deeplearning/comments/11ryc3s/how_to_finetune_llama_models_smaller_models_with/,0,deeplearning
wfazqr,Research Paper Book Club,"Would anyone here be interested in starting a little discord community where people can vote on weekly/ biweekly papers to read and discuss as a group? I‚Äôm looking for a way to engage with complicated material and share the ideas with other people for better understanding. I‚Äôve got a big back log of papers I want to read and I‚Äôm trying to come up with ways to enforce a personal reading schedule. Thanks in advance for any feedback.

Edit: Link to new server

https://discord.gg/GdX7nbTu",46,36,Jjax7,2022-08-03 16:26:14,https://www.reddit.com/r/deeplearning/comments/wfazqr/research_paper_book_club/,0,deeplearning
q422p8,NYU Deep Learning 2021 by Alfredo Canziani & Yann LeCun,"[Youtube link](https://www.youtube.com/watch?v=mTtDfKgLm54&list=PLLHTzKZzVU9e6xUfG10TkTWApKSZCzuBI)

 **Lectures**:

01 ‚Äì History and resources  
01L ‚Äì Gradient descent and the backpropagation algorithm  
02 ‚Äì Neural nets: rotation and squashing  
02L ‚Äì Modules and architectures  
03 ‚Äì Tools, classification with neural nets, PyTorch implementation  
03L ‚Äì Parameter sharing: recurrent and convolutional nets  
04L ‚Äì ConvNet in practice  
04.1 ‚Äì Natural signals properties and the convolution  
04.2 ‚Äì Recurrent neural networks, vanilla and gated (LSTM)  
05L ‚Äì Joint embedding method and latent variable energy based models (LV-EBMs)  
05.1 ‚Äì Latent Variable Energy Based Models (LV-EBMs), inference  
05.2 ‚Äì But what are these EBMs used for?  
06L ‚Äì Latent variable EBMs for structured prediction  
06 ‚Äì Latent Variable Energy Based Models (LV-EBMs), training  
07L ‚Äì PCA, AE, K-means, Gaussian mixture model, sparse coding, and intuitive VAE  
07 ‚Äì Unsupervised learning: autoencoding the targets  
08L ‚Äì Self-supervised learning and variational inference  
08 ‚Äì From LV-EBM to target prop to (vanilla, denoising, contractive, variational) autoencoder  
09L ‚Äì Differentiable associative memories, attention, and transformers  
09 ‚Äì AE, DAE, and VAE with PyTorch, generative adversarial networks (GAN) and code  
10L ‚Äì Self-supervised learning in computer vision  
10 ‚Äì Self / cross, hard / soft attention and the Transformer  
11L ‚Äì Speech recognition and Graph Transformer Networks  
11 ‚Äì Graph Convolutional Networks (GCNs)  
12L ‚Äì Low resource machine translation  
12 ‚Äì Planning and control  
13 ‚Äì The Truck Backer-Upper  
14L ‚Äì Lagrangian backpropagation, final project winners, and Q&A session  
14 ‚Äì Prediction and Planning Under Uncertainty

[Link](https://tutobase.com/post/368) to the github notebooks, website, and previous year version

More machine learning courses on [https://tutobase.com/t/MachineLearning?tag=course](https://tutobase.com/t/MachineLearning?tag=course)",47,4,NaN_Loss,2021-10-08 17:08:13,https://www.reddit.com/r/deeplearning/comments/q422p8/nyu_deep_learning_2021_by_alfredo_canziani_yann/,0,deeplearning
ng883y,[D] Why Transformers are taking over the Compute Vision world: Self-Supervised Vision Transformers with DINO explained in 7 minutes!,"Check out the [new post from Casual GAN Papers](https://t.me/casual_gan/39) that explains the main ideas from Self-Supervised Vision Transformers with DINO.

1 Minute summary:

>In this paper from Facebook AI Research the authors propose a novel pipeline to train a [ViT](https://t.me/casual_gan/33) model in a self-supervised setup. Perhaps the most interesting consequence of this setup is that the learned features are good enough to achieve 80.1% top-1 score on ImageNet. At the core of their pipeline is a pair of networks that learn to predict the outputs of one another. The trick is that while the student network is trained via gradient descent over the cross-entropy loss functions, the teacher network is updated with an exponentially moving average of the student network weights. Several tricks such as centering and sharpening are employed to combat mode collapse. As a fortunate side-effect the learned self-attention maps of the final layer automatically learns class-specific features leading to unsupervised object segmentations.

\[[Full Explanation Post](https://t.me/casual_gan/39)\] \[[Arxiv](https://arxiv.org/pdf/2104.14294v1.pdf)\] \[[Project Page](https://github.com/facebookresearch/dino)\]

[Self supervised video segmentation](https://reddit.com/link/ng883y/video/vr1jszyyd3071/player)

More recent popular paper explanations:  
\[[MLP-mixer](https://t.me/casual_gan/35)\]  
\[[Vision Transformer (ViT)](https://t.me/casual_gan/33)\]",48,0,None,2021-05-19 15:03:51,https://www.reddit.com/r/deeplearning/comments/ng883y/d_why_transformers_are_taking_over_the_compute/,0,deeplearning
mnltdk,"[N] TUM, Google, Nvidia & LMU M√ºnchen's CodeTrans Pretrained Models Crack Source Code Tasks With SOTA Performance","A research team from Technical University of Munich, Google, Nvidia and LMU M√ºnchen proposes CodeTrans, an encoder-decoder transformer model which achieves state-of-the-art performance on six tasks in the software engineering domain, including Code Documentation Generation, Source Code Summarization, Code Comment Generation, etc.

Here is a quick read: [TUM, Google, Nvidia & LMU M√ºnchen's CodeTrans Pretrained Models Crack Source Code Tasks With SOTA Performance](https://syncedreview.com/2021/04/09/tum-google-nvidia-lmu-munchens-codetrans-pretrained-models-crack-source-code-tasks-with-sota-performance/)

The CodeTrans code is available on the project [GitHub](https://github.com/agemagician/CodeTrans). The paper *CodeTrans: Towards Cracking the Language of Silicone‚Äôs Code Through Self-Supervised Deep Learning and High Performance Computing* is on [arXiv](https://arxiv.org/ftp/arxiv/papers/2104/2104.02443.pdf).",46,1,Yuqing7,2021-04-09 17:06:03,https://www.reddit.com/r/deeplearning/comments/mnltdk/n_tum_google_nvidia_lmu_m√ºnchens_codetrans/,0,deeplearning
m3wprw,Researchers at the University of Michigan and Netease Fuxi AI Lab Introduce ‚ÄòMeInGame‚Äô: A Deep Learning Technique To Automatically Create a Game Character Face from a Single Portrait (Paper and Github link included),"A team of researchers from Netease Fuxi AI Lab and the University of Michigan recently created a deep learning technique called ‚ÄòMeInGame‚Äô that can automatically generate character faces by analyzing a single portrait of a person‚Äôs face.¬†

In the past few years, many computer scientists and developers have been trying to develop techniques that could make gaming experiences increasingly immersive, engaging, and realistic. Several 3D face reconstruction methods based on deep learning have been proposed, but only a few of them have applications in games. Present game character customization systems require players to manually adjust the face attributes to obtain the desired look and sometimes even have limited facial shape and texture.

Paper Summary: [https://www.marktechpost.com/2021/03/12/researchers-at-the-university-of-michigan-and-netease-fuxi-ai-lab-introduce-meingame-a-deep-learning-technique-to-automatically-create-a-game-character-face-from-a-single-portrait/](https://www.marktechpost.com/2021/03/12/researchers-at-the-university-of-michigan-and-netease-fuxi-ai-lab-introduce-meingame-a-deep-learning-technique-to-automatically-create-a-game-character-face-from-a-single-portrait/) 

Paper: [https://arxiv.org/pdf/2102.02371.pdf](https://arxiv.org/pdf/2102.02371.pdf) 

GitHub: [https://github.com/FuxiCV/](https://github.com/FuxiCV/)",47,2,techsucker,2021-03-13 02:02:44,https://www.reddit.com/r/deeplearning/comments/m3wprw/researchers_at_the_university_of_michigan_and/,0,deeplearning
hd5hz2,Reduce Deep Learning Costs,"Hello everyone!

Training a deep learning model on GPUs is costly. Specially if its done on a cloud. To help data scientists and ML engineers train at 10X less cost, we have developed a new peer to peer GPU computing network. The instances are pre-configured with frameworks like Tensorflow and PyTorch, so you can focus on what matters.

We are inviting early users to try us out with free GPU Credits:

[https://www.qblocks.cloud/?ref=qb\_red](https://www.qblocks.cloud/?ref=qb_red)",43,18,gvij,2020-06-21 11:32:57,https://www.reddit.com/r/deeplearning/comments/hd5hz2/reduce_deep_learning_costs/,0,deeplearning
fhkhbm,"NVIDIA's GTC 2020 - The World's Biggest AI & Deep Learning Conference - Best of all, registration for GTC Digital is free*",,46,0,jugleni,2020-03-12 17:56:11,https://www.nvidia.com/en-us/gtc/?ncid=em-targ-77456,0,deeplearning
emxt3f,"Reinforcement Learning Course, by DeepMind",,44,5,newworld-ai,2020-01-10 21:50:08,https://www.newworldai.com/reinforcement-learning-course-deepmind/,0,deeplearning
cbzqp2,AI To Save Snow Leopards," I know Microsoft has been all over news with their AI that helps snow leopard preservation community. But I work for a small non-profit organization Kashmir World Foundation, and during my internship I created a program to detect snow leopard in the wild and classify them. So the preservation workers do not spend their valuable time sorting them. Just wanted to share it here.

https://preview.redd.it/9s1luucr2q931.jpg?width=2048&format=pjpg&auto=webp&s=3b06eda1476b741494d37fd1207d026e4b990fa5

https://preview.redd.it/4s3cnotr2q931.jpg?width=2048&format=pjpg&auto=webp&s=6323f58776058369822108b0abecd7ecac184806",44,10,lomiag,2019-07-11 19:03:46,https://www.reddit.com/r/deeplearning/comments/cbzqp2/ai_to_save_snow_leopards/,0,deeplearning
b0y8tm,Awesome papers and reviews [with codes!] on Computer Vision News of March. Links for free reading!,"Here are the links to the March 2019 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: many articles about Artificial Intelligence, Deep Learning, Computer Vision and more. Free subscription on page 34.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019March/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-march-pdf/)

Enjoy!

&#x200B;

https://preview.redd.it/7rq6fvgx02m21.jpg?width=794&format=pjpg&auto=webp&s=a39d611e41d8dd26d6a4339c7f1e506b7418c02b",46,0,Gletta,2019-03-14 09:30:29,https://www.reddit.com/r/deeplearning/comments/b0y8tm/awesome_papers_and_reviews_with_codes_on_computer/,0,deeplearning
aqalyd,Easy-to-read summaries of top deep reinforcement learning research papers,,49,1,drrobobot,2019-02-13 19:46:53,https://www.topbots.com/most-important-ai-reinforcement-learning-research/,0,deeplearning
abb37a,NVIDIA ‚ÄúSuper SloMo‚Äù Makes Video Smooth,,44,5,gwen0927,2018-12-31 20:47:46,https://medium.com/syncedreview/nvidia-super-slomo-makes-video-smooth-7bf4cffffe27,0,deeplearning
a69ys1,GAN 2.0: NVIDIA‚Äôs Hyperrealistic Face Generator,,43,1,gwen0927,2018-12-14 23:12:26,https://medium.com/syncedreview/gan-2-0-nvidias-hyperrealistic-face-generator-e3439d33ebaf,0,deeplearning
5lugdc,Anybody interested in an online reading group?,"I have just started the book by Goodfellow et al. Its a bit math heavy so it would be great to collaborate and discuss on it. I found this local meetup (https://www.meetup.com/Deep-Learning-Textbook-Study-Group/), but it has ended. Anybody interested?


EDIT 1: 

Since many of the people seem interested, we could start as early as possible. Could the people interested comment on 

* Where should we conduct our meetings?
* What time would be suitable for all?
* What would be the format of the reading group?

My personal suggestions, we could do a weekly meet on hangouts, preferably Sunday, but I'm up for everyday if it suits every1. Also for the format, as I suggested [below](https://www.reddit.com/r/deeplearning/comments/5lugdc/anybody_interested_in_an_online_reading_group/dbyrcgt/), it would be great if I could teach the book as an MOOC if everyone agrees. Eagerly waiting for your reply!


EDIT 2:
I've made a [google group](https://groups.google.com/forum/#!forum/deepreading), and we should start from next Sunday (15th of Jan). Till then we can decide on the above points",46,73,jalFaizy,2017-01-03 20:58:09,https://www.reddit.com/r/deeplearning/comments/5lugdc/anybody_interested_in_an_online_reading_group/,0,deeplearning
1bepill,Unable to understand CNN layer,,46,18,Additional_Bed_3948,2024-03-14 16:37:52,https://www.reddit.com/gallery/1bepill,0,deeplearning
xl6sey,UI for Apache Kafka - An open-source tool for monitoring and managing Apache Kafka Clusters,,45,1,TallAssociation0,2022-09-22 16:56:05,https://github.com/provectus/kafka-ui,0,deeplearning
sdcy1z,3D Autoencoder ‚Äì Instant Aerodynamic Drag Prediction,,44,6,g-x91,2022-01-26 18:36:55,https://i.redd.it/xky9ajzot2e81.gif,0,deeplearning
lk6287,MIT 6.S191 Introduction to Deep Learning,,43,4,techsucker,2021-02-15 04:53:32,http://introtodeeplearning.com/,0,deeplearning
ihii3i,GenRL: PyTorch-First Reinforcement Learning library,"Github: [https://github.com/SforAiDl/genrl](https://github.com/SforAiDl/genrl)

Reinforcement learning research is moving faster than ever before. In order to keep up with the growing trend and ensure that RL research remains reproducible, GenRL aims to aid faster paper reproduction and benchmarking by providing the following main features:

* **PyTorch-first**: Modular, Extensible and Idiomatic Python
* **Tutorials and Documentation:** *We have over 20 tutorials assuming no knowledge of RL concepts. Basic explanations of algorithms in Bandits, Contextual Bandits, RL, Deep RL, etc.*
* **Unified Trainer and Logging class**: code reusability and high-level UI
* **Ready-made algorithm implementations**: ready-made implementations of popular RL algorithms.
* **Faster Benchmarking**: automated hyperparameter tuning, environment implementations, etc.

The core of our library is centered around RL, having policies, values, actor critics, etc. And with trainers and loggers, the only part to care about is to have the right functions implemented and everything else is taken care of!

By integrating these features into GenRL, we aim to eventually support **any new algorithm implementation in less than 100 lines**. **We're also looking for more Open Source Contributors!**

Currently, the library has implementations of popular classical and Deep RL agents that ready to be deployed. Apart from these, various Bandit algorithms are a part of GenRL. It has various abstraction layers that make the addition of new algorithms easy for the user. Do give us a star!

&#x200B;

[Vanilla DQN](https://preview.redd.it/d8rjc9zltij51.png?width=1548&format=png&auto=webp&s=55adf6bef31c0e720867cc2628ac8ca29b5b6f6a)

[Training a DoubleDQN would only require changing a single function](https://preview.redd.it/cg4cua1ltij51.png?width=1784&format=png&auto=webp&s=980f31b95ad3ea0e924065508043da3b2cbf6cba)

[Training a DuelingDQN would only require changing a single function](https://preview.redd.it/o97uu41ltij51.png?width=1682&format=png&auto=webp&s=97db9c8f6eb0cd0664cd59f85ed20375aa9d4ab8)",45,5,sharadchitlangia,2020-08-27 10:20:19,https://www.reddit.com/r/deeplearning/comments/ihii3i/genrl_pytorchfirst_reinforcement_learning_library/,0,deeplearning
ie39vc,Maximizing Computer Vision's Field of View (CVPR 2020) - Free live online lecture by the researcher,,45,1,dataskml,2020-08-21 19:17:36,https://i.redd.it/1y6uxjezhih51.gif,0,deeplearning
hzbjgu,"Meet InvoiceNet, a software platform to train custom models and extract intelligent information from PDF invoice documents!",,46,9,naiveHobo,2020-07-28 09:25:06,https://github.com/naiveHobo/InvoiceNet,0,deeplearning
hl1cxt,AI generates Cars from the movie,,44,4,None,2020-07-04 10:42:03,https://youtu.be/fDh-qcbIxtU,0,deeplearning
djuxwf,Faces of DeepFake,,44,3,cmillionaire9,2019-10-18 22:29:16,https://youtu.be/V7TPSxMzMUg,0,deeplearning
ap9n1u,"A Gentle Introduction to Graph Neural Networks (Basics, DeepWalk, and GraphSage)","Graph Neural Networks is a special type of NN that directly operates on a graph structure. In a number of recent studies, it has achieved SOTA results on various domains, including Knowledge Graph, Social Network, Life Science, and Recommender System.

&#x200B;

This article will brief you the basics of Graph Neural Networks and introduce you two more advanced algorithms, DeepWalk and GraphSage. Check it out :)

[https://towardsdatascience.com/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3](https://towardsdatascience.com/a-gentle-introduction-to-graph-neural-network-basics-deepwalk-and-graphsage-db5d540d50b3)",47,0,steeveHuang,2019-02-10 23:03:25,https://www.reddit.com/r/deeplearning/comments/ap9n1u/a_gentle_introduction_to_graph_neural_networks/,0,deeplearning
a7bx88,Nvidia learned to make realistic faces,,43,2,cmillionaire9,2018-12-18 15:17:25,https://youtu.be/bIVU8UuHPKI,0,deeplearning
19ebmp2,Question from my Recent Interview,"Consider a dataset of Cats and dogs, which has more than 100k data points, it has some significant wrongly labelled data, how would you tackle this while training or before training, as samples are more and you can‚Äôt go through each and every image to check label‚Ä¶

This question made me stumble and couldn‚Äôt focus on following questions and eventually a bad experience 

I wanted to know your approach!",45,12,SuperProposal8378,2024-01-24 07:31:42,https://www.reddit.com/r/deeplearning/comments/19ebmp2/question_from_my_recent_interview/,0,deeplearning
uyrxzg,I wrote an opensource software that shows audio reactive visual effects generated by StyleGAN2 (links to github and more information under video description),,42,12,goolygoolygu,2022-05-27 06:29:11,https://youtu.be/E-so0qycPEY,0,deeplearning
t2qywq,"The type of tutorial I wish I had when first starting to learn more of the math behind deep learning papers as a non-phd. Connecting equations to specific lines of code, using a simple but end2end casually annotated example",,43,2,clam004,2022-02-27 15:48:43,https://github.com/clam004/intro_continual_learning,0,deeplearning
qgu1n2,How to read more research papers? (tips & tools given),"In this article, I am sharing the best tips and practical tools I use daily to simplify my life as a research scientist to be more efficient when looking for interesting research papers and reading them

[https://www.louisbouchard.ai/research-papers/](https://www.louisbouchard.ai/research-papers/)

Please, let me know if you use any other tools that I did not mention in my article that could be of great addition.

Quick summary of the tools discussed:

* [42 Papers](https://42papers.com/)‚Ää‚Äî‚ÄäFind trending papers
* [Arxiv Sanity Preserver](http://www.arxiv-sanity.com/)‚Ää‚Äî‚ÄäA Curation list of Arxiv papers
* [Papers With Code](https://paperswithcode.com/)‚Ää‚Äî‚ÄäFind papers for your task with code!
* [Daily Papers](https://papers.labml.ai/papers/daily)‚Ää‚Äî‚ÄäFind trending papers on Twitter
* [Crossmind](https://crossminds.ai/video/swin-transformer-hierarchical-vision-transformer-using-shifted-windows-606d0de375292b321dd08f80/)‚Ää‚Äî‚ÄäVideo explanations for many Arxiv papers
* [CatalyzeX](https://www.catalyzex.com/)‚Ää‚Äî‚ÄäCode implementation for most Arxiv papers
* [Connected Papers](https://www.connectedpapers.com/)‚Ää‚Äî‚ÄäCreate a visual graph with your paper‚Äôs citations‚Äô relations.
* [Yannic Kilcher](https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew)‚Ää‚Äî‚ÄäGreat youtube channel covering AI papers
* [What‚Äôs AI](https://www.youtube.com/channel/UCUzGQrN-lyyc0BWTYoJM_Sg)‚Ää‚Äî‚ÄäGreat youtube channel covering AI papers
* [Letitia](https://www.youtube.com/channel/UCobqgqE4i5Kf7wrxRxhToQA)‚Ää‚Äî‚ÄäGreat youtube channel covering AI papers
* [Two Minute Papers](https://www.youtube.com/user/keeroyz)‚Ää‚Äî‚ÄäGreat youtube channel giving a quick overview of AI papers",43,8,OnlyProggingForFun,2021-10-27 10:59:38,https://www.reddit.com/r/deeplearning/comments/qgu1n2/how_to_read_more_research_papers_tips_tools_given/,0,deeplearning
oqxldy,AlphaFold predicts structures for nearly every protein in the human body,,45,3,keghn,2021-07-24 20:30:43,https://newatlas.com/biology/alphafold-structures-every-protein-human-body/,0,deeplearning
o95awa,3rd place solution on Waymo Motion Prediction Challenge 2021 (CVPR21 Autoinomous driving Workshop),"https://preview.redd.it/cpf16k7oev771.png?width=797&format=png&auto=webp&s=6f561c4a9c161a39248d764ccef2a97d0e3673d7

Our team ([me](https://twitter.com/artsiom_s), Stepan Konev, Kirill Brodt) was awarded 3rd place within the Waymo Motion Prediction Challenge 2021.  


To plan a safe and efficient route, an autonomous vehicle should anticipate future motions of other agents around it. Motion prediction is an extremely challenging task that recently gained significant attention from the research community. We present a simple and yet very strong baseline for multimodal motion prediction based purely on Convolutional Neural Networks.

The task was the following: Given agents' tracks for the past 1 second on a corresponding map, we had to predict the positions of the agents on the road for 8 seconds into the future.  


[Pipeline of our approach.](https://preview.redd.it/vs4659orev771.png?width=1830&format=png&auto=webp&s=b2264972fff7cd18a340f4be48e0a264186dcb88)

Our model takes a raster image centered around a target agent as input and directly predicts a set of possible trajectories along with their confidences. The raster image is obtained by rasterisation of a scene and the history of all the agents. While being easy-to-implement, the proposed approach achieves competitive performance compared to the state-of-the-art methods on the Waymo Open Dataset Motion Prediction Challenge (2021): Our model ranks 1st using minimum average displacement error and 3rd using mAP score.

We wrote a small paper and release our code!

üìúTechnical report [https://github.com/kbrodt/waymo-motion-prediction-2021/blob/main/docs/CVPR2021\_Waymo\_motion\_prediction.pdf](https://github.com/kbrodt/waymo-motion-prediction-2021/blob/main/docs/CVPR2021_Waymo_motion_prediction.pdf)

‚öíÔ∏èCode [https://github.com/kbrodt/waymo-motion-prediction-2021](https://github.com/kbrodt/waymo-motion-prediction-2021)",44,1,temakone,2021-06-27 20:47:39,https://www.reddit.com/r/deeplearning/comments/o95awa/3rd_place_solution_on_waymo_motion_prediction/,0,deeplearning
n1vatz,[R] Yann LeCun Team's Novel End-to-End Modulated Detector Captures Visual Concepts in Free-Form Text,"A research team from NYU and Facebook proposes MDETR, an end-to-end modulated detector that identifies objects in images conditioned on a raw text query and is able to capture a long tail of visual concepts expressed in free-form text.

Here is a quick read: [Yann LeCun Team's Novel End-to-End Modulated Detector Captures Visual Concepts in Free-Form Text.](https://syncedreview.com/2021/04/30/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-9/)

 The paper *MDETR ‚Äì Modulated Detection for End-to-End Multi-Modal Understanding* is on [arXiv](https://arxiv.org/pdf/2104.12763.pdf).",46,0,Yuqing7,2021-04-30 14:42:09,https://www.reddit.com/r/deeplearning/comments/n1vatz/r_yann_lecun_teams_novel_endtoend_modulated/,0,deeplearning
mn5zwd,From Scratch: How to Build a Neural Network and Calculate its Gradients? Solution is Presented as a Chemical Structure!,,44,2,ahmed26gad,2021-04-09 00:57:47,https://www.amazon.com/Introduction-Learning-Neural-Networks-PythonTM/dp/0323909337,0,deeplearning
ku1lwg,How I Went From Being a Sales Engineer to Deep Learning / Computer Vision Research Engineer,"Transitioning into DL/ML can be challenging. In today's article, I share how I transitioned my career from being a Key Accounts Manager to a Computer Vision and Deep Learning Research Engineer. I hope it guides and helps you!

\#careerchange #ai #deeplearning #machinelearning #careeradvice #sales 

https://towardsdatascience.com/how-i-went-from-being-a-sales-engineer-to-deep-learning-computer-vision-research-engineer-8882272a1a6?sk=ce681ade9e38cb058143510355aaad36",44,15,msminhas93,2021-01-09 22:59:40,https://www.reddit.com/r/deeplearning/comments/ku1lwg/how_i_went_from_being_a_sales_engineer_to_deep/,0,deeplearning
jr3pdn,Tips for doing your own deep learning projects! (in the context of the original transformer),,45,5,gordicaleksa,2020-11-09 18:54:55,https://www.youtube.com/watch?v=px4rtkWHFvM&ab_channel=TheAIEpiphany,0,deeplearning
jhckad,A new deep learning computer vision library in Pytorch!,"Hi guys, I hope you are well and healthy! I have put together a compact, concise, and customizable deep learning computer vision library called ""glasses"".

Github: [https://github.com/FrancescoSaverioZuppichini/glasses](https://github.com/FrancescoSaverioZuppichini/glasses)

Website: [https://francescosaveriozuppichini.github.io/glasses-webapp/](https://francescosaveriozuppichini.github.io/glasses-webapp/)

It is the first beta so there are a lot of missing models and features that I will add in the future.

I do computer vision for a living and I wanted to have a flexible easy to use tool for my daily work. Most of the current libraries are very badly written with tons of code repetition and not very easy to customize. Moreover, it is hard to understand how most models are implemented and I hope my library will make it easier for new people in the field.

Unfortunately, I still haven't found a good place to host the pre-trained models so they are not available at the moment (any suggestions?)

I also would like to know if anyone wants to help me out with some feedback or in the coding!",46,12,None,2020-10-24 17:10:02,https://www.reddit.com/r/deeplearning/comments/jhckad/a_new_deep_learning_computer_vision_library_in/,0,deeplearning
jc8q0b,A new brain-inspired intelligent system drives a car using only 19 control neurons!,,44,5,OnlyProggingForFun,2020-10-16 12:15:27,https://youtu.be/wAa358pNDkQ,0,deeplearning
iqsul7,[R] OpenAI ‚ÄòGPT-f‚Äô Delivers SOTA Performance in Automated Mathematical Theorem Proving,"San Francisco-based AI research laboratory OpenAI has added another member to its popular GPT (Generative Pre-trained Transformer) family. In a new paper, OpenAI researchers introduce GPT-f, an automated prover and proof assistant for the Metamath formalization language.

Here is a quick read: [OpenAI ‚ÄòGPT-f‚Äô Delivers SOTA Performance in Automated Mathematical Theorem Proving](https://syncedreview.com/2020/09/10/openai-gpt-f-delivers-sota-performance-in-automated-mathematical-theorem-proving/)

The paper *Generative Language Modeling for Automated Theorem Proving* is on [arXiv](https://arxiv.org/pdf/2009.03393.pdf).",46,2,Yuqing7,2020-09-11 15:37:20,https://www.reddit.com/r/deeplearning/comments/iqsul7/r_openai_gptf_delivers_sota_performance_in/,0,deeplearning
i133sm,Virtual walks in Google Street View,,45,0,Independent-Square32,2020-07-31 07:09:30,https://youtu.be/EVovYLbB8sY,0,deeplearning
fb81zw,Wrote a Blog on Kalman Filters,,46,0,Nailer_Owl,2020-02-29 05:36:41,https://towardsdatascience.com/the-curious-case-of-kalman-filters-f29c3d17b121,0,deeplearning
eqw7l8,"When I was learning machine learning for the first time, the exact manner in which convolutional neural networks worked always evaded me, largely because they were only ever explained at an introductory level in tutorials. So, I made an animated video explaining exactly how CNNs work. Hope it helps!",,46,4,antaloaalonso,2020-01-19 13:28:08,https://www.youtube.com/watch?v=eyKwPyOqMg4&t=9s,0,deeplearning
cp3nug,"Which tool do people use to make such figures? Draw.io for the boxes maybe, but what about the input/output images?",,40,17,Jesper89,2019-08-11 22:48:24,https://i.redd.it/s4smj5isewf31.png,0,deeplearning
bvt8ze,Do We Still Need Traditional Pattern Recognition and Signal Processing in the Age of Deep Learning?,,44,4,ai-lover,2019-06-02 03:29:08,https://www.marktechpost.com/2018/11/28/do-we-still-need-traditional-pattern-recognition-and-signal-processing-in-the-age-of-deep-learning/,0,deeplearning
bsiyol,"[R] Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-based Image Retrieval, Anjan Dutta and Zeynep Akata, CVPR 2019.",,44,3,AnjanDutta,2019-05-24 16:26:19,https://v.redd.it/29xbtvjwp6031,0,deeplearning
aub1dx,This algorithm decodes rat squeaks and could revolutionize animal research | Verge Science,,45,3,abhishekchakraborty,2019-02-24 18:47:35,https://www.youtube.com/watch?v=25LYVxTUZhM,0,deeplearning
1bise80,Announcing FeatUp: a Method to Improve the Resolution of ANY Vision Model,,45,7,mhamilton723,2024-03-19 19:08:46,https://v.redd.it/fyvi8ivmacpc1,0,deeplearning
1b2ee2z,90% faster active speaker detection on video,,44,7,happybirthday290,2024-02-28 19:07:32,https://v.redd.it/k7os8qm7kdlc1,0,deeplearning
18b3el9,How long does it take for you to implement a research paper?,"Hi, I'm new to Machine Learning. I've talked to senior researchers and ML engineers and looked up resources online, and one of the most frequent advices I've heard is to read tons of papers and try to implement them or replicate the result if possible. While I can feel that I'm getting more used to reading paper, I still find implementing papers extremely hard. If a paper is well-written and has code and weights available (and they are proven to work), I can spend some time to understand the code and train it on different datasets and do some parameter-tuning etc (in this case I actually don't do much because the model itself is implemented already). But if the paper has no code available, I find it almost impossible to implement it as I never know if what I am doing is correct, especially if there are missing details. Thus, I'm just wondering, if you are a phd student/researcher/ML engineer/hobbyist,

How much time do you spend on implementing a paper on average?

How often do you try to implement /replicate a paper instead of doing other things?

How do you determine if a paper is worth implementing and what's your typical approach if you decide to do it?

Many people told me it's a rewarding thing to do but I never successfully implemented one from scratch and replicated the result. I always give up at some point. Any tips will be helpful. Thank you.",45,10,Tensor_Devourer_56,2023-12-05 04:10:23,https://www.reddit.com/r/deeplearning/comments/18b3el9/how_long_does_it_take_for_you_to_implement_a/,0,deeplearning
11ijo7o,[P] We built Life Copilot - an AI assistant that can understand text + images & control a browser to surf the internet using MULTI¬∑ON (multion.ai) to do things for you!,,43,9,DragonLord9,2023-03-05 01:31:14,https://v.redd.it/rl0g2kysptla1,0,deeplearning
112u10p,[P] From ‚Äúiron manual‚Äù to ‚ÄúIron Man‚Äù ‚Äî Augmenting GPT for fast editable memory to enable context aware question & answering,,43,7,skeltzyboiii,2023-02-15 09:25:30,https://i.redd.it/yujf2enambia1.gif,0,deeplearning
o4phgq,"GANs N' Roses: Stable, Controllable, Diverse Image to Image Translation paper explained!",,42,4,gordicaleksa,2021-06-21 07:14:38,https://youtu.be/VNg0NyCGl_4,0,deeplearning
msl4xl,The Genetic Algorithm and Deep Learning Play Snake: https://youtu.be/3bhP7zulFfY,,45,6,ahmed26gad,2021-04-17 05:51:34,https://v.redd.it/4oahxw8aaot61,0,deeplearning
jv5bm7,"A lecture by St√©phane Mallat on ""Multiscale Models for Image Classification and Physics with Deep Networks"", who knows maybe one of you guys will find it interesting, cause I certainly did!",,43,1,kehal12,2020-11-16 11:35:29,https://www.youtube.com/watch?v=R5hSqeLSQC0,0,deeplearning
jhzd4q,Google AI Introduces Performer: A Generalized Attention Framework based on the Transformer architecture,"[Transformer model](https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html), a deep learning framework, has achieved state-of-the-art results across diverse domains, including¬†[natural language](https://ai.googleblog.com/2018/11/open-sourcing-bert-state-of-art-pre.html),¬†[conversation](https://ai.googleblog.com/2020/01/towards-conversational-agent-that-can.html),¬†[images](https://openai.com/blog/image-gpt/), and even¬†[music](https://magenta.tensorflow.org/music-transformer). The core block of any Transformer architecture is the¬†[attention module](https://lilianweng.github.io/lil-log/2018/06/24/attention-attention.html), which computes similarity scores for all pairs of positions in an input sequence. Since it requires quadratic computation time and quadratic memory size of the storing matrix, with the increase in the input sequence‚Äôs length, its efficiency decreases.

Thus, for long-range attention, one of the most common methods is¬†[sparse attention](https://openai.com/blog/sparse-transformer/). It reduces the complexity by computing selective similarity scores from the sequence, based on various methods. There are still certain limitations like unavailability of efficient sparse-matrix multiplication operations on all accelerators, lack of theoretical guarantees, insufficiency to address the full range of problems, etc.

**Introduction to ‚ÄúPerformer‚Äù**

To resolve these issues, Google AI introduces the¬†[Performer](https://arxiv.org/abs/2009.14794), a Transformer architecture with attention mechanisms that scale linearly. The framework is implemented by¬†[Fast Attention Via Positive Orthogonal Random Features (FAVOR+) algorithm](https://github.com/google-research/google-research/tree/master/performer/fast_self_attention), providing scalable¬†low-variance¬†and¬†unbiased¬†estimation of attention mechanisms expressed by random feature maps decompositions (in particular, regular softmax-attention). Mapping helps in preserving linear space and time complexity.

**Full Summary:** [https://www.marktechpost.com/2020/10/25/google-ai-introduces-performer-a-generalized-attention-framework-based-on-the-transformer-architecture/](https://www.marktechpost.com/2020/10/25/google-ai-introduces-performer-a-generalized-attention-framework-based-on-the-transformer-architecture/) 

**Github:**¬†[https://github.com/google-research/google-research](https://github.com/google-research/google-research) 

**Paper:**¬†[https://arxiv.org/pdf/2009.14794.pdf](https://arxiv.org/pdf/2009.14794.pdf)",44,2,ai-lover,2020-10-25 19:26:17,https://www.reddit.com/r/deeplearning/comments/jhzd4q/google_ai_introduces_performer_a_generalized/,0,deeplearning
hjnn7b,An Embarrassingly Simple Approach for Trojan Attack in Deep Neural Networks (Paper Summary Video),,43,0,ai-lover,2020-07-02 01:22:28,https://youtu.be/CkVGb2_LR1s,0,deeplearning
gk94x1,Machine / Deep Learning Paper Reading Group,"Hi guys,

I have been trying to read some papers in deep learning, and though some are easy to understand, others can be exceptionally hard to understand (especially when on your own). I was wondering we can make this more like a collaborative approach (especially amid covid) where we can have a person present a summary of what they understand and then go into an in depth discussion amongst other people. Allowing us to ask questions that bug us and more importantly understand the content.

If interested, I have created a google sheets:  [https://docs.google.com/spreadsheets/d/1HMpIWNQ\_20DCWiiv0SZcTJ4sGoBKBoQ7chWwnO375F4/edit?usp=sharing](https://docs.google.com/spreadsheets/d/1HMpIWNQ_20DCWiiv0SZcTJ4sGoBKBoQ7chWwnO375F4/edit?usp=sharing)

where you can choose a paper to present and some other details. I'm happy to kick it off with a paper. Please do join, I look forward to learning together.

Furthermore, for discussions I also created a slack group: [https://join.slack.com/t/deep-learning-net/shared\_invite/zt-ebz4dc9g-ykv00oT3ON8bhhsW5nzyog](https://join.slack.com/t/deep-learning-net/shared_invite/zt-ebz4dc9g-ykv00oT3ON8bhhsW5nzyog)",43,10,None,2020-05-15 13:29:58,https://www.reddit.com/r/deeplearning/comments/gk94x1/machine_deep_learning_paper_reading_group/,0,deeplearning
g3jfb4,Social distance | AI | Covid-19,,42,6,cmillionaire9,2020-04-18 07:12:53,https://youtu.be/me_uDNba8u8,0,deeplearning
e1wew5,"High resolution video visualization of mode connectivity using real data | NeurIPS 2018, ARXIV:1802.10026",,42,3,javismiles,2019-11-26 10:56:54,https://v.redd.it/ogaocpecf0141,0,deeplearning
e0etsr,AI-enabled Time Machine Lens,,43,2,cmillionaire9,2019-11-23 07:41:59,https://youtu.be/M43BPA9HFU8,0,deeplearning
c96v4c,Created the fastest and most customizable NLP tokenizer in Python using a novel approach (not regex!),[https://github.com/kootenpv/tok](https://github.com/kootenpv/tok),45,3,pvkooten,2019-07-04 19:49:21,https://www.reddit.com/r/deeplearning/comments/c96v4c/created_the_fastest_and_most_customizable_nlp/,0,deeplearning
brn659,Python library to control nvidia gpu fan to use more aggressive cooling for DL applications,,39,16,magnusjja,2019-05-22 10:43:05,https://github.com/magnusja/nvfan/,0,deeplearning
axik2t,Using deep learning to ‚Äúread your thoughts‚Äù ‚Äî with Keras and an EEG sensor,,43,0,quasci,2019-03-05 07:44:53,https://medium.com/@justlv/using-ai-to-read-your-thoughts-with-keras-and-an-eeg-sensor-167ace32e84a,0,deeplearning
1aym8k0,"If everything is mathematically calculated, what part of the deep learning network is actually a blackbox?","In a simple neural network, weights are randomly assigned, loss, gardient is calculated mathematically and weights are then readjusted. Isn't this all maths? Consider even a CNN, Image is converted to lets say 224\*224 pixel values and then convolution, maxpooling etc is performed..again mathematically...given a person has eternity, can he perform the same functions and mathematically train a model manually? ",41,26,akshat235,2024-02-24 05:04:26,https://www.reddit.com/r/deeplearning/comments/1aym8k0/if_everything_is_mathematically_calculated_what/,0,deeplearning
1apdrrt,Why do models trained on discretised continuous data outperform their continuous contrrparts,"Hey, From experience, I've discovered that when training a neural network on discretised continuous data (Say, an RNN on time series data), it usually outperforms the continuous model in generalisation and accuracy.

I was wondering why this is the case, It feels like the answer would be something really simple and I'm totally missing it but it's been bugging me for some time. The obvious thing is the objective function changing from the MSE to Log likelihood.

Anyone care to share some insight?",42,14,dace27,2024-02-12 22:59:26,https://www.reddit.com/r/deeplearning/comments/1apdrrt/why_do_models_trained_on_discretised_continuous/,0,deeplearning
146ralm,Crazy stylization with Temporalnet,,40,6,oridnary_artist,2023-06-11 11:13:42,https://v.redd.it/cffz3kewgd5b1,0,deeplearning
11dbval,ChatLLaMA ü¶ô the first open source implementation of LLaMA based on Reinforcement Learning from Human Feedback (RLHF): https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama,"**ChatLLaMA ü¶ô the first open source implementation of LLaMA based on Reinforcement Learning from Human Feedback (RLHF):** [**https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama**](https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama) 

https://preview.redd.it/2qjvoyuemqka1.png?width=672&format=png&auto=webp&s=6dcb2ddbe8fb25a0da7bf8cba1ea135c30587542",42,5,None,2023-02-27 13:29:23,https://www.reddit.com/r/deeplearning/comments/11dbval/chatllama_the_first_open_source_implementation_of/,0,deeplearning
x2w6f1,Training Physics In 10 Seconds... (My first machine learner),,42,6,TheRPGGamerMan,2022-09-01 02:44:43,https://v.redd.it/g076ptuhu5l91,0,deeplearning
r3ysls,Me Trying Machine Learning for the first time - What could possibly go wrong?,,45,3,vadhavaniyafaijan,2021-11-28 07:30:56,https://v.redd.it/vv1lwhl0k2281,0,deeplearning
otsmoo,A Job Site dedicated to Deep Learning/AI Roles exclusively,,42,0,ai_jobs,2021-07-29 07:17:28,https://ai-jobs.net/,0,deeplearning
o8vlyx,"I made a funny 3-minute video explaining convolutional neural networks for the Breakthrough Junior Challenge (a video-making competition). If you guys want a brief and entertaining introduction to convolutional neural networks, then consider checking out my video. I spent a ton of time on it!",,42,11,antaloaalonso,2021-06-27 11:50:04,https://www.youtube.com/watch?v=eR19j7332vU,0,deeplearning
n7wsrj,The neural network makes movie dubbing more natural,,41,1,cmillionaire9,2021-05-08 19:39:31,https://youtu.be/T7vrk6NCNsU,0,deeplearning
kg8dk3,Open-source web app that generates template code for machine learning | Github,,42,5,cmillionaire9,2020-12-19 14:14:36,https://youtu.be/ZjijMvKgb7c,0,deeplearning
jtnrpz,"L Google AI Releases ‚ÄòObjectron Dataset‚Äô Consisting Of 15,000 Annotated Videos And 4M Annotated Images",,42,1,Independent-Square32,2020-11-13 20:31:25,https://youtu.be/_eXa2qv_c4A,0,deeplearning
j6tdlw,"A new way to discover top trending papers in Deep Learning, ML and CS.",,43,6,gsvclass,2020-10-07 15:53:47,https://42papers.com/,0,deeplearning
j4f7da,This computer vision algorithm removes the water from underwater images!,,46,12,OnlyProggingForFun,2020-10-03 13:42:17,https://www.youtube.com/watch?v=E1kffL4_AS8,0,deeplearning
g9ts5t,"Springer has released 65 Machine Learning and Data books for free Hopefully someone will find any of them useful, otherwise share the knowledge",,43,4,tatogt81,2020-04-28 19:30:00,https://towardsdatascience.com/springer-has-released-65-machine-learning-and-data-books-for-free-961f8181f189,0,deeplearning
f8bstw,Disappearing-People - Person removal from complex backgrounds over time,,43,4,cmillionaire9,2020-02-23 16:36:26,https://youtu.be/jisEpZJzMtA,0,deeplearning
ef3ogg,Deep Learning Pioneers Yann LeCun and Yoshua Bengio Elected as AAAI-20 Fellows,,44,0,Yuqing7,2019-12-24 16:40:45,https://medium.com/syncedreview/deep-learning-pioneers-yann-lecun-and-yoshua-bengio-elected-as-aaai-20-fellows-48730cf8cdf,0,deeplearning
e2i636,"PyTorch implementation of a transformer chatbot. Code is explained with highschool level language, without jargon, down to the fundamentals with diagrams in ipython notebooks",,43,7,clam004,2019-11-27 16:11:27,https://github.com/chloerobotics/chloebot,0,deeplearning
dbuvry,Tensorflow 2.0 is out!,,45,0,alejandrohall,2019-10-01 15:19:19,https://medium.com/tensorflow/tensorflow-2-0-is-now-available-57d706c2a9ab,0,deeplearning
bi1g9z,Advanced Deep Learning Courses,"A few months ago, I saw this post on Reddit.

[Ph.D. level courses:](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses/)[ Machine Learning](https://www.reddit.com/r/MachineLearning/comments/51qhc8/phdlevel_courses/)

I am wondering if anyone can mention such courses in deep learning.

This course from CMU is the best course in deep learning I've ever seen.

[CMU 11-785: Introduction to Deep Learning](http://deeplearning.cs.cmu.edu/)

&#x200B;

Here are some other courses as well:

[IFT 6085: Theoretical principles for deep learning](http://mitliagkas.github.io/ift6085-dl-theory-class-2019/)

[CS 294-158: Deep Unsupervised Learning](https://sites.google.com/view/berkeley-cs294-158-sp19/home)

[CMU 10-703: Deep Reinforcement Learning and Control](http://www.andrew.cmu.edu/course/10-703/)",43,11,None,2019-04-27 17:33:30,https://www.reddit.com/r/deeplearning/comments/bi1g9z/advanced_deep_learning_courses/,0,deeplearning
aymy9o,Udacity's updated tutorial course for Tensorflow2.0!,"Hey guys, some of you might have seen the release of Tensorflow2.0 alpha that came out a few days ago. Just wanted to share the updated [Udacity tutorial](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187) for getting started with it.

However I did find that it doesn't cover how to actually create your own custom loss function optimizer operations for applying the new 2.0 API for more complex reinforcement learning applications so I'm going to try and make a YouTube coding tutorial for that soon.

&#x200B;

Edit: I uploaded the YouTube tutorial here ---> [https://www.youtube.com/watch?v=fQCKxzHvYnw](https://www.youtube.com/watch?v=fQCKxzHvYnw)",42,6,shawnmanuel000,2019-03-08 06:10:59,https://www.reddit.com/r/deeplearning/comments/aymy9o/udacitys_updated_tutorial_course_for_tensorflow20/,0,deeplearning
ay3yta,GIPHY open-sources their celebrity detection deep learning model and code,,41,2,giphy,2019-03-06 21:07:47,https://github.com/Giphy/celeb-detection-oss,0,deeplearning
a9dxrg,Learn backprop the hard way: build your neural network from scratch using Numpy only,,42,8,ahmedbesbes,2018-12-25 10:25:15,https://github.com/ahmedbesbes/Neural-Network-from-scratch,0,deeplearning
14dp21n,"I know this is off topic, but no paper should be published unless they put their code online. it's really frustrating!","Authors should always publish their experiments for reproduction, no matter how simple the paper's algorithms are!",41,19,caesar______,2023-06-19 20:03:35,https://www.reddit.com/r/deeplearning/comments/14dp21n/i_know_this_is_off_topic_but_no_paper_should_be/,0,deeplearning
1350qtu,What are some small LLM models or free LLM APIs for tiny fun project?,"Hi, I'm looking for a free/opensource api to build a small GPT webapp for fun. I want to deploy it on something like Heroku and use Flask in the backend. 


I'm also open to uploading a small-ish llm model on Heroku and use that to answer chat like queries from users.


Do you know of any such small foss models and/or free APIs?",41,20,silent_lantern,2023-05-01 20:45:08,https://www.reddit.com/r/deeplearning/comments/1350qtu/what_are_some_small_llm_models_or_free_llm_apis/,0,deeplearning
12dn9t5,Meta's new Segment Anything Model Explained,,39,1,OnlyProggingForFun,2023-04-06 15:11:39,https://youtu.be/bx0He5eE8fE,0,deeplearning
12bpldr,DATID-3D: Diversity-Preserved Domain Adaptation Using Text-to-Image Diffusion for 3D Generative Model (CVPR 2023),,41,5,ImBradleyKim,2023-04-04 17:11:05,https://v.redd.it/ik5l8dc4hwra1,0,deeplearning
z4lpry,Is Linux still vastly preferred for deep learning over Windows?,I'm building a brand new RTX 4090 PC and came across a number of posts from several years ago saying Linux was vastly preferred over Windows for the field. Is that still the case or has Windows caught up/is good enough for casual non-professional projects? Is dual boot setup the optimal choice if I want to do both deep learning and be able to run standard Windows applications/games on the machine?,41,52,moekou,2022-11-25 19:21:37,https://www.reddit.com/r/deeplearning/comments/z4lpry/is_linux_still_vastly_preferred_for_deep_learning/,0,deeplearning
y13wjg,I made densify ‚Äì‚Äì a tool for enriching point cloud datasets,,42,13,jsonathan,2022-10-11 08:51:23,https://i.redd.it/lo9sa8mh45t91.gif,0,deeplearning
po2xkq,How should one keep track of the deep learning literature?,"Every day I read a newly published paper where the authors change the number of layers or the activations functions used in known deep learning models, and they propose their contribution as a novel deep learning algorithm and give their model a new name. There are many other papers where they introduce other, more advanced changes and publish them. How can a researcher keep track of all these studies and proposed methods before publishing their own method to make sure it wasn't published before with a different name? How do they know the model they proposed wasn't already published before? There are too many new studies every year. A keyword search would not be of much help since parts and pieces introduced are also commonly used by many others, and it is impossible to go through all of the returned studies. I want to know if there are easy tricks or tools people are using to reduce the overlapping deep learning studies.",43,14,AcademicAlien,2021-09-14 13:36:59,https://www.reddit.com/r/deeplearning/comments/po2xkq/how_should_one_keep_track_of_the_deep_learning/,0,deeplearning
oz0939,Target Recovery for Robust Deep Learning-Based Person Following in Mobile Robots: Online Trajectory Prediction.,,40,6,redhwanALgabri,2021-08-06 05:21:37,https://v.redd.it/8nh7ol83aof71,0,deeplearning
m971lq,Why people don't describe complete algorithms on arxiv,"Hello, recently I have been reading a paper about AlphaZero, I think they didn't mention many details, so we end up reading other resources to understand what is going on. Do you have the same problem or this problem occurs to me because I am a beginner in paper readings?",40,14,datonefaridze,2021-03-20 13:28:02,https://www.reddit.com/r/deeplearning/comments/m971lq/why_people_dont_describe_complete_algorithms_on/,0,deeplearning
i77hld,Convolution Neural Network visualiser. I have developed a python package for interpreting and visualizing cnns.,"The link for to this project :- https://github.com/rshah240/conv_visualiser

Please give me more suggestions for improving this and if you're facing any issues please feel free to reach out to me.",41,11,None,2020-08-10 15:57:23,https://www.reddit.com/r/deeplearning/comments/i77hld/convolution_neural_network_visualiser_i_have/,0,deeplearning
hluzqc,JAX: Accelerated Machine Learning Research | SciPy 2020 | VanderPlas,,44,0,EmergenceIsMagic,2020-07-05 21:51:26,https://www.youtube.com/watch?v=z-WSrQDXkuM,0,deeplearning
f5ozg6,Real-Time Detection and Tracking of Basketball Players using Deep Neural Networks #dl #ml,,44,6,cmillionaire9,2020-02-18 09:01:48,https://youtu.be/EJWD85amLW8,0,deeplearning
dvdmxd,Texas A&M and Simon Fraser Universities Open-Source RL Toolkit for Card Games,,42,1,Yuqing7,2019-11-12 18:01:04,https://medium.com/syncedreview/texas-a-m-and-simon-fraser-universities-open-source-rl-toolkit-for-card-games-858e22195f36,0,deeplearning
cdvz2t,Machine Learning books suggested by top experts like Professor Bengio (U of Montreal) and Daphne Koller (Cofounder of Coursera),,43,1,TJ1,2019-07-16 11:48:03,http://www.doradolist.com/machine-learning.html,0,deeplearning
cbqovr,Announcing a series of blogs on PyTorch C++ API (Libtorch),"Hi everyone. 

I'm happy to announce a series of blogs on PyTorch C++ API. When I started using the C++ API, I had lots of problems and thanks to the community at [discuss.pytorch.com](https://discuss.pytorch.com) where I got most of the help. I decided to write blogs on using C++ API for the community. Here it comes! 

There have been 3 blogs as of now, and I would love to hear your comments and feedback on them.

 [https://krshrimali.github.io/Announcing-PyTorch-CPP-Series/](https://krshrimali.github.io/Announcing-PyTorch-CPP-Series/) 

&#x200B;

[Announcing PyTorch C++ API Series! - krshrimali.github.io](https://preview.redd.it/ez8mwe51gl931.png?width=960&format=png&auto=webp&s=92e9e61cd25c5cba4a5c167cecfa8fac97d94ac0)

Thanks!",41,8,Kushashwa,2019-07-11 03:29:10,https://www.reddit.com/r/deeplearning/comments/cbqovr/announcing_a_series_of_blogs_on_pytorch_c_api/,0,deeplearning
bz0vsd,"PyTorch Hub | Check out the models for Researchers and Developers, or learn How it Works",,41,1,asuagar,2019-06-10 17:46:36,https://pytorch.org/hub,0,deeplearning
ai0uwh,Training YOLOv3 : Deep Learning based Custom Object Detector,,40,5,sunitanyk,2019-01-20 18:47:10,https://v.redd.it/tllouv4v8mb21,0,deeplearning
1ak1hmn,How to get out the loneliness of research career,"Hi guys, I'm a ms student and I'm doing research under the guidance with a new AP in my university. H's a good person, has strong capability, and he always encourages us to follow our own thoughts. However, since he is a new AP, our lab only have 2 ms students including me and 0 phd student.

I feel like overwhelmed by the loneliness. When I come across problems, such as the derivation of formulas and some research stuff, I can't find a friend to ask.  My only way of acquiring information from other people is my weekly meeting with my professor.

I tried to talk with other phds in my univ but they usually don't work on my field, i.e., unsupervised learning and world models stuff. One impressive moment is one day I deployed some docker apps to our lab server just for fun. I wanted to cheer for that but couldn't find anyone to talk with.

I'm determined to pursue a phd career but I can't stand for the loneliness and pressure (from both research and coursework since I'm a ms).  The instructions given by professor is rather free because he doesn't want to be so rigorous and hopes to inspire our enthusiasm towards research, whereas I need to publish one paper before my phd application so that I can be competitive in the applicantion pool.  However, even if I become a phd in those big schools, I'm afraid that I'll keep repeating this lonely life for 5 years, and I'll spend my life before my 30 as an upset person :(

Sorry for these cliche, I just can't hold myself.",40,6,AdministrativeCar545,2024-02-06 04:39:36,https://www.reddit.com/r/deeplearning/comments/1ak1hmn/how_to_get_out_the_loneliness_of_research_career/,0,deeplearning
wb7776,Huge win for Deep Learning with AlphaFold using it to predict millions of protein structures!,,40,0,BeautifulVegetable10,2022-07-29 15:07:15,https://www.deepmind.com/blog/alphafold-reveals-the-structure-of-the-protein-universe,0,deeplearning
w8o9m5,"How I found nearly 300,000 errors in MS COCO","Hi folks! I've made a new technique for finding errors in object detection datasets, using new explainable AI techniques from my PhD. I was frankly pretty surprised to be able to find about 275k errors in MS COCO's training set (which has around 700k labels). This includes things like incorrectly drawn bounding boxes (shown below, about 55k), missing background labels (178k), and missing labels that overlap with existing labels (40k).

While there's been some work on improving datasets, as far as I know this is the largest number of errors found on any public ML dataset, by a wide margin.

I would love to get the communities thoughts on this. I am also building a company, so if you're interested in using this on your work feel free to DM me.

To learn more about the results (and see more pictures), check out my article: [https://medium.com/@jamie\_34747/79d382edf22b?source=friends\_link&sk=d36ad07c074818c48d8f421f6ed104cd](https://medium.com/@jamie_34747/79d382edf22b?source=friends_link&sk=d36ad07c074818c48d8f421f6ed104cd)

&#x200B;

[ COCO label \(solid line\) and FIXER correction \(dotted\) in MS COCO. The COCO label cut off the baseball player‚Äôs legs ](https://preview.redd.it/k4vix5vcwxd91.png?width=1440&format=png&auto=webp&s=b9f28c2a2c62abd3b69e6fe6ee587f1fb2b56a25)",38,2,AGI_aint_happening,2022-07-26 16:31:34,https://www.reddit.com/r/deeplearning/comments/w8o9m5/how_i_found_nearly_300000_errors_in_ms_coco/,0,deeplearning
vdbqlp,"Dalle mini is amazing, free, and open-source ‚Äî Here‚Äôs how it works...",,42,6,OnlyProggingForFun,2022-06-16 02:51:25,https://youtu.be/qOxde_JV0vI,0,deeplearning
v2ew58,Are transformers taking over CNNs in the computer vision field ?,"As far as I know the transformer architecture is the de facto standard for all NLP tasks since 2017. Since ""attention is all you need"" and the Bert model came out, everyone started using transformers, to push new SOTA in NLP tasks.

I see similar things now happening in the computer vision field as well, e.g.[https://paperswithcode.com/sota/image-classification-on-imagenet](https://paperswithcode.com/sota/image-classification-on-imagenet)[https://paperswithcode.com/sota/semantic-segmentation-on-cityscapes](https://paperswithcode.com/sota/semantic-segmentation-on-cityscapes)[https://paperswithcode.com/sota/object-detection-on-coco](https://paperswithcode.com/sota/object-detection-on-coco)All top models now use transformers in some way.

I found the paper ""AN IMAGE IS WORTH 16X16 WORDS: TRANSFORMERS FOR IMAGE RECOGNITION AT SCALE"" as a very influential one.

So what do you think, is this the end of CNNs? What other papers are important in the CV field, with regards to Transformers ?",42,13,keremidk0,2022-06-01 11:36:30,https://www.reddit.com/r/deeplearning/comments/v2ew58/are_transformers_taking_over_cnns_in_the_computer/,0,deeplearning
ktq7im,New deep learning computer vision library,"Hi guys, some time ago I posted about my work in progress CV library called glasses. In the past weeks I have added new models (ViT, RegNet, ...) and heavily update the doc so I would love to have your feedback.

Github: [https://github.com/FrancescoSaverioZuppichini/glasses](https://github.com/FrancescoSaverioZuppichini/glasses)

Website: [https://francescosaveriozuppichini.github.io/glasses-webapp/](https://francescosaveriozuppichini.github.io/glasses-webapp/)

Take care and cheers :)",40,6,None,2021-01-09 12:36:26,https://www.reddit.com/r/deeplearning/comments/ktq7im/new_deep_learning_computer_vision_library/,0,deeplearning
jtcgog,Plexiglass: a PyTorch toolbox for cybersecurity research and testing against adversarial attacks and deepfakes.,"Hi everyone, my name is Enoch and I am a researcher studying deep generative models.

I've started this project called Plexiglass, which is a PyTorch toolbox for cybersecurity research and testing against adversarial attacks and deepfakes.

 I would very much appreciate any suggestions/ feedbacks and even contributions. 

Repo is here: [https://github.com/enochkan/p](https://github.com/enochkan/safetynet)lexiglass",39,4,kanxx030,2020-11-13 06:50:58,https://www.reddit.com/r/deeplearning/comments/jtcgog/plexiglass_a_pytorch_toolbox_for_cybersecurity/,0,deeplearning
imzl8f,"ECCV 2020's Best Paper Award! A new architecture for Optical Flow, with code publicly available! (Video cover and demo)",,36,3,OnlyProggingForFun,2020-09-05 11:30:27,https://www.youtube.com/watch?v=OSEuYBwOSGI,0,deeplearning
gjd2xq,"New Tesla V100 GPU Cloud Instances by Lambda Labs, 50% less than AWS",,41,19,mippie_moe,2020-05-14 02:02:38,https://lambdalabs.com/service/gpu-cloud,0,deeplearning
ftst23,I am writing a series of blogs about object detection where I will be reviewing object detection papers. I have written first blog of the series. Here is the link.,"&#x200B;

1. Introductory blog about the series. [https://medium.com/@sanchittanwar75/getting-started-with-object-detection-179677feb3f4](https://medium.com/@sanchittanwar75/getting-started-with-object-detection-179677feb3f4)
2. Overfeat paper: [https://medium.com/@sanchittanwar75/overfeat-review-1312-6229-4fd925f3739f](https://medium.com/@sanchittanwar75/overfeat-review-1312-6229-4fd925f3739f)
3. RCNN paper:  [https://medium.com/@sanchittanwar75/rcnn-review-1311-2524-898c3148789a](https://medium.com/@sanchittanwar75/rcnn-review-1311-2524-898c3148789a)
4. Sppnet:
‚ÄúReview: Spatial Pyramid Pooling[1406.4729]‚Äù by Sanchit Tanwar https://link.medium.com/zLcyA4RSN5
5. Fast Rcnn:
https://medium.com/@sanchittanwar75/fast-rcnn-1504-08083-d9a968a82a70
6. Faster RCNN:
https://towardsdatascience.com/faster-rcnn-1506-01497-5c8991b0b6d3",39,8,sanchit2843,2020-04-02 19:31:21,https://www.reddit.com/r/deeplearning/comments/ftst23/i_am_writing_a_series_of_blogs_about_object/,0,deeplearning
ftc40g,DDSP: Differentiable Digital Signal Processing - Voice to instrument example,,41,0,stochastic4ts,2020-04-02 00:24:23,https://magenta.tensorflow.org/ddsp,0,deeplearning
fbisjw,What's the current situation of TenserFlow 2.0 vs Pytorch?,"Hi all! So i remember a couple of months ago during the launch of TF 2.0 the reactions of it were quite mixed and many people said to prefer Pytorch over it also saying Pytorch is steadily improved, well its been quite a while since TF 2.0 so i wanted to ask which one you guys prefer for Machine Learning nowdays?",40,27,Flamyngoo,2020-02-29 20:45:10,https://www.reddit.com/r/deeplearning/comments/fbisjw/whats_the_current_situation_of_tenserflow_20_vs/,0,deeplearning
eihyiv,CS230 Deep Learning Lectures | Stanford Engineering,,37,0,newworld-ai,2020-01-01 12:40:48,https://www.newworldai.com/cs230-deep-learning-stanford-engineering/,0,deeplearning
e6yzn0,Deep Learning with PyTorch: Part 1 of 5 | 2-hour tutorial on PyTorch Basics & Linear Regression,,38,14,None,2019-12-06 13:49:35,https://www.youtube.com/watch?v=1HWwDUCxGFU&list=PLyMom0n-MBroupZiLfVSZqK5asX8KfoHL&index=1,0,deeplearning
d9f2t7,A Roundup Review of the Best Deep Learning Books,,43,7,marylai22,2019-09-26 05:07:18,https://blog.soshace.com/en/python/a-roundup-review-of-the-best-deep-learning-books/,0,deeplearning
cd27wb,Breast cancer diagnosis with neural networks (implemented in python),,37,2,antaloaalonso,2019-07-14 11:58:50,https://www.youtube.com/watch?v=QiLHwCkx-YQ,0,deeplearning
bajn04,Deep Learning With NO Code,"Hello everyone,

The project is called Deep Learner. This is a project my and my friends worked on during one of the Hackathons I thought it would be appropriate for this sub. The purpose of this project is to allow people prototype Deep Neural networks very very quickly and with writing 0 lines of code. For now you can only build regular dense networks. It also allows for data visualization using Tableau and you can also save models in json format. Please note this is very much work in progress and was made by 4 college students in 24 hours, so there will be bugs. We decided to make this open source, so you are more than welcome to contribute, I have posted a couple issues on github so feel free to contribute.  We are hoping to expand on it in the near future.

[Deep Learner](https://github.com/GioLomia/Deep_Learner)

Let me know if you have any questions <3.",38,11,lomiag,2019-04-07 18:50:14,https://www.reddit.com/r/deeplearning/comments/bajn04/deep_learning_with_no_code/,0,deeplearning
as3f4f,The Power of AI Generated Stories,"For the past 3 years, I've made a modest income generating genre fiction novels using deep learning and publishing them. By A/B testing, constant iteration and moving fast using many different pen-names I've been able to discover and serve tiny niches a human author would have trouble even finding. Most of the credit goes to a large and painstakingly annotated data set (which oddly enough, occurred to me just a few hours after my father died).  I'm continuously in awe of how powerful the ability to tell people a fictional story about the world is but more alarmingly, that often times the only difference between my books and many books I see under ""non-fiction"" is the category we each selected in the drop down menu.

&#x200B;

No matter what your opinion is on Open AI's decision to restrict their model,  this technology has much more profound and dangerous implications than most people realize. Whether you want people to build a pyramid, believe in Jesus or buy a stock, stories are how you program people and cultures. Yuval Noah Harari makes a good case in his books that our ability to share and collectively believe in fictional stories is what made us the dominant species on the planet.

&#x200B;

That being said, I now have a 240 GB training set of over 2.7 million narratives from fiction and non-fiction, about 85-90% English, each with very structuralized meta data, including the names of the central people in the narrative, directional graphs about their relationships, tags of their behavioural traits, tags of narrative themes, outcomes, points of view etc. etc. I have more data than my AI skills or my computational resources can effectively utilize. If there's anyone here with a very strong DL and NLP background who I can partner with to get access to the resources needed to train on my entire data set, please let me know.

&#x200B;

Edit: Just so there's no ambiguity, No I did not generate the 2.7 million narratives in the data set. That's a much, much larger version of the original data set I trained the first model with 3 years ago. That's what this whole post is about. I intend to train a brand new model with that.",42,24,00hello,2019-02-18 23:13:02,https://www.reddit.com/r/deeplearning/comments/as3f4f/the_power_of_ai_generated_stories/,0,deeplearning
ak34aw,MIT 6.S091: Introduction to Deep Reinforcement Learning (Deep RL),,39,0,keghn,2019-01-26 17:51:05,https://www.youtube.com/watch?v=zR11FLZ-O9M,0,deeplearning
19bz2yp,Are there any YouTube channels that implements DL papers? Or any hands on DL YouTube channels.,,39,19,Agitated-Ad809,2024-01-21 08:45:48,https://www.reddit.com/r/deeplearning/comments/19bz2yp/are_there_any_youtube_channels_that_implements_dl/,0,deeplearning
145revi,PyTorch or TensorFlow,"I am a college student trying to learn all things AI, ML and Neural Nets on the side. Just started a course and did a little bit of Neural Networks. I know python, but now i'm in a dilemma whether to learn PyTorch or TensorFlow so that i can understand the coding parts of the courses that i'm watching, and also learn to implement my own code. Which library do you guys recommend for a beginner to get into these topics?",39,34,i_amsov,2023-06-10 05:23:22,https://www.reddit.com/r/deeplearning/comments/145revi/pytorch_or_tensorflow/,0,deeplearning
12n16jx,Automatic Gradient Descent: Deep Learning without Hyperparameters,"[https://arxiv.org/abs/2304.05187](https://arxiv.org/abs/2304.05187)

By [Jeremy Bernstein](https://arxiv.org/search/cs?searchtype=author&query=Bernstein%2C+J), [Chris Mingard](https://arxiv.org/search/cs?searchtype=author&query=Mingard%2C+C), [Kevin Huang](https://arxiv.org/search/cs?searchtype=author&query=Huang%2C+K), [Navid Azizan](https://arxiv.org/search/cs?searchtype=author&query=Azizan%2C+N), [Yisong Yue](https://arxiv.org/search/cs?searchtype=author&query=Yue%2C+Y)

>The architecture of a deep neural network is defined explicitly in terms of the number of layers, the width of each layer and the general network topology. Existing optimisation frameworks neglect this information in favour of implicit architectural information (e.g. second-order methods) or architecture-agnostic distance functions (e.g. mirror descent). Meanwhile, the most popular optimiser in practice, Adam, is based on heuristics. This paper builds a new framework for deriving optimisation algorithms that explicitly leverage neural architecture. The theory extends mirror descent to non-convex composite objective functions: the idea is to transform a Bregman divergence to account for the non-linear structure of neural architecture. Working through the details for deep fully-connected networks yields automatic gradient descent: a first-order optimiser without any hyperparameters. Automatic gradient descent trains both fully-connected and convolutional networks out-of-the-box and at ImageNet scale. A PyTorch implementation is available at [this https URL](https://github.com/jxbz/agd) and also in Appendix B. Overall, the paper supplies a rigorous theoretical foundation for a next-generation of architecture-dependent optimisers that work automatically and without hyperparameters.

&#x200B;

https://preview.redd.it/i4j7eb0ln1ua1.png?width=1024&format=png&auto=webp&s=ff9cb25b86775ab61980f2340251e168c23aadb0",39,3,moetsi_op,2023-04-15 12:44:14,https://www.reddit.com/r/deeplearning/comments/12n16jx/automatic_gradient_descent_deep_learning_without/,0,deeplearning
10rlbc4,Any of you know a local and Open Source equivalent to Eleven Labs text to speech AI ?,,40,46,lordnyrox,2023-02-02 08:55:09,https://www.reddit.com/r/deeplearning/comments/10rlbc4/any_of_you_know_a_local_and_open_source/,0,deeplearning
zaxg5m,Everyone: AI will make it easy to spread misinformation; Me: Stop hitting yourself GPT3!,,40,0,hayAbhay,2022-12-02 20:59:47,https://i.redd.it/mrf9rz0ltj3a1.png,0,deeplearning
o6hp7r,YOLOR (Scaled-YOLOv4-based): The best speed/accuracy ratio for Waymo autonomous driving challenge,,40,1,AlexeyAB,2021-06-23 17:30:21,https://i.redd.it/jmpzjnj1w1771.png,0,deeplearning
n0lan4,"Announcing Labelflow, the open source image labeling and dataset cleaning platform.","Hi, all! Announcing Labelflow ( [https://www.labelflow.net/](https://www.labelflow.net/) ), the open source image labeling and dataset cleaning platform.

We are a team of 9 people with experience in image labeling and dataset curating to build quality datasets for deep learning.  We were frustrated by the amount of scripts required to move the data back and forth between tools, and by the lack of control over our data, especially when we have data that can‚Äôt easily be shared. 

So we started building Labelflow, an image labeling tool with all the bells and whistles, but with an open source backend that you can connect to your own data stack easily. Let me know what you think, and feel free to request early access to get up to 50% off when we release it in a few months!",40,12,crubier,2021-04-28 18:23:55,https://www.reddit.com/r/deeplearning/comments/n0lan4/announcing_labelflow_the_open_source_image/,0,deeplearning
k2u1w2,"I built a platform that lets you deploy your ML models for free using a super-optimized model runtime, I'd love your input!",,39,18,Cold999,2020-11-28 19:36:47,https://getficra.com/,0,deeplearning
iv3rnz,GPT-3: new AI can write like a human but don't mistake that for thinking ‚Äì neuroscientist,,42,14,PowerOfLove1985,2020-09-18 10:45:02,https://theconversation.com/gpt-3-new-ai-can-write-like-a-human-but-dont-mistake-that-for-thinking-neuroscientist-146082,0,deeplearning
itt5al,"PiFuHD: A new method for high-fidelity 3d reconstruction. It only needs a single image of you to generate a 3D avatar that looks just like you, even from the back!",,43,2,OnlyProggingForFun,2020-09-16 10:51:17,https://www.youtube.com/watch?v=ajWtdm05-6g,0,deeplearning
igobay,How PyTorch hooks work (explained visually),,40,1,elliotwaite,2020-08-26 00:09:21,https://youtu.be/syLFCVYua6Q,0,deeplearning
i5a8ep,"Jupyter notebook tutorial for ""Indoor house room type recognition""",,38,1,Independent-Square32,2020-08-07 08:39:11,https://youtu.be/a1lBOj2qTQI,0,deeplearning
ho73xj,NVAE: A Deep Hierarchical Variational Autoencoder (Paper Explained),,41,1,keghn,2020-07-09 17:19:28,https://www.youtube.com/watch?v=x6T1zMSE4Ts,0,deeplearning
hlkcqs,Automatic road condition analysis using mobile mapping,,38,0,cmillionaire9,2020-07-05 10:16:33,https://youtu.be/fKxRgua-ms0,0,deeplearning
gl0axh,"I completed the deep learning specialization on Coursera and now trying to implement my own models. However, the data in the courses was readily available with preprocessing. I am having a hard time preprocessing data. Any link would be super helpful. Please help",,39,15,None,2020-05-16 19:06:17,https://www.reddit.com/r/deeplearning/comments/gl0axh/i_completed_the_deep_learning_specialization_on/,0,deeplearning
ei64sh,2019 in Review: 10 AI Papers That Made an Impact,,38,0,Yuqing7,2019-12-31 17:45:46,https://medium.com/syncedreview/2019-in-review-10-ai-papers-that-made-an-impact-6f607c9c6035,0,deeplearning
cvx04n,Create Your Own Synthetic Voice With Just One Hour of Speech (Lyrebird Review),,39,0,LimarcAmbalina,2019-08-27 00:53:15,https://lionbridge.ai/articles/how-to-create-your-own-synthetic-voice-with-just-one-hour-of-speech-lyrebird-review/,0,deeplearning
crq5l3,Sports Matches & Artificial Intelligence,,40,5,cmillionaire9,2019-08-17 18:44:29,https://youtu.be/kaslJ-8piSE,0,deeplearning
bc0qwo,A Google Brain Program Is Learning How to Program,,40,9,gwen0927,2019-04-11 14:48:02,https://medium.com/syncedreview/a-google-brain-program-is-learning-how-to-program-27533d5056e3,0,deeplearning
aw4m90,"""Topology of Learning in Artificial Neural Networks"" 21 Feb 2019 article",,38,4,None,2019-03-01 13:00:20,https://medium.com/generate-vision/the-paperoftheweek-8-is-topology-of-learning-in-artificial-neural-networks-57108378a26e,0,deeplearning
8dw9uz,"The first article in a series exploring Deep Learning in Computer Vision using PyTorch. In this, we set the goal of getting into the top 1% in a Kaggle Competition (you need to be in top 10% to be an expert).",,41,8,databiryani,2018-04-21 15:03:12,http://theaijournal.com/2018/04/20/pytorch-for-computer-vision-1-introduction-to-computer-vision-and-deep-learning/,0,deeplearning
19fe558,Is 192GB RAM useless for AI build?,"I built an AI PC using 2x 4090 GPUs and 7950X CPU. I also utilized an Asus ProArt X670E mobo and a 192GB DDR5 Corsair RAM kit(they are working @ 4800Mhz/s). It seems everything works fine and I haven't had any unstability issues so far.  But when I check RAM usage during the inference of Stable Diffusion models, it only used 10%(around 18GB) of RAM(With only one GPU. I couldn't figure it out how to enable dual GPU usage).

I am wondering is this RAM kit overkill for this CPU? If so, I would return this RAM kit and buy a 96GB kit instead?",40,56,thefreemanever,2024-01-25 17:06:05,https://www.reddit.com/r/deeplearning/comments/19fe558/is_192gb_ram_useless_for_ai_build/,0,deeplearning
10zepkt,‚≠ï New Open-Source Version Of ChatGPT,"GPT is getting competition from open-source.

A group of researchers, around the YouTuber [Yannic Kilcher](https://www.ykilcher.com/), have announced that they are working on [Open Assistant](https://github.com/LAION-AI/Open-Assistant). The goal is to produce a chat-based language model that is much smaller than GPT-3 while maintaining similar performance.

If you want to support them, they are crowd-sourcing training data [here](https://open-assistant.io/).

**What Does This Mean?**

Current language models are too big.

They require millions of dollars of hardware to train and use. Hence, access to this technology is limited to big organizations. Smaller firms and universities are effectively shut out from the developments.

Shrinking and open-sourcing models will facilitate academic research and niche applications.

Projects such as Open Assistant will help to make language models a commodity. Lowering the barrier to entry will increase access and accelerate innovation.

What an exciting time to be alive! 

Thank you for reading! I really enjoyed making this for you!  
The Decoding ‚≠ï is a thoughtful weekly 5-minute email that keeps you in the loop about machine research and the data economy. [Click here to sign up](https://thedecoding.net/)!",39,3,LesleyFair,2023-02-11 06:59:00,https://www.reddit.com/r/deeplearning/comments/10zepkt/new_opensource_version_of_chatgpt/,0,deeplearning
zau0uc,GPU Comparisons: RTX 6000 ADA vs A100 80GB vs 2x 4090s,"Hey everyone. I'm building a new workstation for both personal and professional use and I need some help weighing the pros/cons of the different GPUs I'm looking at as well as general advice/recommendations.

Most of my professional work would fall within NLP and GNN models, however, I do occasionally dabble in image classifiers and stable diffusion as a hobby. The current GPUs that I was looking at are an RTX A6000 ADA, a used/refurbished A100 80GB (using PCIE instead of SXM4), or dual 4090s with a power limitation (I have a 1300watt PSU).

With the RTX A6000 ADA having 48gb of vram, it's definitely nice to be able to be able to load a whole new range of models that I wouldn't have been able to otherwise (without AWS or model parallelism), but it's harder to justify the current expected cost of $7,378-8210 when you could spend an additional $2-3k and get a used/refurbished A100 80GB GPU from ebay that provides almost double the vram and would likely outperform the new A6000 ADA card by a sizeable amount in FP16 and FP32 calculations.

However, you could also just get two RTX 4090s that would cost \~$4k and likely outperform the RTX 6000 ADA and be comparable to the A100 80GB in FP16 and FP32 calculations. The only consideration here is that I would need to change to a custom water-cooling setup as my current case wouldn't support two 4090s with their massive heatsinks (I'm assuming this change may cost in the range of $1.5-2k). Furthermore, I would likely need to put a power limitation on the GPUs with a 1300 watt PSU. The vram, at 24gb, would likely cover all of my professional use cases, but prevents me from loading in larger models without having to utilize model parallelism, which can be painful.

I also do like to play games casually. While this is not a major factor, it would be nice to not have to maintain two different rigs, with the A100 not really able to support games.

So, with all that being said, does it make sense to go for two 4090s, which would be \~4k plus a water cooling setup at \~1.5k, making it 5.5k in total? Or go for a RTX 6000 ADA at \~7.5-8k, which would likely have less computing power than 2 4090s, but make it easier to load in larger things to experiment with. Or just go for the end game with an A100 80gb at \~10k, but have a separate rig to maintain for games.

I do use AWS as well for model training for work. But with the recent AWS bills, my company has offered to pay a portion of the cost to build a new workstation. I will still be paying for most of the costs, but want to utilize the opportunity as personal PC upgrade. Any model training on AWS, that wouldn't be used for work, would obviously be billed to me (hence the interest in just getting a card with greater vram).

What do you all think makes the most sense here?

\--------------------------------------------------------------------------------------------------------------------------------------------

Edit: 05/09/2023

I ended up going with 1x 4090. Computer specs below:

CPU:  AMD RYZEN 9 7950X

GPU:  MSI RTX4090 GAMING X TRIO 24G

RAM:  G.SKILL 64G 4X D5 6000 C36

MB:  ASUS ROG CROSSHAIR X670E HERO

PSU:  MSI MPG AI1300P 80+P ATX3 PSU

Case: Fractal Torrent

&#x200B;

https://preview.redd.it/ung19j0yjwya1.jpg?width=12000&format=pjpg&auto=webp&s=5d8ddb99a64b2c969fbaf062d823abf2cdab5666

I ended up undervolting the CPU in bios and power limiting the 4090 via MSI Afterburner. This solved some initial stability issues with model training (PC would reboot while training). Since then, I've have 0 stability issues and the computer chews through model training. I haven't had temps go past 80c for either the CPU or GPU while training or gaming. The 24gb of vram solves most of my day to day use cases and if I need to load something over 24gb, I resort to AWS. As suflaj recommended, I think this is the way to go and I would highly recommend following latest guides to undervolt and power limit a 4090 if you choose to go with a similar build. Hope this helps...",35,53,TheButteryNoodle,2022-12-02 18:47:55,https://www.reddit.com/r/deeplearning/comments/zau0uc/gpu_comparisons_rtx_6000_ada_vs_a100_80gb_vs_2x/,0,deeplearning
wlnw5o,PepsiCo Inc. partners with Provectus to empower company's e-commerce business with AI and ML,,39,0,TallAssociation0,2022-08-11 10:17:12,https://siliconangle.com/2022/06/28/ai-machine-learning-critical-pepsicos-ecommerce-efforts-reinvent/,0,deeplearning
q1vv1c,The whole story on how I landed a job at DeepMind as a Research Engineer (No ML degree),,38,10,gordicaleksa,2021-10-05 12:59:21,https://gordicaleksa.medium.com/how-i-got-a-job-at-deepmind-as-a-research-engineer-without-a-machine-learning-degree-1a45f2a781de,0,deeplearning
p2y9ur,"[P] NLP ""tl;dr"" Notes on Transformers","With the explosion in work on all things transformers, I felt the need to keep a single table of the ""tl;dr"" of various papers to distill their main takeaways: [https://github.com/will-thompson-k/tldr-transformers](https://github.com/will-thompson-k/tldr-transformers) . Would love feedback - and feel free to contribute!

&#x200B;

&#x200B;

[notes on the \\""tl'dr\\"" of several big transformer papers](https://preview.redd.it/gcaezvyf1xg71.jpg?width=770&format=pjpg&auto=webp&s=6764e981d8bd973efed0f5a125bbdbdfe5c50954)",37,10,wilhelm____,2021-08-12 11:53:30,https://www.reddit.com/r/deeplearning/comments/p2y9ur/p_nlp_tldr_notes_on_transformers/,0,deeplearning
nvt9fs,"Are you currently learning or working with AI? Well, 12'000+ of us are, too! So join our Discord servers, ask questions, find teammates, share your projects, help others, and much more!","Programming is way more fun when you learn/work with someone. Help each other, ask questions, brainstorm, etc. There is just so much benefit to joining a community when you are in this field, especially when you cannot find the question you are looking for on stack overflow! üòâ  
This is the same thing with AI, and it is why a little less than a year ago, I created a discord server where anyone learning or working in the field could come and share their projects, learn together, work together, and much more. As a result, the community is now close to 13'000 members, which is unbelievable! So glad to see it growing and see everyone so active.  


Join us if you are in the field of AI!  
[https://discord.gg/learnaitogether](https://discord.gg/learnaitogether)",40,0,OnlyProggingForFun,2021-06-09 11:13:22,https://www.reddit.com/r/deeplearning/comments/nvt9fs/are_you_currently_learning_or_working_with_ai/,0,deeplearning
nu92k1,When Vision Transformers Outperform ResNets without Pretraining! (Paper Explained),,41,0,gordicaleksa,2021-06-07 10:26:22,https://youtu.be/oDtcobGQ7xU,0,deeplearning
n8ikdk,BERT - Annotated Paper + Paper Summary,"Everyone who is interested in NLP or even DL and ML for that matter, has definitely heard about the BERT family of models. BERT, RoBERTa, DistilBERT and many many more. This paper ""BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"" first introduced this and it has now completely changed the way AI practitioners are solving and looking at NLP problems these days.

As a part of my Paper Notes series, I have gone through the paper and created an informative summary of the paper. This time it goes a bit longer than the previous paper summaries, but it had to be done. The paper contained many tiny interesting nuggets that I had to include. Check out the links below and happy reading!

Paper Summary -  [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://shreyansh26.github.io/post/2021-05-09_pretraining_deep_bidirectional_transformers_bert/)

Annotated Paper -  [https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf](https://github.com/shreyansh26/Annotated-ML-Papers/blob/main/BERT.pdf)",38,8,shreyansh26,2021-05-09 17:09:05,https://www.reddit.com/r/deeplearning/comments/n8ikdk/bert_annotated_paper_paper_summary/,0,deeplearning
mbejst,"We created a face recognition powered door lock for our office and decided to share the DIY. You can find tutorials, instructions, and photos in the blog.",,40,2,meancuki,2021-03-23 13:19:29,https://arsfutura.com/magazine/building-a-face-recognition-powered-door-lock/,0,deeplearning
mafxmz,Attention Mechanism Animated,,40,1,No-Guard-5438,2021-03-22 05:32:04,https://www.youtube.com/watch?v=lmepFoddjgQ,0,deeplearning
m22ulx,"At GTC21, NVIDIA CEO Jensen Huang will host AI pioneers Yoshua Bengio, Geoffrey Hinton, and Yann LeCun who collectively won the 2018 ACM Turing Award for breakthroughs in deep learning.",,39,2,jaquitowelles,2021-03-10 17:23:07,https://twitter.com/NVIDIAGTC/status/1369332167453650948,0,deeplearning
lz0bh8,Generating completely novel but functional enzyme sequences with deep learning,,38,3,janimezzz,2021-03-06 12:09:24,https://www.nature.com/articles/s42256-021-00310-5,0,deeplearning
l6h5zf,[N] ZeRO-Offload: Training Multi-Billion Parameter Models on a Single GPU,"Researchers from University of California, Merced and Microsoft have introduced ZeRO-Offload, a novel heterogeneous DL training technology that enables training of multi-billion parameter models on a single GPU without any model refactoring.

Here is a quick read: ZeRO-Offload: [Training Multi-Billion Parameter Models on a Single GPU](https://syncedreview.com/2021/01/27/zero-offload-training-multi-billion-parameter-models-on-a-single-gpu/)

The paper *ZeRO-Offload: Democratizing Billion-Scale Model Training* is on [arXiv](https://arxiv.org/pdf/2101.06840.pdf).",37,2,Yuqing7,2021-01-27 23:09:04,https://www.reddit.com/r/deeplearning/comments/l6h5zf/n_zerooffload_training_multibillion_parameter/,0,deeplearning
kjceeo,Time-Travel Rephotography,,38,7,cmillionaire9,2020-12-24 09:19:05,https://youtu.be/yBNmXU26UXE,0,deeplearning
jdsp12,Deep Learning in Production Resource List,,39,4,ConfidentMushroom,2020-10-19 01:35:42,https://github.com/ahkarami/Deep-Learning-in-Production,0,deeplearning
iww40v,Google Introduces A New Algorithm For Training Sparse Neural Networks,,37,3,analyticsindiam,2020-09-21 07:56:45,https://analyticsindiamag.com/rigl-google-algorithm-neural-networks/,0,deeplearning
hel8wh,[R] Google & DeepMind Researchers Revamp ImageNet,"A  team of researchers from Google Brain in Z√ºrich and DeepMind London believe one of the world‚Äôs most popular image databases may need a makeover. ImageNet is an unparalleled computer vision reference point with more than 14 million labelled images. It was designed for visual object recognition software research and is organized according to the WordNet hierarchy. Each node of the hierarchy is depicted by hundreds and thousands of images, and there are currently an average of over 500 images per node.  


In a [paper](https://arxiv.org/pdf/1912.11370.pdf) published last year, the Google Brain Z√ºrich team proposed Big Transfer (BiT-L), now a SOTA ImageNet model. Looking at what were considered ‚Äúmistakes‚Äù in BiT-L, Google Brain researcher Lucas Beyer suggested most of these could in fact be label noise rather than genuine model mistakes.  


To quantify this idea, Beyer and his Google Brain colleagues joined DeepMind researchers in a recent study to determine ‚Äúwhether recent progress on the ImageNet classification benchmark continues to represent meaningful generalization, or whether the community has started to overfit to the idiosyncrasies of its labeling procedure.‚Äù 

Here is a quick read: [Google & DeepMind Researchers Revamp ImageNet](https://syncedreview.com/2020/06/23/google-deepmind-researchers-revamp-imagenet/)

The paper *Are We Done With ImageNet?* is on [arXiv](https://arxiv.org/pdf/2006.07159.pdf).",35,1,Yuqing7,2020-06-23 19:30:30,https://www.reddit.com/r/deeplearning/comments/hel8wh/r_google_deepmind_researchers_revamp_imagenet/,0,deeplearning
gdzjut,Emotional Speech generation from Text,"Hi guys!

For a university course project, a few of us explored different TTS techniques for generating *emotional* speech (both HMM-based and Deep Learning-based). All our experiments are here - [https://github.com/Emotional-Text-to-Speech](https://github.com/Emotional-Text-to-Speech)

There is a gap in the literature while trying to fine-tuning pre-trained TTS models (trained on large datasets like LJ Speech) on low resource (emotional) speech data. We tried a lot of approaches ‚Äì most of them didn‚Äôt work out, and we thought that the TTS community could benefit from our findings and build up over these experiments üòÑ ‚Äì they are documented over here - [https://github.com/Emotional-Text-to-Speech/dl-for-emo-tts](https://github.com/Emotional-Text-to-Speech/dl-for-emo-tts)

We‚Äôve also released the models for all the approaches we tried (even if they didn‚Äôt work) along with their corresponding code for reproducibility purposes, along with some demos that can be played with!

Suggestions and comments are most welcome üòÄ",38,2,justachetan,2020-05-05 15:13:48,https://www.reddit.com/r/deeplearning/comments/gdzjut/emotional_speech_generation_from_text/,0,deeplearning
faxe0l,Deep Learning books to read in 2020,,38,3,przemekc,2020-02-28 16:36:18,https://towardsdatascience.com/deep-learning-books-you-should-read-in-2020-7806048c1dc5,0,deeplearning
coevrf,We developed arrow color detection using transfer learning and online training. For application in self driving mini rovers. It was really fun and exciting.,,36,8,bathon,2019-08-10 07:07:18,https://i.redd.it/t7tkrajbmkf31.gif,0,deeplearning
chqmjm,Winning Gold Medal on a Kaggle Competition using just kernels: Interview with Ryan Chesler,"To everyone who asks the question if free cloud resources are good enough for Kaggle Competitions, in this Interview with Kaggle Master Ryan Chesler, about his Gold Winning Solution to the Jigsaw ""Unintended Bias in Toxicity Classification"" Kaggle Competition, Ryan mentions their team did almost all of the workflow on JUST Kaggle kernels!  

Video: [https://www.youtube.com/playlist?list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1](https://www.youtube.com/playlist?list=PLyMom0n-MBrrGL8w-nD9kc2q5dOwN7Hb1)

&#x200B;

Podcast: [https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Master--ML-Engineer-Ryan-Chesler--Chai-Time-Data-Science-e4ntbt/a-ajj3f5](https://anchor.fm/chaitimedatascience/episodes/Interview-with-Kaggle-Master--ML-Engineer-Ryan-Chesler--Chai-Time-Data-Science-e4ntbt/a-ajj3f5)",36,5,init__27,2019-07-25 17:17:15,https://www.reddit.com/r/deeplearning/comments/chqmjm/winning_gold_medal_on_a_kaggle_competition_using/,0,deeplearning
blohe1,Understand objective functions in deep learning,,38,0,mQuBits,2019-05-07 09:14:22,https://youtu.be/N9mcfsHac1U,0,deeplearning
bidq1s,3 Machine Learning Books that Helped me Level Up,,38,1,papereraser,2019-04-28 17:34:50,http://www.datastuff.tech/data-science/3-machine-learning-books-that-helped-me-level-up-as-a-data-scientist/,0,deeplearning
b45tyi,Hinton's reading list from the removed Coursera MOOC,"Hi all,

&#x200B;

Geoffrey Hinton's Coursera MOOC was recently discontinued:

[https://twitter.com/geoffreyhinton/status/1085325734044991489?lang=en](https://twitter.com/geoffreyhinton/status/1085325734044991489?lang=en)

&#x200B;

The videos however are still available at both on Youtube and on Hinton's webpage:

[https://www.cs.toronto.edu/\~hinton/coursera\_lectures.html](https://www.cs.toronto.edu/~hinton/coursera_lectures.html)

&#x200B;

However in his MOOC Hinton also had some papers as required (or recommended, I can't really remember) readings after each lecture. They were generally old, seminal papers which provided some good insights and intuitions and were worth reading IMHO for learning purposes. I couldn't find these papers as a reading list online. Does anyone have this list?",37,3,durmusau,2019-03-22 14:38:50,https://www.reddit.com/r/deeplearning/comments/b45tyi/hintons_reading_list_from_the_removed_coursera/,0,deeplearning
ar1754,Get started with Google Colaboratory (Coding TensorFlow),,38,2,asuagar,2019-02-15 20:59:35,https://www.youtube.com/watch?v=inN8seMm7UI&list=PLQY2H8rRoyvyK5aEDAI3wUUqC_F0oEroL,0,deeplearning
124nlos,Big news! LambdaConf returns Sept 16-19th and is better than ever! üî•,"Join us in the Rockies for an unforgettable conference featuring thought-provoking talks, workshops, craft beer tasting, hiking, and immersive experiences that will change the way you think about software development. Grab your Early Bird Ticket: [https://www.eventbrite.com/e/lambda-conf-colorado-usa-in-person-only-tickets-540887036687](https://www.eventbrite.com/e/lambda-conf-colorado-usa-in-person-only-tickets-540887036687)",36,0,Agataziverge,2023-03-28 12:43:57,https://www.reddit.com/r/deeplearning/comments/124nlos/big_news_lambdaconf_returns_sept_1619th_and_is/,0,deeplearning
yvjge8,"Analog AI chip startup Mythic runs out of money, exec says",,38,4,fergy80,2022-11-15 01:52:30,https://www.theregister.com/2022/11/09/mythic_analog_ai_chips/,0,deeplearning
tt8dri,Made website with best resources I could find on GANs and Transformers.,"I spent \~50 hours ‚Äè‚Äè‚Äé looking for the best resources on various GANs and Transformer models and organized them into a website [backprop.org](https://backprop.org). Check it out! If mass find this useful I'll add more pages on more topics. Also, if you know any great resources that I missed send it my way!",36,2,Pretend-Alarm-7420,2022-03-31 20:04:31,https://www.reddit.com/r/deeplearning/comments/tt8dri/made_website_with_best_resources_i_could_find_on/,0,deeplearning
s1c8pc,From 53% to 95% acc - Real vs Fake Faces Classification | Fine-tuning EfficientNet (Github in comment),,39,16,oFlamingo,2022-01-11 12:54:38,https://i.redd.it/a20uwxqx22b81.png,0,deeplearning
ri0joa,[D] Try to explain the intuition of the Transformer's attention mechanism without any code and with animations. Please tell me how I did.,"Transformer-based models have been dominating NLP for quite some time. Recently it made inroads into other areas of machine learning like vision, audio, cybersecurity. Many are already using it and having a great time, and others often face a steep learning curve. At its core is the attention mechanism, which is none trivial thing to wrap your mind around. There were quite a lot of great explainers on the web already I know, but I struggled to find one doing it without codes or a lot of formulas, so I gave it a try and created one myself. I used the r/manim as my tool to create those animations. Please let me know how you feel. 

&#x200B;

[Intuition Builder: How to Wrap Your Mind Around Transformer‚Äôs Attention Mechanism](https://towardsdatascience.com/how-to-explain-transformer-self-attention-like-i-am-five-9020bf50b764)",37,2,lymenlee,2021-12-16 21:20:47,https://www.reddit.com/r/deeplearning/comments/ri0joa/d_try_to_explain_the_intuition_of_the/,0,deeplearning
ociduk,CVPR 2021: paper summaries and highlights (blog post),"The 2021 CVPR conference, one of the main computer vision and machine learning conferences, concluded its second 100% virtual version last week with a record of papers presented at the main conference. 1660 papers (vs 1467 papers last year) were accepted with an acceptance rate of 23.7% (vs 22.1% last year). Such a huge (and growing) number of papers can be a bit overwhelming, so if you want to get a quick overview of the conf, I hope this blog post can help with just that.

Blog post: https://yassouali.github.io/ml-blog/cvpr2021/",38,1,youali,2021-07-02 20:13:18,https://www.reddit.com/r/deeplearning/comments/ociduk/cvpr_2021_paper_summaries_and_highlights_blog_post/,0,deeplearning
nxikzm,[R] Yoshua Bengio Team Designs Consciousness-Inspired Planning Agent for Model-Based RL,"A research team from McGill University, Universit√© de Montr√©al, DeepMind and Mila presents an end-to-end, model-based deep reinforcement learning (RL) agent that dynamically attends to relevant parts of its environments to facilitate out-of-distribution (OOD) and systematic generalization.

Here is a quick read: [Yoshua Bengio Team Designs Consciousness-Inspired Planning Agent for Model-Based RL.](https://syncedreview.com/2021/06/11/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-39/)

The paper *A Consciousness-Inspired Planning Agent for Model-Based Reinforcement Learning* is on [arXiv](https://arxiv.org/abs/2106.02097).",34,1,Yuqing7,2021-06-11 15:25:10,https://www.reddit.com/r/deeplearning/comments/nxikzm/r_yoshua_bengio_team_designs/,0,deeplearning
m8tehb,3D Video Stabilization with AI via Depth Estimation & 3D Scene Reconstruction [NSFF],,39,0,cloud_weather,2021-03-19 22:52:09,https://youtu.be/3Bi3xuM-iWs,0,deeplearning
m2xpqj,Chatting with Google's DeepMind engineer about the future of AI,,37,1,ConfidentMushroom,2021-03-11 18:52:55,https://stackoverflow.blog/2021/03/02/podcast-317-deepmind-google-ai-deep-learning-muzero/,0,deeplearning
lepj87,"Neural Style Transfer AI with Multiple Styles, it looks better than expected!",,36,2,cloud_weather,2021-02-07 16:20:16,https://youtu.be/Eq7sYxf3XLM,0,deeplearning
kpll14,Nanograd: a Pytorch-like lightweight deep learning library,"[Nanograd](https://github.com/PABannier/nanograd)

I have been intrigued for a long time by automatic differentiation engine. I could not understand how gradients could be computed automatically without relying on numerical differentiation.

So I decided to write my own autograd library for learning purposes. I've pushed things a bit further by extending my library with DL capabilities: optimizers, layers, etc...

I got inspired by Geohotz's tinygrad and Karpathy's micrograd (only working for scalar values).

I started by solving Assignment 2 of CMU Deep Learning Course and then added features on top of it.

It is now a deep learning library.

A cool feature from Nanograd (display forward and backward computational graphs!):

&#x200B;

[Forward graph](https://preview.redd.it/7ip8o95oc6961.png?width=1888&format=png&auto=webp&s=864d7a57b0cef5a9459c875e4669e5c32bf15726)

&#x200B;

[Backward graph](https://preview.redd.it/ljjlsw9pc6961.png?width=1562&format=png&auto=webp&s=55cd06320a54a2111e31d004f027e6ef5239e8f2)

My next steps are: supporting GPU with PyOpenCL, have better visualization tools (activation maps of a CNN or attention visualizer for NLP)...

What do you guys think of it? Do you have any comments/ideas/recommendations?

Feel free to reach out!",37,0,Psychological-Ad5119,2021-01-03 14:34:52,https://www.reddit.com/r/deeplearning/comments/kpll14/nanograd_a_pytorchlike_lightweight_deep_learning/,0,deeplearning
jcra3v,Speech Separation + GitHub,,37,5,Independent-Square32,2020-10-17 08:06:35,https://youtu.be/STNklQIKQMw,0,deeplearning
j9ivsw,Interview with Tim Dettmers: Which RTX 3000 GPU(s) to get for Deep Learning?,"Hi Everyone! 

I run a non-monetised, Ad-free interview series as a service to the ML Community where I interview my ML Heroes. 

I had interviewed Tim Dettmers about his GPU advice now that the 3000 series is released:

[Audio](https://anchor.fm/chaitimedatascience/episodes/Tim-Dettmers-Which-RTX-3000-GPU-to-get-for-DL--3090-FAQ--CTDS-Show-108-ekeue8), [Video](https://www.youtube.com/watch?v=CaoQLrSBk0o)

I hope you find this useful and if you've any feedback for me, or guest suggestions, I'd be very grateful. Thanks!",37,9,init__27,2020-10-12 02:47:43,https://www.reddit.com/r/deeplearning/comments/j9ivsw/interview_with_tim_dettmers_which_rtx_3000_gpus/,0,deeplearning
ixm6yu,OCR in the Wild: SOTA in Text Detection and Recognition,"Check out this post to learn more about the **SOTA in scene text detection and recognition**: [https://www.sicara.ai/blog/ocr-text-detection-recognition](https://www.sicara.ai/blog/ocr-text-detection-recognition)

Deep learning has enabled a breakthrough in the field of OCR, making it possible to read complex text instances ""in the wild"".

3 papers are reviewed:

* Textsnake \[Long et al., 2018\], a text detection algorithm with the specificity of handling very complex text shapes.
* MORAN \[Luo et al., 2019\], a text recognition algorithm using a rectification network and the attention mechanism to correct and read complicated textboxes.
* FOTS \[Liu et al., 2018\], an end-to-end approach sharing the convolutions between the detection step and the recognition step to improve robustness and efficiency.",33,0,Noe_Achache,2020-09-22 12:14:21,https://www.reddit.com/r/deeplearning/comments/ixm6yu/ocr_in_the_wild_sota_in_text_detection_and/,0,deeplearning
inu5du,"Facebook AI open-sources Opacus, a new high-speed library for training PyTorch models with differential privacy (DP)","With the growing interest in machine learning (ML), the use of differential privacy is trending in analytics. It‚Äôs a mathematical rigorous framework for quantifying the anonymization of sensitive data. Keeping in mind this growing interest, Facebook AI launched Opacus.

Opacus is the new high-speed library for training PyTorch models with differential privacy. With minimal required code modifications, this library supports training and has minimal impact on training performance. Thus, It provides an easier path to adopt differential privacy in machine learning and boost research. Compared to the existing state-of-the-art methods, Opacus has a significant advantage of being more scalable.

Blog: [https://www.marktechpost.com/2020/09/06/facebook-ai-open-sources-opacus-a-new-high-speed-library-for-training-pytorch-models-with-differential-privacy-dp/](https://www.marktechpost.com/2020/09/06/facebook-ai-open-sources-opacus-a-new-high-speed-library-for-training-pytorch-models-with-differential-privacy-dp/)

Github: [https://github.com/pytorch/opacus?](https://github.com/pytorch/opacus?)",35,2,ai-lover,2020-09-06 21:14:59,https://www.reddit.com/r/deeplearning/comments/inu5du/facebook_ai_opensources_opacus_a_new_highspeed/,0,deeplearning
hqj29j,So a junior of mine at college wrote a program to convert an image to a Van-Gogh-like painting using neural style transfer. Got him to write a blog post about it. Tell me what you think!,,40,11,dush-t,2020-07-13 16:58:11,https://blog.bitsacm.in/neural-style-transfer-with-tensorflow/,0,deeplearning
gmns0l,"How does publishing in the Deep Learning world works, with respect to Journals and ArXive?","Let's say I implemented a new Deep Learning model that pushed some SOTA a little bit further, and I wrote a new paper about for publication.

How does it work now? I pictured three options:

1. **Submit it to a Conference**. Ok that's the easy one, I submit it to something like NeurIPS or ICML and hope to get accepted. At that point, how do you make your paper accessible? Are there problems in uploading it to ArXive later, in order to get read by more people?

2. **Upload it on ArXive directly**. If I do that it would not be peer reviewed, and technically speaking it would be devoid of ""academic value""... right? It could easily by anyone, but there would be no formal ""proof"" of its ""scientific quality"". Please correct me if I'm wrong.

3. **Submit it to a peer reviewed Journal**. Dodge desk rejection, dodge reviewers' rejection, after a long painful process it ends up on some international scientific Journal. At that point, since the article is formally Editor's property, can you still upload it on ArXive, or on your blog, so that it can be accessible by many people?

&#x200B;

How do the big stars of Deep Learning research do when they have some  hot new paper ready for publication? And what publications are the most  valued in the professional and the academic world?",41,15,Le2vo,2020-05-19 12:40:29,https://www.reddit.com/r/deeplearning/comments/gmns0l/how_does_publishing_in_the_deep_learning_world/,0,deeplearning
gid8ey,Full Autopilot in GTA using Tensorflow,"&#x200B;

*Processing video f8h1kgoupcy41...*

Hi, 

I spent the last month working on getting openpilot to work in GTA using Tensorflow. 

Here is the blog post, explaining everything:

[https://littlemountainman.github.io/2020/05/12/openpilot/](https://littlemountainman.github.io/2020/05/12/openpilot/)

If you have any suggestions, please let me know in the comments down below.",41,1,None,2020-05-12 15:22:17,https://www.reddit.com/r/deeplearning/comments/gid8ey/full_autopilot_in_gta_using_tensorflow/,0,deeplearning
g19xmt,New NVIDIA and Heidelberg University Viewpoint Estimation Technique Learns From Unlabelled Images,"A team of researchers from NVIDIA and Heidelberg University recently introduced an open-source self-supervised learning technique for viewpoint estimation of general objects that draws on such freely available Internet images: ‚ÄúWe seek to answer the research question of whether such unlabelled collections of in-the-wild images can be successfully utilized to train viewpoint estimation networks for general object categories purely via self-supervision.‚Äù

A quick read: [New NVIDIA and Heidelberg University Viewpoint Estimation Technique Learns From Unlabelled Images](https://medium.com/syncedreview/new-nvidia-and-heidelberg-university-viewpoint-estimation-technique-learns-from-unlabelled-images-6c642838467f)

In case you want to read the original paper [Self-Supervised Viewpoint Learning From Image Collections](https://arxiv.org/pdf/2004.01793v1.pdf)

You can find the open-source code at [GitHub](https://github.com/NVlabs/SSV).",41,0,Yuqing7,2020-04-14 17:33:06,https://www.reddit.com/r/deeplearning/comments/g19xmt/new_nvidia_and_heidelberg_university_viewpoint/,0,deeplearning
fnpszs,[R] Google Introduces Neuroevolution for Self-Interpretable Agents,"Good gamers can tune out distractions and unimportant on-screen information and focus their attention on avoiding obstacles and overtaking others in virtual racing games like Mario Kart. However, can machines behave similarly in such vision-based tasks? A possible solution is designing agents that encode and process abstract concepts, and research in this area has focused on learning all abstract information from visual inputs. This however is compute intensive and can even degrade model performance. Now, researchers from Google Brain Tokyo and Google Japan have proposed a novel approach that helps guide reinforcement learning (RL) agents to what‚Äôs important in vision-based tasks.

Quick read: [Google Introduces Neuroevolution for Self-Interpretable Agents](https://medium.com/syncedreview/google-introduces-neuroevolution-for-self-interpretable-agents-80afb69662c9)

The original papaer:  [*Neuroevolution of Self-Interpretable Agents*](https://arxiv.org/pdf/2003.08165.pdf)",34,0,Yuqing7,2020-03-23 19:06:49,https://www.reddit.com/r/deeplearning/comments/fnpszs/r_google_introduces_neuroevolution_for/,0,deeplearning
fc8y1h,Top 3 Artificial Intelligence Research Papers ‚Äì February 2020,,38,0,RubiksCodeNMZ,2020-03-02 08:11:49,https://rubikscode.net/2020/03/02/top-3-artificial-intelligence-research-papers-february-2020/,0,deeplearning
eefze8,Yoshua Bengio: From System 1 Deep Learning to System 2 Deep Learning (NeurIPS 2019),,36,2,DrJohanson,2019-12-23 05:10:42,https://www.youtube.com/watch?v=T3sxeTgT4qc,0,deeplearning
e9dwjw,Baidu's pre-training model ERNIE has achieved new SOTA on GLUE; 1st model to score over 90,,38,1,trcytony,2019-12-11 21:56:00,http://research.baidu.com/Blog/index-view?id=128,0,deeplearning
dl1ell,5 Awesome New Features ‚Äì Python 3.8,,37,2,RubiksCodeNMZ,2019-10-21 14:33:10,https://rubikscode.net/2019/10/21/5-awesome-new-features-python-3-8/,0,deeplearning
cl48ke,N-Shot Learning: Learning More with Less Data,,38,0,pirate7777777,2019-08-02 13:38:55,https://blog.floydhub.com/n-shot-learning/,0,deeplearning
b0h8h1,Tensorflow2.0 YouTube Tutorial!!,"Hey guys, I made a YouTube tutorial to help beginners learn to code their own neural networks with the high level API of Tensorflow2.0 as well as from the low level building blocks for custom models. Hope it helps with adapting to the new version of tf which is much easier to use than the first version!

Link: [https://www.youtube.com/watch?v=fQCKxzHvYnw](https://www.youtube.com/watch?v=fQCKxzHvYnw)

PS: My next tutorial would probably be something similar for tensorflow.js which I can also post here if people are interested.",36,3,shawnmanuel000,2019-03-13 03:32:16,https://www.reddit.com/r/deeplearning/comments/b0h8h1/tensorflow20_youtube_tutorial/,0,deeplearning
ad5q9b,A Layman guide to moving from Keras to Pytorch,,36,4,mlwhiz,2019-01-06 13:52:19,https://mlwhiz.com/blog/2019/01/06/pytorch_keras_conversion/?utm_campaign=shareaholic&utm_medium=reddit&utm_source=news,0,deeplearning
a7xedd,First complete online course on Generative Artificial Intelligence,"There is an online course on Generative AI coming up. --> [https://generativeai.net/](https://generativeai.net/)

As I believe Generative AI will affect the way we create content and develop products, this course is really valuable .

Perhaps interesting to you?",34,10,martinmusiol14,2018-12-20 12:23:07,https://www.reddit.com/r/deeplearning/comments/a7xedd/first_complete_online_course_on_generative/,0,deeplearning
9u6t3k,Tensorflow 2.0: models migration and new design,,41,0,pgaleone,2018-11-04 20:30:54,https://pgaleone.eu/tensorflow/gan/2018/11/04/tensorflow-2-models-migration-and-new-design/,0,deeplearning
186cwub,Run 70B LLM Inference on a Single 4GB GPU with Our New Open Source Technology,"Large language models require huge amounts of GPU memory. Is it possible to run inference on a single GPU? If so, what is the minimum GPU memory required?

The 70B large language model has parameter size of 130GB. Just loading the model into the GPU requires 2 A100 GPUs with 100GB memory each.

  
During inference, the entire input sequence also needs to be loaded into memory for complex ‚Äúattention‚Äù calculations. The memory requirement of this attention mechanism scales quadratically with the input length. On top of the 130GB model size, a lot more memory is needed.

  
We created this **open source technology - AirLLM** that can save so much memory and enable inference on a single 4GB GPU. You can achieve this with a few lines of codes!

Please check out our blog here for more details:

[https://medium.com/@lyo.gavin/unbelievable-run-70b-llm-inference-on-a-single-4gb-gpu-with-this-new-technique-93e2057c7eeb](https://medium.com/@lyo.gavin/unbelievable-run-70b-llm-inference-on-a-single-4gb-gpu-with-this-new-technique-93e2057c7eeb)",34,8,l_y_o,2023-11-29 01:22:46,https://www.reddit.com/r/deeplearning/comments/186cwub/run_70b_llm_inference_on_a_single_4gb_gpu_with/,0,deeplearning
14lapn4,"what causes these sudden spikes in val_loss, and how can I solve these.",,33,25,Outside-Berry6879,2023-06-28 14:16:23,https://i.redd.it/1nbbbbtgor8b1.png,0,deeplearning
ym5evl,NVIDIA RTX 4090 vs RTX 3090 Deep Learning Benchmarks,,33,6,mippie_moe,2022-11-04 17:47:04,https://lambdalabs.com/blog/nvidia-rtx-4090-vs-rtx-3090-deep-learning-benchmark,0,deeplearning
ylj1ux,BlogNLP: AI Writing Tool,"Hey everyone,

I created this web app using Open AI's GPT-3 (Davinci model). The purpose here is to provide a free tool to allow people to generate blog content/outlines/headlines and help with writer's block. Will continue to improve it over time, but just a side project I figured would provide some value to you all. Hope you all enjoy and please share ‚ù§Ô∏è

[https://www.blognlp.com/](https://www.blognlp.com/)",38,9,britdev,2022-11-03 23:55:15,https://www.reddit.com/r/deeplearning/comments/ylj1ux/blognlp_ai_writing_tool/,0,deeplearning
vo2aoq,Mad race for publishing a research paper,"   I work as a project assistant in a research lab at a university. In last 2 month I have observed one thing that everyone just wants to publish a paper as fast and as much as they can. In the process, I feel we always show the numbers which make our research look good and hide the ones that are not.  This whole thing just feels weird to me. In the end instead of tweaking the idea and making changes in your hypothesis, we always end up making changes in our experiment that make our hypothesis look valid. My question is , does this happen with others too  ?  PS: I work in deep learning research.",38,11,No_Incident_6009,2022-06-30 07:18:13,https://www.reddit.com/r/deeplearning/comments/vo2aoq/mad_race_for_publishing_a_research_paper/,0,deeplearning
v99o5e,How To Run DALL-E Mini On Your Own PC.,"DALLE-Mini has become really popular, so much so that the public access points are commonly overrun with traffic. Using the video below, one can run DALL-E Mini on their own computer, with or without a GPU! No more waiting on some overrun third-party service!

[https://www.youtube.com/watch?v=eWpzLIa6v9E](https://www.youtube.com/watch?v=eWpzLIa6v9E)",34,15,l33thaxman,2022-06-10 15:00:08,https://www.reddit.com/r/deeplearning/comments/v99o5e/how_to_run_dalle_mini_on_your_own_pc/,0,deeplearning
t49j82,Skilful precipitation nowcasting using deep generative models of radar - Link to a free online lecture by the author in comments (deepmind research published in nature),,35,1,dataskml,2022-03-01 14:47:04,https://i.redd.it/w1c0vxerbsk81.gif,0,deeplearning
s6z4cu,What is Singular Value Decomposition (SVD)? A 2-minute visual guide. [OC],"&#x200B;

https://preview.redd.it/ofr255wvkgc81.png?width=2048&format=png&auto=webp&s=ffad99201e68269e3f9b3841a0fdb2cc36b05e2e

https://preview.redd.it/w7mox5yvkgc81.png?width=2048&format=png&auto=webp&s=1dee2a386b8329b5acce65fa55cb484b0c7d20e7

https://preview.redd.it/ll4e8ayvkgc81.png?width=2048&format=png&auto=webp&s=604c55a30c47e5f28e7874b93777fad727287cab

https://preview.redd.it/kh7ddjwvkgc81.png?width=2048&format=png&auto=webp&s=d0b9aea1ea66511270344476777a6a748c0ba434

https://preview.redd.it/c5utvaxvkgc81.png?width=2048&format=png&auto=webp&s=81e039e4e53585a5f8f972983e6007b58b66de83

https://preview.redd.it/rpyk8ywvkgc81.png?width=2048&format=png&auto=webp&s=2e7589e95eb530d98f36c8ca3b347b8a49fe5e03

https://preview.redd.it/4ommddwvkgc81.png?width=2048&format=png&auto=webp&s=db68590271a04d6c98baa3606823db8e58bf51c3

üîµ Singular Value Decomposition üîµ

ü™Ñ Remember from the [post on eigenvectors](https://www.reddit.com/r/learnmachinelearning/comments/ruf6eq/what_is_an_eigenvector_a_2minute_visual_guide/): eigenvectors of a matrix are special vectors that only get scaled when the matrix is applied to them. While EVD (eigenvalue decomposition) can only be applied to special matrices (diagonalizable matrices) SVD is a generalization of EVD and can be applied to any rectangular matrix.

üß© Like prime factorization where a number is broken down to its prime factors (simpler pieces = prime numbers in this case); SVD factorizes the matrix into simpler pieces i.e. simpler matrices. This factorization or decomposition comes in handy for many applications some of which I briefly touch upon later.

üè•ü¶¥ Time for (somewhat of) an analogy: You can think of SVD as an x-ray of a matrix. It provides us with simpler pieces that constitute the matrix and by looking at these simpler pieces i.e. simpler matrices we can say a lot about the matrix in question. Things like its (pseudo-) inverse, rank, null-space, range among other things can be easily determined the same way a doctor can say a lot with an x-ray scan of your body.

üî® The Singular Value decomposition breaks the original matrix into 3 pieces: 2 unitary matrices and a rectangular diagonal matrix. You can draw a parallel with the Eigenvalue decomposition equation and see exactly how SVD has a more general form.

üîÑ With the help of the Singular Value decomposition we can explain what happens to an arbitrary vector when a matrix M is applied to it. Since M can be broken down into simpler pieces, we can represent the matrix M by a rotation, followed by scaling (by the singular values) and another rotation. So if you had a circle it would first be rotated then stretched by the singular values (becoming an ellipse) and finally be rotated to end up as a rotated ellipse.

üóúÔ∏è There are numerous applications of SVD. Perhaps you could comment on the ones that I missed but you know about. One of the nicest things you can get is the pseudo-inverse of a matrix without doing crazy matrix inversion. This is because the simple pieces that SVD provides are extremely easy to invert making inversion of the original matrix child's play. SVD is heavily applied in solving numerical problems such as solving linear equations that so frequently pop up in engineering.

üé• Data compression and computing low-rank approximations make it handy for compressing images and videos so you can watch cat videos without buffering. And of course, SVD has also been used for ranking web pages like Google's Pagerank algorithm does so you can find your favorite recipe with a quick search.

\---------------------------------------------------------------------------------

I have been studying and practicing Machine Learning and Computer Vision for 7+ years. As time has passed I have realized more and more the power of data-driven decision-making. Seeing firsthand what ML is capable of I have personally felt that it can be a great inter-disciplinary tool to automate workflows. I will bring up different topics of ML in the form of short notes which can be of interest to existing practitioners and fresh enthusiasts alike.

The posts will cover topics like statistics, linear algebra, probability, data representation, modeling, computer vision among other things. I want this to be an incremental journey, starting from the basics and building up to more complex ideas.

If you like such content and would like to steer the topics I cover, feel free to suggest topics you would like to know more about in the comments.",37,4,ml_a_day,2022-01-18 14:43:54,https://www.reddit.com/r/deeplearning/comments/s6z4cu/what_is_singular_value_decomposition_svd_a/,0,deeplearning
q4z8wm,Generate READMEs Using AI,"&#x200B;

https://i.redd.it/nbnqpn0f9js71.gif

You can use this program I wrote to generate readmes: [https://github.com/tom-doerr/codex-readme](https://github.com/tom-doerr/codex-readme)

It's far from perfect, but I'm still surprised how well it works if you give it a few tries. It often generates interesting usage examples and explains the available command line options.

You probably won't use this for larger projects, but I think this can make sense for small projects or single scripts. Many small scripts are very useful but might never be published because of the work that is required to document and explain it. Using this AI might assist you with that.

Be aware that you need to get access to OpenAI's Codex API to use it.

What do you think?",34,2,tomd_96,2021-10-10 02:22:26,https://www.reddit.com/r/deeplearning/comments/q4z8wm/generate_readmes_using_ai/,0,deeplearning
pt34es,"Salesforce Research Introduces ‚ÄòMerlion‚Äô, An Open-Source Machine Learning Library For Time Series Intelligence","Time series are a way to visualize and analyze the behavior of complex systems. They can represent key performance indicators for computing resources such as memory utilization or request latency, business metrics like revenue per day active users (DAU), marketing campaigns in social media reactions from customers through clickthrough rate. It is important to forecast the trends and values of key metrics accurately and rapidly detect a ny anomalies in those numbers. In software industries, anomaly detection is a critical machine learning technique to automate the identification of issues and improve IT system availability. It notifies the operator in a timely manner when something unexpected happens and helps them resolve underlying issues.

Salesforce research team introduces [Merlion](https://arxiv.org/pdf/2109.09265.pdf), an open-source Python library for time series intelligence. Merlion offers an end-to-end machine learning framework comprised of loading data, transforming it into useable formats, and building models. Once training has been completed, post-processing can include many aspects such as evaluating model performance or making predictions on what will happen in the future based on historical trends with some degree of accuracy.

# [5 Min Read](https://www.marktechpost.com/2021/09/22/salesforce-research-introduces-merlion-an-open-source-machine-learning-library-for-time-series-intelligence/) | [Paper](https://arxiv.org/pdf/2109.09265.pdf) | [Code](https://github.com/salesforce/Merlion)

&#x200B;

https://preview.redd.it/h6fuj8qpm0p71.png?width=984&format=png&auto=webp&s=7fe2798c4faaab551be0640ee48d0300015e6dbf",38,0,techsucker,2021-09-22 08:30:26,https://www.reddit.com/r/deeplearning/comments/pt34es/salesforce_research_introduces_merlion_an/,0,deeplearning
nzgkj3,"This Chinese Super Scale Intelligence Model, ‚ÄòWu Dao 2.0‚Äô, Claims To Be Trained Using 1.75 Trillion Parameters, Surpassing All Prior Models to Achieve a New Breakthrough in Deep Learning","Deep learning is one area of technology where ambitiousness has no barriers. According to a recent announcement by¬†[The Beijing Academy of Artificial Intelligence (BAAI)](https://www.baai.ac.cn/), in China, yet another milestone has been achieved in the field with its ‚ÄúWu Dao‚Äù AI system. The¬†[GPT 3](https://www.marktechpost.com/2020/08/02/gpt-3-a-new-breakthrough-in-language-generator/)¬†brought in new interest for all the AI researchers, the super scale pre training models. By this approach and making use of 175 billion parameters, it managed to achieve exceptional performance results across the natural language processing tasks (NLP). However, the lacking component is its inability to have any form of cognitive abilities or common sense. Therefore, despite the size, even these models cannot indulge in tasks such as open dialogues, visual reasoning, and so on. With Wu Dao, the researchers plan to address this issue. This is China‚Äôs first attempt at a home-grown super-scale intelligent model system.¬†

Article: [https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/](https://www.marktechpost.com/2021/06/13/this-chinese-super-scale-intelligence-model-wu-dao-2-0-claims-to-be-trained-using-1-75-trillion-parameters-surpassing-all-prior-models-to-achieve-a-new-breakthrough-in-deep-learning/?_ga=2.13897584.636390090.1623335762-488125022.1618729090)

Reference: [https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/](https://syncedreview.com/2021/03/23/chinas-gpt-3-baai-introduces-superscale-intelligence-model-wu-dao-1-0/)",38,9,ai-lover,2021-06-14 06:34:33,https://www.reddit.com/r/deeplearning/comments/nzgkj3/this_chinese_super_scale_intelligence_model_wu/,0,deeplearning
mbzox6,Geoffrey Hinton Fellowship for Artificial Intelligence | Godfather of AI Live,"[**Univ.AI**](http://univ.ai/) is an institution founded by **Harvard & UCLA** professors of Artificial Intelligence and Machine Learning aiming to make state-of-the-art AI education available beyond the confines of the world‚Äôs top institutions.

We are inaugurating and launching [Geoffrey Hinton Fellowship (GHF)](https://www.univ.ai/ghf) for Artificial Intelligence and Machine Learning as a pre-eminent platform for recognising and rewarding the nation's top talent in AI, Machine Learning and Data Science. GHF inauguration will be graced by an enriching lecture on **part-whole hierarchies in neural networks by Prof. Geoffrey Hinton** himself.

We invite all the fellow Redditors for this rare & exclusive opportunity to attend **Prof. Geoffrey Hinton‚Äôs lecture on 27th March 2021, 9 AM IST.** The lecture will be followed by a Q&A session. **Watch Geoff Hinton‚Äôs last interview with** [**Andrew Ng here**](https://youtu.be/-eyhCTvrEtE)

**Seats are limited.**  [**Register**](https://www.univ.ai/events/geoffrey-hinton-live?ref=GHF-EXPERIMENTATION)¬†for FREE on the GHF page to interact with Geoff Hinton LIVE.

**About Prof. Geoffrey Hinton**

Prof Geoffrey Hinton is known to many as the **Godfather of AI.** He introduced the famous backpropagation algorithm in his seminal 1986 paper and has made immense contributions to **deep learning**. He is the recipient of the prestigious **Turing Award** and currently splits his time as a professor of Computer Science at the University of Toronto and as the VP and Engineering Fellow at Google.

Best,

Team [Univ.AI](http://univ.ai/)",34,5,Hound301099,2021-03-24 07:06:12,https://www.reddit.com/r/deeplearning/comments/mbzox6/geoffrey_hinton_fellowship_for_artificial/,0,deeplearning
lpjwuv,torch.nn.Embedding explained (+ Character-level language model),,36,2,mildlyoverfitted,2021-02-22 09:27:17,https://youtu.be/euwN5DHfLEo,0,deeplearning
l2uu2h,[D] - Best deep CNN architectures and their principles: from AlexNet to EfficientNet,"How convolutional neural networks architectures are designed?

What are the principles behind designing one CNN architecture?

How did we go from AlexNet to EfficientNet?

Back    in 2012,  Alexnet scored 63.3% Top-1 accuracy on ImageNet. Now, we  are   over 90%  with EfficientNet architectures and teacher-student   training.

In  this article, we   will focus on the evolution of convolutional neural  networks (CNN)   architectures. Rather than reporting plain numbers, we  will focus on   the fundamental principles.

Link: [https://theaisummer.com/cnn-architectures/](https://theaisummer.com/cnn-architectures/)

Contents:

\- **AlexNet**

\- **VGG**

\- **InceptionNet** V1,V2,V3

\- **ResNet**: Deep Residual Learning for Image Recognition

\- **DenseNet**: Densely Connected Convolutional Networks (2017)

\- Big Transfer (**BiT**): General Visual Representation Learning (2020)

\- **EfficientNet**: Rethinking Model Scaling for Convolutional Neural Networks (2019) ++",36,2,black0017,2021-01-22 19:19:27,https://www.reddit.com/r/deeplearning/comments/l2uu2h/d_best_deep_cnn_architectures_and_their/,0,deeplearning
k5wn5k,Resources/papers to understand transformers and attention,"I have an overall understanding of deep learning. But I have always struggled to understand attention and transforms completely :( . What are good papers/resources I can use to gain a deep understanding, given they are becoming more essential everyday ?",38,25,NewPhoneWhuDis,2020-12-03 12:52:03,https://www.reddit.com/r/deeplearning/comments/k5wn5k/resourcespapers_to_understand_transformers_and/,0,deeplearning
jlsjwa,Job interviews in data science - my experience copy-pasting solutions,,36,1,mostafabenh,2020-10-31 23:38:41,https://melwy.com/blog/job-interviews-in-data-science-my-experience-copy-pasting-solutions,0,deeplearning
g0nna2,"Age detection in images and real-time video streams with OpenCV, Deep Learning, and Python",,38,4,cmillionaire9,2020-04-13 17:37:52,https://youtu.be/y4vh1wRkEWA,0,deeplearning
fxzvra,[P] Curated List of Semi-Supervised Learning Papers & Resources.,"Hi everybody,

In the last few months, I spent a lot of time working on semi-supervised learning (SSL), and seeing the rising interest in SSL approaches in deep learning, I thought I create a list [*] of SSL resources to make navigating the growing number of papers easier. It includes papers per tasks, books, surveys, blog posts and talks. 

[*] https://github.com/yassouali/awesome-semi-supervised-learning

If you found any errors or any missing papers you like, please consider creating a pull request. thanks.",37,7,youali,2020-04-09 20:21:32,https://www.reddit.com/r/deeplearning/comments/fxzvra/p_curated_list_of_semisupervised_learning_papers/,0,deeplearning
fpfut4,Perfect setup - Jetson at the edge / PC for training,,37,11,gimel1213,2020-03-26 17:39:25,https://i.redd.it/oqjqifdvz1p41.jpg,0,deeplearning
egvfiq,"TensorFlow Implementation of Graphical Attention RNNs (Cirstea et. al, 2019)","I really enjoyed this [paper](https://milets19.github.io/papers/milets19_paper_8.pdf) on graphical attention RNNs. It is basically a clever way to combine a Graph Attention Mechanism [(Veliƒçkoviƒá et al., 2017)](https://arxiv.org/abs/1710.10903) with a Diffusion Convolutional RNN [(Li et al., 2017)](https://arxiv.org/pdf/1707.01926.pdf). As the authors did not provide an implementation, I decided to create one myself. My implementation can be found [here](https://github.com/LeviBorodenko/garnn).

Hope it may be of use to somebody. Any feedback would be greatly appreciated.",34,0,Gedanke,2019-12-28 20:03:23,https://www.reddit.com/r/deeplearning/comments/egvfiq/tensorflow_implementation_of_graphical_attention/,0,deeplearning
eemskh,CMU Senior Develops World‚Äôs First Classical Chinese Programming Language,,35,2,Yuqing7,2019-12-23 16:31:05,https://medium.com/syncedreview/cmu-senior-develops-worlds-first-classical-chinese-programming-language-7ffe7fca75ad,0,deeplearning
dp81be,250+ Machine Learning and Deep Learning Resources (Courseware and Lecture Videos),,35,1,None,2019-10-30 15:09:35,https://www.hashtagtechgeek.com/2019/10/250-machine-learning-deep-learning-videos-courseware.html,0,deeplearning
de4l53,"AR + AI | AutoML Vision Edge, AutoML Video, and Video Intelligence API",,35,3,cmillionaire9,2019-10-06 15:20:40,https://youtu.be/KUVVVquQsAM,0,deeplearning
d961tz,CS 236: Deep Generative Models,"Lecture Notes Fall 2019-2020


#AI #artificialintelligence #deeplearning #generativemodels
#GANs 

https://deepgenerativemodels.github.io/",36,6,aiforworld2,2019-09-25 16:52:53,https://www.reddit.com/r/deeplearning/comments/d961tz/cs_236_deep_generative_models/,0,deeplearning
chvlbh,Google Colab RAM increase,"It looks like Colab is beginning to allocate users 24GB worth of RAM instead of the default of 12. Is anyone else seeing this? This morning I tried running my model, and a messaged popped up saying to ""reset runtime to get more ram"" after my session crashed [1]. There also seems to be new UI upgrades?

[1] https://imgur.com/a/n8bUNhu",34,5,nulleq,2019-07-26 00:04:43,https://www.reddit.com/r/deeplearning/comments/chvlbh/google_colab_ram_increase/,0,deeplearning
bl6zpc,OPENCV Kickstarter Campaign,"Dear Friends,   
We at OpenCV.org will launch a Kickstarter campaign in about a week for three courses

1. Computer Vision I: Introduction
2. Computer Vision II: Applications 
3. Deep Learning with PyTorch

Please sign up below to stay informed:  
[https://opencv.org/courses](https://opencv.org/courses?fbclid=IwAR09uJ6A2xS5KmeBb0xiPVPlmhyOV9yoywObXtPFUVKGZoQ13s2nQ6HMPQ4)

We need your help to spread the word. Please share this with your friends and colleagues.   
Many thanks,

Satya Mallick & Gary Bradski

https://reddit.com/link/bl6zpc/video/odfsrju9giw21/player",38,5,spmallick,2019-05-06 03:31:45,https://www.reddit.com/r/deeplearning/comments/bl6zpc/opencv_kickstarter_campaign/,0,deeplearning
bipu7x,"A PyTorch implementation of ""Semi-Supervised Graph Classification: A Hierarchical Graph Perspective"" (WWW 2019)","&#x200B;

https://preview.redd.it/hsoze1lhm7v21.jpg?width=1619&format=pjpg&auto=webp&s=45b33c8b445eb416bcaf1d9ce21fce4a9b8d5076

GitHub: [https://github.com/benedekrozemberczki/SEAL-CI](https://github.com/benedekrozemberczki/SEAL-CI)

Paper: [https://arxiv.org/pdf/1904.05003.pdf](https://arxiv.org/pdf/1904.05003.pdf)

Abstract:

Node classification and graph classification are two graph learning  problems that predict the class label of a node and the class label of a  graph respectively. A node of a graph usually represents a real-world  entity, e.g., a user in a social network, or a protein in a  protein-protein interaction network. In this work, we consider a more  challenging but practically useful setting, in which a node itself is a  graph instance. This leads to a hierarchical graph perspective which  arises in many domains such as social network, biological network and  document collection. For example, in a social network, a group of people  with shared interests forms a user group, whereas a number of user  groups are interconnected via interactions or common members. We study  the node classification problem in the hierarchical graph where a \`node'  is a graph instance, e.g., a user group in the above example. As labels  are usually limited in real-world data, we design two novel  semi-supervised solutions named Semi-supervised graph classification via  Cautious/Active Iteration (or SEAL-C/AI in short). SEAL-C/AI adopt an  iterative framework that takes turns to build or update two classifiers,  one working at the graph instance level and the other at the  hierarchical graph level. To simplify the representation of the  hierarchical graph, we propose a novel supervised, self-attentive graph  embedding method called SAGE, which embeds graph instances of arbitrary  size into fixed-length vectors. Through experiments on synthetic data  and Tencent QQ group data, we demonstrate that SEAL-C/AI not only  outperform competing methods by a significant margin in terms of  accuracy/Macro-F1, but also generate meaningful interpretations of the  learned representations.",36,0,benitorosenberg,2019-04-29 14:03:21,https://www.reddit.com/r/deeplearning/comments/bipu7x/a_pytorch_implementation_of_semisupervised_graph/,0,deeplearning
bfktmx,[R] FineGAN: Unsupervised Hierarchical Disentanglement for Fine-Grained Object Generation and Discovery (CVPR'19 Oral presentation),,38,3,utkarsh2254,2019-04-21 03:45:56,https://www.youtube.com/watch?v=tkk0SeWGu-8,0,deeplearning
ah1hp7,"Amazon Object2Vec: Deep Representation Learning for general-purpose objects such as sentences, customers, products and sequences",,36,1,fairworldcup,2019-01-17 19:33:40,https://aws.amazon.com/blogs/machine-learning/introduction-to-amazon-sagemaker-object2vec/,0,deeplearning
ae5ckd,DEMO: Automatic image captioning with visual attention using PyTorch,,37,3,ahmedbesbes,2019-01-09 09:50:28,https://www.youtube.com/watch?v=RlNjzz358Jc,0,deeplearning
a6ohy1,What‚Äôs the best resource for learning Reinforcement Learning?,"I am an undergraduate computer science student and I‚Äôm currently studying deep learning. So far, I have only worked with supervised and unsupervised learning.
Now I want to learn Reinforcement Learning, where can I start? ",36,9,BrunoMelicio,2018-12-16 11:55:09,https://www.reddit.com/r/deeplearning/comments/a6ohy1/whats_the_best_resource_for_learning/,0,deeplearning
9eb5f7,Stanford's Deep Learning cheatsheet ‚Ä¢ r/MachinesLearn,,32,0,lohoban,2018-09-09 06:57:33,https://www.reddit.com/r/MachinesLearn/comments/9duxeu/stanfords_deep_learning_cheatsheet/,0,deeplearning
881ywa,YOLO v3 Release!,,36,4,onmywaytostealyagirl,2018-03-29 15:02:39,https://pjreddie.com/darknet/yolo/,0,deeplearning
160z5pp,AI Meets AI: A Conversation Between GPT-4 and Google's Bard,,36,3,Ubica123,2023-08-25 13:21:12,https://www.youtube.com/watch?v=3H45IncZ7gs,0,deeplearning
x07rfw,ODD Platform - An open-source data discovery and observability service for data-driven enterprises looking to democratize data,,35,3,firig1965,2022-08-28 22:17:56,https://github.com/opendatadiscovery/odd-platform,0,deeplearning
ulxzk8,"Here's a repository where I try to keep up with the most interesting research papers of 2022. It is a curated list of the latest breakthroughs in AI and Data Science by release date with a clear video explanation, link to a more in-depth article, and code (if applicable).",,36,2,OnlyProggingForFun,2022-05-09 18:37:09,https://github.com/louisfb01/best_AI_papers_2022,0,deeplearning
rpnmbd,"Visualization of different optimizers (SGD, SGD Momentum, Nesterov, AdaGrad, RMSProp, Adam)",,37,3,c_wald,2021-12-27 13:31:42,https://i.imgur.com/LDvafLI.mp4,0,deeplearning
o2rxis,"[R] Game On! MIT, Allen AI & Microsoft Open-Source a Suite of AI Programming Puzzles","A research team from MIT, Allen Institute for AI and Microsoft Research open-sources Python Programming Puzzles (P3), a novel programming challenge suite that captures the essence of puzzles and can be used to teach and evaluate an AI's programming proficiency. 

Here is a quick read: [Game On! MIT, Allen AI & Microsoft Open-Source a Suite of AI Programming Puzzles.](https://syncedreview.com/2021/06/18/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-44/)

The paper *Programming Puzzles* is on [arXiv](https://arxiv.org/abs/2106.05784).",34,1,Yuqing7,2021-06-18 15:37:27,https://www.reddit.com/r/deeplearning/comments/o2rxis/r_game_on_mit_allen_ai_microsoft_opensource_a/,0,deeplearning
nf0kov,Intel makes GTA V Hyperrealistic with CNN's,,35,15,Snoo28889,2021-05-18 03:58:07,https://youtu.be/eE7WmJl7j14,0,deeplearning
m1bn5f,Deep Neural Network Training Flow Chart. Any suggestions to improve it?,"I made a Flow chart inspired by  [u/komi96](https://www.reddit.com/user/komi96/)'s chart (source): [https://www.reddit.com/r/deeplearning/comments/hf0ngb/i\_made\_a\_flow\_chart\_on\_how\_to\_train\_deep\_neural/?utm\_source=share&utm\_medium=web2x&context=3](https://www.reddit.com/r/deeplearning/comments/hf0ngb/i_made_a_flow_chart_on_how_to_train_deep_neural/?utm_source=share&utm_medium=web2x&context=3)

The whole thing is made in [draw.io](https://draw.io). Let me know what you guys think.

EDIT: I realized its difficult to box things like I have done. This is more of a rudimentary guide rather then any form of law since there is all sorts of grey zones depending on the situation. 

EDIT: Updated graph

https://preview.redd.it/pgnetyyfj8m61.png?width=1363&format=png&auto=webp&s=7354b176030d2585ab25a6a0fea4efbe24816235",38,11,Rephil1,2021-03-09 17:35:53,https://www.reddit.com/r/deeplearning/comments/m1bn5f/deep_neural_network_training_flow_chart_any/,0,deeplearning
l5xfhj,AI takes dynamic photos,,37,1,cmillionaire9,2021-01-27 05:35:50,https://youtu.be/Xx3rORzRm-0,0,deeplearning
kbmb1q,Node2Vec: Scalable Feature Learning for Networks | ML with Graphs | Research Paper Walkthrough,,35,1,prakhar21,2020-12-12 09:25:01,https://youtu.be/LpwGZG5j_q0,0,deeplearning
k38d1b,Graph neural network resouces,,35,2,Restaurant_Awkward,2020-11-29 12:07:11,https://hhaji.github.io/Deep-Learning/Graph-Neural-Networks/,0,deeplearning
jlf0ue,[R] Memory Optimization for Deep Networks,"**Abstract:** This new research presents MONET, a system for automatically reducing memory requirements for training deep networks. MONET jointly optimizes local (operator-level) and global (graph-level) optimizations to yield a compute- and memory-efficient checkpointing schedule. MONET reduces memory usage by 3√ó over PyTorch, with a compute overhead of 9 ‚àí 16%. It can also use 1.2-1.8√ó less memory than the state-of-the-art automated checkpointing framework for the same computational cost. Experimental results show that MONET leads to better memory-computation trade-offs compared to the state-of-the-art.

Github: [https://github.com/utsaslab/MONeT](https://github.com/utsaslab/MONeT)

Paper link: [https://arxiv.org/abs/2010.14501v2](https://arxiv.org/abs/2010.14501v2)",37,3,cdossman,2020-10-31 08:43:41,https://www.reddit.com/r/deeplearning/comments/jlf0ue/r_memory_optimization_for_deep_networks/,0,deeplearning
jbf93c,Mini Neural Network Framework,"I'm writing a framework for mini neural networks from scratch, to try make it easier for people to understand what's going on under the hood, and how the choice of different training algorithms and activation functions affect your results.

As of right now, I've implemented backpropagation and the genetic algorithm, and will soon be adding more.

If you're interested in the project's progress, you can find the github link [here](https://github.com/evanbernard/MiniNeuralNets)",35,10,evanbernard0,2020-10-15 02:38:41,https://www.reddit.com/r/deeplearning/comments/jbf93c/mini_neural_network_framework/,0,deeplearning
j67r95,Does this mean my model is overfitting!? FYI - I'm trying to make a text generator using LSTM RNN.,,32,34,h_buddana,2020-10-06 16:04:23,https://i.redd.it/c8e4oxqpzhr51.jpg,0,deeplearning
hip427,What are the 50 layers of resnet50? I know that each conv block and identity block has 3 convolution layers. So 4 conv blocks +12 identity blocks= 16*3=48 conv layers. Which are the other two layers. Is pooling and padding not considered a layer?,,36,3,None,2020-06-30 15:08:24,https://i.redd.it/bhp5sosfc2851.png,0,deeplearning
hhptzi,Revealing Dark Secrets of BERT (Analysis of BERT's Attention Heads) - Paper Explained,,31,1,deeplearningperson,2020-06-29 00:30:03,https://youtu.be/mnU9ILoDH68,0,deeplearning
gywb0h,Free live hands-on python lecture about using generative neural networks to create art - for redditors,,33,5,pinter69,2020-06-08 09:41:26,https://i.redd.it/e1pp21v22n351.jpg,0,deeplearning
gx38kx,Neuromorphic Computing: The Next-Level Artificial Intelligence,,31,1,Albertchristopher,2020-06-05 12:01:52,https://www.artiba.org/blog/neuromorphic-computing-the-next-level-artificial-intelligence,0,deeplearning
gr5ysy,[R] NVIDIA‚Äôs GameGAN Uses AI to Recreate Pac-Man and Other Game Environments,"Aiming at training a game simulator that can model both the deterministic and stochastic nature of environments, researchers from NVIDIA, University of Toronto, Vector Institute and MIT have proposed a simulator that learns by simply watching an agent interact with its environment.  Focusing on games as a proxy of real environments ‚Äî and particularly on the seminal Pac-Man, which turns 40 this year ‚Äî the researchers propose GameGAN, a generative model that learns to visually imitate video game environments by ingesting screenplay and keyboard actions during training. 

Here is a quick read: [NVIDIA‚Äôs GameGAN Uses AI to Recreate Pac-Man and Other Game Environments](https://medium.com/syncedreview/nvidias-gamegan-uses-ai-to-recreate-pac-man-and-other-game-environments-798f833dac64)

The paper *Learning to Simulate Dynamic Environments with GameGAN* was accepted to CVPR 2020 and is on [arXiv](https://arxiv.org/pdf/2005.12126.pdf). There is also a project page on [GitHub](https://nv-tlabs.github.io/gameGAN/).",37,1,Yuqing7,2020-05-26 21:22:43,https://www.reddit.com/r/deeplearning/comments/gr5ysy/r_nvidias_gamegan_uses_ai_to_recreate_pacman_and/,0,deeplearning
ehjj1x,NeurIPS 2019 Outstanding Machine Learning Paper Awards,,34,0,RubiksCodeNMZ,2019-12-30 08:37:21,https://rubikscode.net/2019/12/30/neurips-2019-outstanding-machine-learning-paper-awards/,0,deeplearning
e6h4a0,SparkTorch: Distributed training of PyTorch networks on Apache Spark with ML Pipeline support,,34,0,lodev12,2019-12-05 13:23:03,https://github.com/dmmiller612/sparktorch,0,deeplearning
dt50v4,UNSUPERVISED LEARNING OF 3D REPRESENTATIONS FROM NATURAL IMAGES,,37,4,cmillionaire9,2019-11-07 21:54:18,https://youtu.be/lxZhmr9ebAo,0,deeplearning
dpi61w,Bayesian Deep Learning Summer School 2019, [https://github.com/bayesgroup/deepbayes-2019](https://github.com/bayesgroup/deepbayes-2019),37,9,data_datum,2019-10-31 03:52:02,https://www.reddit.com/r/deeplearning/comments/dpi61w/bayesian_deep_learning_summer_school_2019/,0,deeplearning
dmh9kc,Share the implementation of 44.1K Enhanced Singing Voice Separation.,"Hi guys! I did share my Source Separation (Single Channel) Deep Learning(AI) implementation.

github :  [https://github.com/AppleHolic/source\_separation](https://github.com/AppleHolic/source_separation)

Recently I add ""Singing Voice Separation"" with DSD100 dataset.

Mainly, it is trained with 44.1k sample rate to satisfy my ears. And it is trained jointly Voice Bank, DSD100 and Audioset dataset.

&#x200B;

You can checkout the test sample on my youtube playlist that has 5 my favorite songs!

\- List :

\- Sung Si Kyung - On the Street

\- Linkin Park - Pushing me Away

\- Baek Ye Rin - His Ocean

\- Cheeze - Moments for everyone

\- Taeyeon - Four Seasons

\- link :  [https://www.youtube.com/playlist?list=PLQ4ukFz6Ieir5bZYOns08\_2gMjt4hYP4I](https://www.youtube.com/playlist?list=PLQ4ukFz6Ieir5bZYOns08_2gMjt4hYP4I)

&#x200B;

One of them, ""Sung Si Kyung - On the street"" is added the shifted vocal track with 2 db volume down. So, it can feel fresh to listeners who did already hear that song.

\- link :  [https://www.youtube.com/watch?v=xmoBUf\_6b0c&list=PLQ4ukFz6Ieir5bZYOns08\_2gMjt4hYP4I&index=1](https://www.youtube.com/watch?v=xmoBUf_6b0c&list=PLQ4ukFz6Ieir5bZYOns08_2gMjt4hYP4I&index=1)

&#x200B;

I will keeping to try my best on application and research area on Speech and Music. If you find some problems or improvement for this model, freely contact me.

Thanks.",34,4,choiilji,2019-10-24 14:34:30,https://www.reddit.com/r/deeplearning/comments/dmh9kc/share_the_implementation_of_441k_enhanced_singing/,0,deeplearning
d0gnp0,We present a (Poly-GAN) novel way for fitting clothes virtually on a person.,"&#x200B;

[https://arxiv.org/abs/1909.02165v1](https://arxiv.org/abs/1909.02165v1)

> We present Poly-GAN, a novel conditional GAN architecture that is motivated by Fashion Synthesis, an application where garments are automatically placed on images of human models at an arbitrary pose. Poly-GAN allows conditioning on multiple inputs and is suitable for many tasks, including image alignment, image stitching, and inpainting. Existing methods have a similar pipeline where three different networks are used to first align garments with the human pose, then perform stitching of the aligned garment and finally refine the results. Poly-GAN is the first instance where a common architecture is used to perform all three tasks. Our novel architecture enforces the conditions at all layers of the encoder and utilizes skip connections from the coarse layers of the encoder to the respective layers of the decoder. Poly-GAN is able to perform a spatial transformation of the garment based on the RGB skeleton of the model at an arbitrary pose. Additionally, Poly-GAN can perform image stitching, regardless of the garment orientation, and inpainting on the garment mask when it contains irregular holes. Our system achieves state-of-the-art quantitative results on Structural Similarity Index metric and Inception Score metric using the DeepFashion dataset.  

We will be happy to share code as well .

Thanks",33,7,None,2019-09-06 13:27:22,https://www.reddit.com/r/deeplearning/comments/d0gnp0/we_present_a_polygan_novel_way_for_fitting/,0,deeplearning
c7p9kg,Begin creating Deep Learning models. A list of things I wish I knew a year ago (xpost /r/learnmachinelearning),,35,1,s_cond,2019-07-01 06:46:22,https://link.medium.com/bZN6vTOGXX,0,deeplearning
buqaw4,Head Pose Estimation using OpenCV and Dlib,,39,2,spmallick,2019-05-30 07:33:37,https://v.redd.it/6iyc50bpwa131,0,deeplearning
bt57e3,Gradient boosting research papers from the last 25 years,"&#x200B;

[https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers](https://github.com/benedekrozemberczki/awesome-gradient-boosting-papers)

A curated list of gradient boosting research papers with implementations from the following conferences.

Machine learning:

1. NeurIPS
2. ICML
3. ICLR

Computer vision:

1. CVPR
2. ICCV
3. ECCV

Natural language processing:

1. ACL
2. NAACL
3. EMNLP

Data Mining:

1. KDD
2. ICDM
3. CIKM
4. WWW

Artificial intelligence:

1. AAAI
2. IJCAI
3. UAI
4. AISTATS",34,2,benitorosenberg,2019-05-26 07:32:19,https://www.reddit.com/r/deeplearning/comments/bt57e3/gradient_boosting_research_papers_from_the_last/,0,deeplearning
6zejuv,Google Launches Free Course on Deep Learning: The Science of Teaching Computers How to Teach Themselves,,34,5,firmsecure,2017-09-11 10:31:40,http://www.openculture.com/2017/07/google-launches-free-course-on-deep-learning.html,0,deeplearning
18wlv4m,"Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory - Free eBook","## [Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory](https://arxiv.org/abs/2310.20360)    


### **Authors:**        
*    Arnulf Jentzen, 
*    Benno Kuckuck, 
*    Philippe von Wurstemberger

This book aims to provide 
*an introduction to the topic of **deep learning** algorithms*. 

We review 
**essential components of deep learning algorithms** in 
**full mathematical detail** including
*    different **artificial neural network** (ANN) architectures such as     
     *    fully-connected feedforward ANNs,  
     *    convolutional ANNs, 
     *    recurrent ANNs,     
     *    residual ANNs, and     
     *    ANNs with batch normalization

* and different **optimization algorithms** such as    
    *    the basic stochastic gradient descent (SGD) method, 
    *    accelerated methods, and 
    *    adaptive methods. 

*    We also cover several theoretical aspects of deep learning algorithms such as     
     *    approximation capacities of ANNs (including a calculus for ANNs),     
     *    optimization theory (including Kurdyka-≈Åojasiewicz inequalities), and.    
     *    generalization errors. 

*    In the last part of the book,      
     *    some deep learning approximation methods for PDEs are reviewed, including      
     *    physics-informed neural networks (PINNs) and     
     *    deep Galerkin methods.      

We hope that **this book will be useful**

*    for students and scientists  who do not yet have any background in deep learning at all and would like **to gain a solid foundation** as well as 
*    for practitioners who would like **to obtain a firmer mathematical understanding of the objects and methods considered in deep learning**.

*    **Comments:**	
601 pages, 36 figures, 45 source codes    . 

* **Subjects**:	    
    *    Machine Learning (cs.LG); 
    *    Artificial Intelligence (cs.AI); 
    *    Numerical Analysis (math.NA); 
    *    Probability (math.PR); 
    *    Machine Learning (stat.ML)",36,4,reddit007user,2024-01-02 09:55:55,https://www.reddit.com/r/deeplearning/comments/18wlv4m/mathematical_introduction_to_deep_learning/,0,deeplearning
18e8djb,How to handle extreme large datasets,"I want to learn techniques to handle extremely large datasets say tens of millions of rows.
If I have to create a pipeline of how I can preprocess the data, do inference write outputs to table in minimum time. What are some best practices which can speed up the pipeline/workflow ?",33,22,h2986bm,2023-12-09 07:38:35,https://www.reddit.com/r/deeplearning/comments/18e8djb/how_to_handle_extreme_large_datasets/,0,deeplearning
12wxrrd,Can an average person learn how to build a LLM model?,"Hello everyone. I am a 30-year-old Korean male.

To be honest, I have never really studied properly in my life. It's a little embarrassing, but that's the truth.

Recently, while using ChatGPT, I had a dream for the first time. I want to create a chatbot that can provide a light comfort to people who come for advice. I would like to create an LLM model using Transformer, and use our country's beginner's counseling manual as the basis for the database.

I am aware that there are clear limits to the level of comfort that can be provided. Therefore, if the problem is too complex or serious for this chatbot to handle, I would like to recommend the nearest mental hospital or counseling center based on the user's location. And, if the user can prove that they have visited the hospital (currently considering a direction where the hospital or counseling center can provide direct certification), I would like to create a program that provides simple benefits (such as a free Starbucks coffee coupon).

I also thought about collecting a database of categories related to people's problems (excluding personal information) and selling it to counseling or psychiatric societies. I think this could be a great help to these societies.

The problem is that I have never studied ""even once,"" and I feel scared and fearful of the unfamiliar sensation. I have never considered myself a smart person.

However, I really want to make this happen! Our country is now in a state of constant conflict, and people hate and despise each other due to strong propaganda.

As a result, the birth rate has dropped to less than 1%, leading to a decline in the population. Many people hide their pain inside and have no will to solve it. They just drink with their friends to relieve their pain. This is obviously not a solution. Therefore, Korea has a really serious suicide rate.

I may not be able to solve this problem, but I want to put one small brick to build a big barrier to stop hatred. Can an ordinary person who knows nothing learn the common sense and study needed to build an LLM model? And what direction should one take to study one by one?",34,30,sch1zoph_,2023-04-24 01:17:58,https://www.reddit.com/r/deeplearning/comments/12wxrrd/can_an_average_person_learn_how_to_build_a_llm/,0,deeplearning
125gzq5,"Stable Diffusion on Apple Silicon M1, M2 with CoreML v0.3.0 Released",,34,0,Time_Key8052,2023-03-29 08:04:57,https://stablediffusion.tistory.com/entry/Run-Stable-Diffusion-on-Mac-Silicon-M1-M2-with-CoreML-v030-Released,0,deeplearning
xd9kff,Transfer Learning is one of the most power techniques for neural networks,,31,0,roycoding,2022-09-13 14:49:29,https://i.redd.it/4p3j8qej1nn91.png,0,deeplearning
w7zhqn,What regularization does to a machine learning model,,36,1,roycoding,2022-07-25 20:33:45,https://i.redd.it/k72b1a9vmrd91.png,0,deeplearning
rdgyo4,"Neural networks can hide malware, researchers find",,37,5,bendee983,2021-12-10 19:51:58,https://bdtechtalks.com/2021/12/09/evilmodel-neural-networks-malware/,0,deeplearning
pghhn0,[Question] Anyone interested in a AI Computer Vision Drone Workshop?,Would you be interested in building a Drone from scratch and programming it using Python and OpenCV?,32,37,NickFortez06,2021-09-02 13:05:04,https://www.reddit.com/r/deeplearning/comments/pghhn0/question_anyone_interested_in_a_ai_computer/,0,deeplearning
oji7dz,Best Computer Vision Google Colab Notebooks List (Updated),,37,0,imapurplemango,2021-07-13 15:40:34,https://www.qblocks.cloud/creators/computer-vision-google-colab-notebooks,0,deeplearning
ocwo2i,CVPR 2021 Best Paper Award: GIRAFFE - Controllable Image Generation,,33,1,OnlyProggingForFun,2021-07-03 11:56:01,https://youtu.be/JIJkURAkCxM,0,deeplearning
o4uzmu,"5 minute paper digest: GANs N‚Äô Roses: Stable, Controllable, Diverse Image to Image Translation (works for videos too!) by Min Jin Chong et al.","Did you ever want to see what you look like as an anime waifu? Thanks to the authors of GANs N' Roses you can animefy (pretty sure this isn't a real word) selfies and even videos with a multitude of unique styles. The authors from the University of Illinois propose a new generator architecture that combines a content code computed from a face image and a randomly chosen style to produce consistent, diverse and controllable anime faces with attributes matching the content image.

Read the [full paper digest](https://t.me/casual_gan/53) (reading time \~5 minutes) to learn about the encoder-decoder architecture of the authors' content-style image generation method, the tricks for ensuring style diversity, and the losses required for high fidelity anime image synthesis.

Meanwhile, check out the paper digest poster by [Casual GAN Papers](https://t.me/casual_gan)!

[GANs N' Roses](https://preview.redd.it/veidtaxndm671.png?width=1877&format=png&auto=webp&s=f7495dac0ffebd79d18908299fe413943e25afce)

\[[Full Explanation Post](https://t.me/casual_gan/53)\] \[[Arxiv](https://arxiv.org/pdf/2106.06561v1.pdf)\] \[[Code](https://github.com/mchong6/GANsNRoses)\]

More recent popular computer vision paper breakdowns:

>[CIPS](https://t.me/casual_gan/51)  
[SimSwap](https://t.me/casual_gan/52)  
[Decision Transformer](https://t.me/casual_gan/50)",34,1,None,2021-06-21 13:20:35,https://www.reddit.com/r/deeplearning/comments/o4uzmu/5_minute_paper_digest_gans_n_roses_stable/,0,deeplearning
mrus8v,"[N] NVIDIA, Stanford & Microsoft Propose Efficient Trillion-Parameter Language Model Training on GPU Clusters","A research team from NVIDIA, Stanford University and Microsoft Research propose a novel pipeline parallelism approach that improves throughput by more than 10 percent with a comparable memory footprint, showing such strategies can achieve high aggregate throughput while training models with up to a trillion parameters.

Here is a quick read: [NVIDIA, Stanford & Microsoft Propose Efficient Trillion-Parameter Language Model Training on GPU Clusters](https://syncedreview.com/2021/04/15/nvidia-stanford-microsoft-propose-efficient-trillion-parameter-language-model-training-on-gpu-clusters/).

The paper *Efficient Large-Scale Language Model Training on GPU Clusters* is on [arXiv](https://arxiv.org/pdf/2104.04473.pdf).",32,0,Yuqing7,2021-04-16 03:21:33,https://www.reddit.com/r/deeplearning/comments/mrus8v/n_nvidia_stanford_microsoft_propose_efficient/,0,deeplearning
movew1,Deep Learning with TensorFlow - free course from udemy,,32,2,Ordinary_Craft,2021-04-11 17:44:48,https://www.myfreeonlinecourses.com/2021/04/100-off-deep-learning-with-tensorflow.html,0,deeplearning
lmog2d,The world's largest scale Turing Test / Do you think OpenAI's GPT3 is good enough to pass the Turing Test?,,35,11,theaicore,2021-02-18 14:52:00,https://www.theaicore.com/imitationgame?utm_source=reddit,0,deeplearning
ky4g3w,Enrollment open for Deep Learning with Python MIT course,,34,5,ConfidentMushroom,2021-01-15 21:34:01,https://www.edx.org/course/machine-learning-with-python-from-linear-models-to,0,deeplearning
kn1r63,Paper reading group,"Hi, fellow (ex-)scholars!

TL;DR: I want to set up a paper reading group in current machine learning research. If you want to join, please reply or DM me.

I obtained a master's degree in AI two years ago. Since then, I feel like it's hard to keep up with research in deep learning and stay in the loop. I can imagine that there are multiple scholars and ex-scholars like me who want to stay up-to-date with current research, broaden and deepen their knowledge in AI, meet like-minded people, discuss ideas, and improve their presentation skills. So I was thinking that it might be a fun idea to start a paper reading group. If you are interested, please reply or DM me, and we'll see if we can set something up.

I would be very open to suggestions and want this to be a joint effort. However, currently, I had the following in mind: Every two/three weeks we organize a meeting over zoom. In this meeting, one participant will present a summary of the chosen paper, probably using some slides. All other participants have read the paper to some degree such that we can ask questions and discuss the paper and its implications after the presentation. On Slack, we will appoint the next presenter. He/she can pick their own paper, but we will also start a poll where everyone can add suggestions and vote for the papers they are most interested in. Ideally, I would say that the group is not too big (~5-30 max.), and is somewhat fixed. This way, we can get to know each other a bit, create some accountability, and keep the discussions lively!
In terms of topics, I'd say that anything AI-related goes; Theoretical or applied research, NLP, CV, from fundamental papers on SVM's to state-of-the deep learning research, but also evolutionary algorithms, knowledge graphs, and anything in-between. Based on current research interests, deep learning research of the last few years will probably be the popular topic though.

Looking forward to discussing papers with you!

Edit: Wow, that's quite some interest. I believe you should be able to join with this link: üëã  Let‚Äôs move this to Slack! We‚Äôve got 56 folks from the team there already. You can sign up here: https://join.slack.com/t/aischolars/shared_invite/zt-kwbtz1fq-vaQaoXKBps9masEX7wYXkg",32,63,porpkcab,2020-12-30 12:54:23,https://www.reddit.com/r/deeplearning/comments/kn1r63/paper_reading_group/,0,deeplearning
jzl6sf,Updated list of Best Computer Vision Google Colab Notebooks,,32,4,imapurplemango,2020-11-23 16:47:06,https://www.qblocks.cloud/creators/computer-vision-google-colab-notebooks,0,deeplearning
i637nv,Testing the demo of DeepFaceDrawing: Deep Generation of Face Images from Sketches,,34,0,ayvin_tech,2020-08-08 17:39:05,https://youtu.be/BFvJkrUmV64,0,deeplearning
h8sv31,AI animated the characters and plays basketball very naturally,,38,4,cmillionaire9,2020-06-14 12:21:35,https://youtu.be/u4PoIk2lPNk,0,deeplearning
f31d6o,Yann LeCun looks like Aaron Courville,,34,7,CaptainJack011,2020-02-13 00:42:53,https://i.redd.it/ln9zew388lg41.jpg,0,deeplearning
evkss3,"Bengio, Hinton, LeCun AI Panel. Deep Learning Summit, Montreal.",,36,1,BlockDelta,2020-01-29 09:42:35,https://blockdelta.io/bengio-hinton-lecun-ai-panel-flashback-video-deep-learning-summit-montreal/,0,deeplearning
en34py,[Code released] LipGAN - Synthesize high-quality talking face videos from any speech,"Github code: [https://github.com/Rudrabha/LipGAN](https://github.com/Rudrabha/LipGAN)

Demo Video: [https://www.youtube.com/watch?v=aHG6Oei8jF0](https://www.youtube.com/watch?v=aHG6Oei8jF0)",31,2,prajwalkr,2020-01-11 05:02:15,https://www.reddit.com/r/deeplearning/comments/en34py/code_released_lipgan_synthesize_highquality/,0,deeplearning
eicj3r,Quantum CNN,,36,1,trn_anttal,2020-01-01 02:10:39,https://www.nature.com/articles/s41567-019-0648-8,0,deeplearning
ee2xm4,[Project] YOLO v3 on Christopher Nolan's Tenet using Python,,35,4,ankmahato,2019-12-22 09:04:42,https://www.youtube.com/watch?v=k37wFIKR0FI,0,deeplearning
dx8osj,About beam search,,33,6,Sahil8141,2019-11-16 16:04:45,https://i.redd.it/3fhuu3ckn2z31.png,0,deeplearning
d5bw0z,what's next after coursera Andrew Ng's course,"Of course, completing it we will not have 100% understanding.

Can you guys guide me on how to hone my skills?  
Kaggle? Reading simple CNN papers?

Should I go for [fast.ai](https://fast.ai) ? Will it be good enough if I'm proficient with [fast.ai](https://fast.ai) ?

Appreciate your advice.

Thanks",31,21,snip3r77,2019-09-17 04:18:20,https://www.reddit.com/r/deeplearning/comments/d5bw0z/whats_next_after_coursera_andrew_ngs_course/,0,deeplearning
c867v4,Coolest Papers of CVPR 2019,What are some of the Coolest papers of CVPR 2019?,38,2,PyWarrior,2019-07-02 07:21:17,https://www.reddit.com/r/deeplearning/comments/c867v4/coolest_papers_of_cvpr_2019/,0,deeplearning
9ejpgs,Papers with Code,I'm working on making a list of Machine Learning papers that has open source code on GitHub. My initial version can be reached at the link included below. I think it will be helpful to this community to select their next paper to read. Please also include your comments and suggestions for improvement. https://github.com/zziz/pwc,34,4,None,2018-09-10 04:37:53,https://www.reddit.com/r/deeplearning/comments/9ejpgs/papers_with_code/,0,deeplearning
8ifdsh,How to implement a YOLO (v3) object detector from scratch in PyTorch: Part 1,,34,0,bzindovic,2018-05-10 14:40:46,https://blog.paperspace.com/how-to-implement-a-yolo-object-detector-in-pytorch/,0,deeplearning
6e5jyi,Essential Cheat Sheets for Machine Learning and Deep Learning Engineers,,35,2,kailashahirwar12,2017-05-30 06:01:02,https://medium.com/@kailashahirwar/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5,0,deeplearning
17d35dp,Is pytorch not good for production,"I have to write a ML algorithm from scratch and confused whether to use tensorflow or pytorch. I really like pytorch as it's more pythonic but I found articles and other things which suggests tensorflow is more suited for production environment than pytorch. So, I am confused what to use and why pytorch is not suitable for production environment and why tensorflow is suitable for production environment.",31,41,ssiddharth408,2023-10-21 13:56:52,https://www.reddit.com/r/deeplearning/comments/17d35dp/is_pytorch_not_good_for_production/,0,deeplearning
13h42ep,Graph depicting all Vector Database Providers and their tools (some work research got a bit out of hand),,32,7,use_excalidraw,2023-05-14 05:56:27,https://i.redd.it/71pwnft2lqza1.png,0,deeplearning
11dxokj,"""This is the moment I've been training for,"" said the pun-generating AI",,33,5,PaulCalhoun,2023-02-28 05:15:11,https://paulcalhoun.substack.com/p/this-is-the-moment-ive-been-training,0,deeplearning
yhww89,Best Practices from Provectus for Migrating and Optimizing Amazon EMR Workloads,,35,1,TallAssociation0,2022-10-31 01:24:49,https://aws.amazon.com/blogs/apn/best-practices-from-provectus-for-migrating-and-optimizing-amazon-emr-workloads/,0,deeplearning
xav2ef,MLPerf submission from Neural Magic: 175X increase in NLP Performance utilizing sparsity,,31,10,markurtz,2022-09-10 17:33:10,https://i.redd.it/2vqk1wqah2n91.png,0,deeplearning
wwv1o4,Run stable diffusion in google colab including image2image,,32,2,Illustrious_Row_9971,2022-08-24 21:16:26,https://i.redd.it/zr3hsohg9qj91.png,0,deeplearning
uu415l,Defect Detection using Synthetic Data,,31,1,moetsi_op,2022-05-20 18:07:54,https://v.redd.it/1pn9jsoc7n091,0,deeplearning
u6ei2u,Collection of Kaggle Past Solutions (to learn ideas and techniques),"I have collected here \[1,2\] almost all available solutions and ideas with codes shared by top performers in the past Kaggle competitions. This list gets updated as soon as a new competition finishes. It allows you to search over the Kaggle past competitions solutions and ideas. Please share it with your friends.

\[1\] [https://github.com/faridrashidi/kaggle-solutions](https://github.com/faridrashidi/kaggle-solutions)

\[2\] [https://farid.one/kaggle-solutions/](https://farid.one/kaggle-solutions/)

&#x200B;

https://preview.redd.it/6r0uqdlisau81.jpg?width=2669&format=pjpg&auto=webp&s=6947832ba0d28afcb4cf8d45a52dcab284360059",33,2,faridrashidi,2022-04-18 14:30:17,https://www.reddit.com/r/deeplearning/comments/u6ei2u/collection_of_kaggle_past_solutions_to_learn/,0,deeplearning
rvx22m,"[R] A Neural Network Solves, Grades & Generates University-Level Mathematics Problems by Program Synthesis","In the new paper A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More, a research team from MIT, Columbia University, Harvard University and University of Waterloo proposes a neural network that can solve university-level mathematics problems via program synthesis. 

Here is a quick read: [A Neural Network Solves, Grades & Generates University-Level Mathematics Problems by Program Synthesis.](https://syncedreview.com/2022/01/04/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-177/)

The paper *A Neural Network Solves and Generates Mathematics Problems by Program Synthesis: Calculus, Differential Equations, Linear Algebra, and More* is on [arXiv](https://arxiv.org/abs/2112.15594).",34,0,Yuqing7,2022-01-04 15:32:12,https://www.reddit.com/r/deeplearning/comments/rvx22m/r_a_neural_network_solves_grades_generates/,0,deeplearning
rur374,I like YOLOv5 but the code complexity is...,"I can't deny that YOLOv5 is a practical open-source object detection pipeline.
However, the pain begins when adding new features or new experimental methods. Code dependencies are hard to follow which makes the code difficult to maintain.
We wanted to try various experimental methods but hate to write one-time code that is never re-used.

So we worked on making an object detection pipeline to have a better code structure so that we could continuously improve and add new features while easy to maintain.

https://github.com/j-marple-dev/AYolov2

And we applied CI(Formating, Linting, Unittest) to ensure code quality with Docker support for development and inference. Our Docker supports the development environment with VIM.

Our code design from the beginning was to try various experimental methods with fewer efforts. The features so far developed are as follows.

1. You can easily use the trained model for another project without code copy and paste.
PyTorch requires model code to use the model. We build the model by the library that builds the PyTorch model from the YAML file (https://github.com/JeiKeiLim/kindle). So the trained model is portable with pip install kindle.
2. Model compression support by tensor decomposition and pruning.
3. Export model to TorchScript, ONNX, and TensorRT
4. Inference with TorchScript and TensorRT
5. (WIP) C++ Inference with TorchScript and TensorRT
6. Auto search for NMS parameter
7. (WIP) Knowledge distillation support
8. (WIP) Representation learning support

AYolov2 also supports W&B with model upload and load function to make trained models easy to manage.

`python3 val.py --weights j-marple/AYolov2/179awdd1 `

For instance, the above single command line will download the trained model from W&B and run the inference.

By the time you read here, you might wonder why the name is AYolov2. AYolov2 comes from Auto-yolo v2. Our initial goal was to implement an auto model architecture search.  And v2 represents that there was v1. Where did v1 go? We have built an auto model architecture search based on the original yolov5 and it worked pretty nice but it became unmanageable. Please stay tuned NAS feature will be coming soon.

If you have any suggestions or feedback, any kind will be appreciated.

Thank you and happy new year!",35,2,workout_JK,2022-01-03 02:55:07,https://www.reddit.com/r/deeplearning/comments/rur374/i_like_yolov5_but_the_code_complexity_is/,0,deeplearning
pb0hmd,"DeepMind Open-Sources Perceiver IO, A General-Purpose Deep Learning Model Architecture That Handles A Wide Range of Data and Tasks","Recently, DeepMind has open-sourced Perceiver IO‚Äìa general-purpose deep learning model architecture that can handle many different types of inputs and outputs. This ‚Äúdrop-in‚Äù replacement for Transformers is powerful enough to outperform baseline models without being constrained by domain knowledge.

A new [preprint on arXiv describes Perceiver IO](https://arxiv.org/pdf/2107.14795.pdf), a more general version of the AI architecture that can produce many different outputs from multiple inputs. This means it is applicable to real-world domains like language and vision as well as difficult games like StarCraft II. Unlike Perceiver, Perceiver IO is an advanced model that overcomes the limitation of only being able to produce very simple outputs by learning how to flexibly query the latent space.

[4 Min Read](https://www.marktechpost.com/2021/08/24/deepmind-open-sources-perceiver-io-a-general-purpose-deep-learning-model-architecture-that-handles-a-wide-range-of-data-and-tasks/) | [Paper](https://arxiv.org/pdf/2107.14795.pdf) | [Codes](https://github.com/deepmind/deepmind-research/tree/master/perceiver)",33,2,techsucker,2021-08-25 00:54:24,https://www.reddit.com/r/deeplearning/comments/pb0hmd/deepmind_opensources_perceiver_io_a/,0,deeplearning
p5bydz,What is 6 month plan becoming beginner level Data Scientist?,,36,6,courseonline-info,2021-08-16 08:29:14,https://i.redd.it/kadj49wqkoh71.png,0,deeplearning
ninvez,3D Neural Network simulation,,31,10,DevTechRetopall,2021-05-22 17:41:52,https://www.youtube.com/watch?v=j53noXmkBRQ,0,deeplearning
mo8lua,Growing neural cellular automata in PyTorch,,31,2,mildlyoverfitted,2021-04-10 17:05:15,https://youtu.be/21ACbWoF2Oo,0,deeplearning
mkd9lg,[D] Deep Learning Performance Cheat Sheet,Tips to help you boost your DL model accuracy [DL performance cheat sheet](https://www.educateai.org/deep-learning-performance-cheat-sheet/?fbclid=IwAR3sEsEE4P5q-oEGCsAemywjYpHZs89SjPJeVD-UFI6bgx7JGS1G1HHVRcw),35,3,cdossman,2021-04-05 05:12:18,https://www.reddit.com/r/deeplearning/comments/mkd9lg/d_deep_learning_performance_cheat_sheet/,0,deeplearning
m5sa5s,"Trained an StyleGAN2-Ada on Naruto characters and got a trippy result. So, here is NaruTrip.",,34,2,None,2021-03-15 19:09:13,https://youtu.be/uxF2HI7gkcc,0,deeplearning
liuetx,AI Nose,,36,9,cmillionaire9,2021-02-13 05:47:18,https://youtu.be/W4K82-RnNT8,0,deeplearning
l83whb,The Time Series Transformer (Keras Code Included),,33,6,Zarkopafilis,2021-01-29 20:54:23,https://towardsdatascience.com/the-time-series-transformer-2a521a0efad3,0,deeplearning
khuz46,"[Research 2020] The best AI papers of 2020 with a clear video demo, short read, paper, and code for each of them.","The best AI papers of 2020 with a clear video demo, short read, paper, and code for each of them.

In-depth **Medium article**:  
[https://medium.com/towards-artificial-intelligence/2020-a-year-full-of-amazing-ai-papers-a-review-c42fa07aff4b](https://medium.com/towards-artificial-intelligence/2020-a-year-full-of-amazing-ai-papers-a-review-c42fa07aff4b)

The full list on **GitHub**: [https://github.com/louisfb01/Best\_AI\_paper\_2020](https://github.com/louisfb01/Best_AI_paper_2020)",29,3,OnlyProggingForFun,2020-12-22 01:21:43,https://www.reddit.com/r/deeplearning/comments/khuz46/research_2020_the_best_ai_papers_of_2020_with_a/,0,deeplearning
kaga0k,JetBrains introduced KotlinDL: Keras-like high-level Kotlin Framework,,31,0,belovrv,2020-12-10 14:34:01,https://blog.jetbrains.com/kotlin/2020/12/deep-learning-with-kotlin-introducing-kotlindl-alpha/,0,deeplearning
k53iuq,"Alpha fold 2, a deep learning based system solved a 50 year old complex protein folding problem","Although the work is not published yet but it is suspected to be a transformers and attention based deep neural network.  
Google's Deep Mind is responsible for developing Alpha Fold 2.  
Perhaps first Nobel Prize in medicine for deep learning ??  
[https://www.deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery](https://www.deepmind.com/blog/article/AlphaFold-Using-AI-for-scientific-discovery)",31,3,mohsintariq10,2020-12-02 05:54:29,https://www.reddit.com/r/deeplearning/comments/k53iuq/alpha_fold_2_a_deep_learning_based_system_solved/,0,deeplearning
hwc3kj,23 Amazing Deep Learning Project Ideas,,33,0,AnujG23,2020-07-23 08:33:53,https://googleweblight.com/i?u=https://data-flair.training/blogs/deep-learning-project-ideas/,0,deeplearning
hm3exs,I have created a Python package for boilerplate code for TensorFlow 2.0 in deep learning! Is anyone interested?,"Git Repo - [https://github.com/amifunny/tf-stitch](https://github.com/amifunny/tf-stitch)

Pip package - [https://pypi.org/project/tf-stitch/](https://pypi.org/project/tf-stitch/)

Hey all, this is my first community post. I am an amateur programmer. I have created a python package that could possibly help you if you work on deep learning in TensorFlow 2.x. 

It just takes from you arguments for model and dataset or your project domain like NLP, vision to generate boilerplate code in TF2.0 which could increase your efficiency. I myself have felt the pain of writing same code again and again which distracts you from implementing new ideas.

I would be delighted to hear your feedback and feel free to contribute.",35,2,amifunny247,2020-07-06 07:52:04,https://www.reddit.com/r/deeplearning/comments/hm3exs/i_have_created_a_python_package_for_boilerplate/,0,deeplearning
gkqm5h,"A highly efficient, real-time text-to-speech system deployed on CPUs ‚Äî Facebook Research",,33,1,PowerOfLove1985,2020-05-16 07:25:06,https://ai.facebook.com/blog/a-highly-efficient-real-time-text-to-speech-system-deployed-on-cpus/,0,deeplearning
g8j13j,You can manipulate faces in high resolution,,34,1,cmillionaire9,2020-04-26 18:01:25,https://youtu.be/t4Zx5pbG278,0,deeplearning
ed5rot,Facebook has a neural network that can do advanced math,"Paper: [https://arxiv.org/pdf/1912.01412.pdf](https://arxiv.org/pdf/1912.01412.pdf)

Article: [https://www.technologyreview.com/s/614929/facebook-has-a-neural-network-that-can-do-advanced-math/?fbclid=IwAR3ypddJzj9ei-DWVeUOlAsdMN-1DdWTy2jpiWAUSijNn8OXkeU9-ITFetk](https://www.technologyreview.com/s/614929/facebook-has-a-neural-network-that-can-do-advanced-math/?fbclid=IwAR3ypddJzj9ei-DWVeUOlAsdMN-1DdWTy2jpiWAUSijNn8OXkeU9-ITFetk) 

&#x200B;

https://preview.redd.it/8whvaal76q541.png?width=727&format=png&auto=webp&s=f67bc8a1f93979da74556c1b2e8f9061736bccab",30,1,ai-lover,2019-12-20 05:37:56,https://www.reddit.com/r/deeplearning/comments/ed5rot/facebook_has_a_neural_network_that_can_do/,0,deeplearning
dwwmnr,This PyTorch Library ‚ÄòKaolin‚Äô is Accelerating 3D Deep Learning Research [Paper and Github included in article],,30,2,ai-lover,2019-11-15 20:44:09,https://www.marktechpost.com/2019/11/15/this-pytorch-library-kaolin-is-accelerating-3d-deep-learning-research/,0,deeplearning
dp0apq,Advanced Deep Learning Topics, [https://lilianweng.github.io/lil-log/](https://lilianweng.github.io/lil-log/),36,4,data_datum,2019-10-30 02:04:19,https://www.reddit.com/r/deeplearning/comments/dp0apq/advanced_deep_learning_topics/,0,deeplearning
d3u1ud,I made a doodle classifier web app,,33,0,nerdy_wits,2019-09-13 19:12:27,https://youtu.be/fEXgDxg698E,0,deeplearning
cuvbsr,What is a Tensor ?,,31,7,nowsden,2019-08-24 16:13:16,https://youtu.be/DkLFSHraMko,0,deeplearning
cq9zk2,Gesture generation by Deep Learning: A demo,,33,0,Svito-zar,2019-08-14 13:54:18,https://youtu.be/tQLVyTVtsSU,0,deeplearning
ckoybr,"For those of you that are unfamiliar with Keras, here is a great video-introduction that explains exactly what it is.",,33,3,antaloaalonso,2019-08-01 14:17:06,https://www.youtube.com/watch?v=yMzTrZ3_NIA&t=4s,0,deeplearning
bnq3z7,"Applied deep learning tutorial covering basics and variations (Autoencoder, LSTM,...)","Hello

I have some machine learning background and I know a little about neural networks. Now I plan to use deep learning in a project using Keras on Python.  In my project I'm using smartphone sensor data (acceleration, gyroscope, touch) as input to predict user behavior. Before I start I would like to read or watch a tutorial about deep learning providing the basics but more on an applied side.

I have found the lecture from stanford [http://cs231n.stanford.edu/](http://cs231n.stanford.edu/). It seems to be applied but it only covers CNN and RNN and is tied to visual recognition (I'm working with sensor data and not in the visual domain). I have also found two tutorial articles [http://ai.stanford.edu/\~quocle/tutorial1.pdf](http://ai.stanford.edu/~quocle/tutorial1.pdf) and [http://ai.stanford.edu/\~quocle/tutorial2.pdf](http://ai.stanford.edu/~quocle/tutorial2.pdf). They cover Autoencoders, CNN and RNN but it seems to be less applied and brief.

Does somebody know a good tutorial (article or video) about deep learning which covers the basics but also the different variations like Autoencoders, LSTM and so on. I'm interested in applied introductions, i.e. I'm not interested in proofs and deriving backproagation for all variations. It would also be nice to get some pratical tips about how to train it and so on.",33,7,Helveticus99,2019-05-12 15:24:47,https://www.reddit.com/r/deeplearning/comments/bnq3z7/applied_deep_learning_tutorial_covering_basics/,0,deeplearning
bmlxax,MIT explains neural networks,,34,0,aiforworld2,2019-05-09 16:32:21,https://news.mit.edu/2017/explained-neural-networks-deep-learning-0414,0,deeplearning
bf3y2k,10 Deep Learning Resources for Audio Processing,,31,1,oblivionreb,2019-04-19 20:32:06,https://codesmithdev.com/10-deep-learning-resources-for-audio-processing/,0,deeplearning
aszd70,Gender & Age Classification using OpenCV Deep Learning,"Ever wondered what a person's real age was? Or have you seen a baby and been really confused if it is a boy or a girl? Well, guess what! LearnOpenCV has a new blog post and it reveals how you can easily guess age and gender using OpenCV Deep Learning

https://reddit.com/link/aszd70/video/fhe21zxwyuh21/player

[https://www.learnopencv.com/age-gender-classification-using-opencv-deep-learning-c-python/](https://www.learnopencv.com/age-gender-classification-using-opencv-deep-learning-c-python/)

We'll be using Convolutional Neural Network (CNN) architecture, and focus on honing the Age Prediction Model.   
Like, tag your friends and follow us for more of such exciting stuff! Mention reviews and what you want us to work on next, in the comments!",30,2,spmallick,2019-02-21 05:36:07,https://www.reddit.com/r/deeplearning/comments/aszd70/gender_age_classification_using_opencv_deep/,0,deeplearning
anqciv,"Awesome papers, new tools, AI news and research reviews [with codes!] on Computer Vision News. Links for free reading!","Hot off the Press! Here are the links to the February 2019 issue of Computer Vision News, the magazine of the algorithm community published by RSIP Vision: many articles about Artificial Intelligence and Autonomous Driving. Free subscription on page 40.

[HTML5 version (recommended)](https://www.rsipvision.com/ComputerVisionNews-2019February/)

[PDF version](https://www.rsipvision.com/computer-vision-news-2019-february-pdf/)

Enjoy!

https://preview.redd.it/8agvmvyw1ye21.jpg?width=400&format=pjpg&auto=webp&s=fd87f6b74358a79d2c00cdfc5131db0ae3818570",34,0,Gletta,2019-02-06 12:44:54,https://www.reddit.com/r/deeplearning/comments/anqciv/awesome_papers_new_tools_ai_news_and_research/,0,deeplearning
aekg6b,Stanford Open-Sources Neural Network Verification Project,,33,0,gwen0927,2019-01-10 16:12:58,https://medium.com/syncedreview/stanford-open-sources-neural-network-verification-project-d2dba0cd21f6,0,deeplearning
9pcpyr,DeepMind Open-Sources RL Library TRFL,,31,0,gwen0927,2018-10-18 20:02:29,https://medium.com/syncedreview/deepmind-open-sources-rl-library-trfl-6cb40c0f9dc7,0,deeplearning
9kt7vf,BigGAN: A New State of the Art in Image Synthesis,,31,1,gwen0927,2018-10-02 18:28:05,https://medium.com/syncedreview/biggan-a-new-state-of-the-art-in-image-synthesis-cf2ec5694024,0,deeplearning
919he1,Evolutionary algorithm outperforms deep-learning machines at video games,,31,3,_b0t,2018-07-23 18:15:35,https://www.technologyreview.com/s/611568/evolutionary-algorithm-outperforms-deep-learning-machines-at-video-games/,0,deeplearning
81cfp5,Machine Learning Crash Course | Google Developers,,31,1,semi23,2018-03-02 06:52:57,https://developers.google.com/machine-learning/crash-course/,0,deeplearning
1bkb95p,How much time do Ai/Ml engineer spend doing Coding?,"I have been learning ML for 6 months but I haven't done any serious big project. I have only done small projects like, next word prediction, sentiment analysis, etc..  I have a question about ml and dl. How much time in a company do ai and ml engineer spend on coding and most of the time what they do? What they spend their time on most?",32,28,CodingWithSatyam,2024-03-21 16:52:57,https://www.reddit.com/r/deeplearning/comments/1bkb95p/how_much_time_do_aiml_engineer_spend_doing_coding/,0,deeplearning
1b8thzw,Stuck in a loop while Learning ML/Deep Learning and I feel whatever I have done can be replaced by a basic chatgpt lol,"A little bit about myself,
I love data. Since childhood I have loved collecting and storing and playing with data, especially once I learnt Excel in my childhood. Hence I really feel this field suits me more than the webdev etc
The thrill while training a model is unparalleled to any other thing that I've ever done.

Coming to my current condition, I have a basic exposure in Deep Learning where I have done a couple of internship where I did transfer learning to train a model to classify a specific type of object.
I used chatgpt and google to guide me and trained the model, with an accuracy of 90% approx. Another project of mine involved predicting a image improvement (densenet, squeezenet) and (random forest, SVM)  algorithm parameters based on features like skewness, contrast etc where I used random forest and outputs were satisfactory.
Again I used chatgpt and just trained, it seemed very rudimentary as I didn't know how to improve the model by myself.
I wouldn't say I learnt nothing but at the same time idk I still feel like a noob in Machine learning
Btw I have placements in a few months, hence I'm even more worried that should I continue to work on ML or just make basic MERN projects and get placed first.

Now the thing is, I don't have much idea about neural networks, or any maths behind it.
I built a NLP project, Twitter sentiment (i know very basic YouTube project) I understood the entire process and loved the new learning but I don't know ANYTHING about LSTM 

I'm learning basics of ML now, like regression, KNN etc but Idk the maths behind it.

How should A guy like me proceed to learn Machine Learning and gradually move towards LLM/other topics
This isn't a normal roadmap cuz I have already worked on stuff but I'm still clueless.
Can someone please please guide me as to how can I proceed from here, and the stuff that I've done is that good enough for a fresher in ML or should I improve in some other direction.

Edit: I'm 20 years old. And a newbie in this field.

Edit: I have taken subjects like Algebra, Calculus, Probability in my uni. So I know the maths basics. It's just that I'm learning the maths related to ML now.",30,38,alcoholic_cat_123,2024-03-07 12:31:01,https://www.reddit.com/r/deeplearning/comments/1b8thzw/stuck_in_a_loop_while_learning_mldeep_learning/,0,deeplearning
1b59x49,Imposter syndrome,"I wasn't sure which sub this belonged to, but how do I deal with imposter syndrome?
Do I have imposter syndrome??? (Ha recursion /s)

On a serious note, I learnt from my supervisor that imposter syndrome doesn't make you look insecure, but you indirectly offend others as well. Just for example, one of my friends in tech was asking what I do at work. I told him, ""Frankly I don't know what I'm doing sometimes. I just import python libraries, spin up some clusters on AWS and run some slurm jobs. Just deploying the LLM stuff and maybe some training."" He probably felt offended that I explained as if it was very simple. 

I honestly have very bad confidence and I have no idea how to work on it. I fear this will affect me because I will always think I'm not good enough for the job. ",32,16,Wheynelau,2024-03-03 05:59:13,https://www.reddit.com/r/deeplearning/comments/1b59x49/imposter_syndrome/,0,deeplearning
13ja5di,Stylized Vector Art using Stable Diffusion,,33,4,oridnary_artist,2023-05-16 16:35:15,https://www.reddit.com/gallery/13ja5di,0,deeplearning
130aze6,Volume Labeling,"Hi guys, I'm working on a task for my thesis. In the image there is a binary volumes (containing only 0s and 1s) that represents a fractured humerus. The aim is to label the fractured components. The connected component analysis is to weak because of bridge voxel: as you can see from the image, you can notice the fractured components but they are roughly separated. Someone has some idea?",30,11,monidp9,2023-04-27 05:29:45,https://i.redd.it/9nyq5xfimewa1.jpg,0,deeplearning
11lgo2d,what exactly is Variance(Xt) during the Forward Process in Diffusion model ?,,30,11,eugene129,2023-03-08 00:25:47,https://i.redd.it/4l95bx76tema1.jpg,0,deeplearning
11ensh6,[P] Wav2Lip + Motion Transfer AI Generated Avatars!,,32,1,happybirthday290,2023-02-28 23:38:56,https://v.redd.it/b71w7cafm0la1,0,deeplearning
wnrfhx,Special Lecture release for Stanford Transformers Course (CS 25) with Geoffrey Hinton,"Announcing the Youtube release of one last special lecture for [**CS25: Transformers United**](http://cs25.stanford.edu/) held at Stanford University given by the Godfather of AI, **Geoffrey Hinton** ü§©!!¬†

See our watchlist here üëâ: [Youtube Link](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM)

Original thread: [Here](https://www.reddit.com/r/MachineLearning/comments/vuw77a/n_firstever_course_on_transformers_now_public/?utm_source=share&utm_medium=web2x&context=3)

Happy Learning!!

&#x200B;

https://preview.redd.it/ly4t0ym3dkh91.png?width=350&format=png&auto=webp&s=fdf6301d7d2d6c101f84be0e034c9cb1d665de94",34,4,DragonLord9,2022-08-13 23:17:02,https://www.reddit.com/r/deeplearning/comments/wnrfhx/special_lecture_release_for_stanford_transformers/,0,deeplearning
v7p8pq,Penn Engineers Create Chip That Can Process and Classify Nearly Two Billion Images per Second,,33,3,keghn,2022-06-08 13:07:13,https://blog.seas.upenn.edu/penn-engineers-create-chip-that-can-process-and-classify-nearly-two-billion-images-per-second/,0,deeplearning
u1iy3x,AI Aimbot Tutorial,For the last 2 weeks I've been working on an AI that recognizes enemies in a video game. Using Opencv for live video capturing & YOLOv5 I built it and created a tutorial for those curious. Hope this helps someone ü§ûhttps://youtu.be/ilsn-TvryyA,35,11,BradPittOfTheOffice,2022-04-11 22:03:07,https://www.reddit.com/r/deeplearning/comments/u1iy3x/ai_aimbot_tutorial/,0,deeplearning
tihwps,I feel like a fraud,"Hi all,

I would like to ask for some help in a form of **honest** opinions. I will try my best to describe the situation that I am currently in for a better understanding.

**\[TLDR: OP thinks he doesn't have enough knowledge in coding to do ML and asks the opinion of the subreddit for some general guideline on how to get better. Exact questions are at the end\]**

I am in an extremely privileged situation, that I am attending a prestigious university where I am doing my PhD in machine learning/deep learning related to material science and chemistry. Even though I have access to tools, classes, and knowledge of any kind, I feel that I have little knowledge of machine learning (more specifically, neural networks). Nonetheless, I have already three papers published related to my research topic and two of ""my networks"" are already deployed online as an open-access tool (e.g. you can use the model for prediction for your own stuff). 

My insecurity comes from the fact that whenever I try to implement something, I always just ""copy-paste"" from others' work. Even pytorch/tensorflow codes, which are super simple anyway. Recently, I tried to implement a simple network to learn the XOR function, just to practice. I initially wanted to do it in C++ to practice the language, but I gave up and went back to python which I am more familiar with. I failed in python too, when I had to implement the backprop by myself (I was not using any kind of external source, I did everything from heart, like at an interview). When I do 'machine learning' related to my research, it is more like using others' work/ideas but applying it to my problem, which is more like an application rather than network development.

I was trying to understand which part is the hardest for me and came to the conclusion, that probably the translation of math into programming is where I usually fail. For example, complex ideas, such as a backprop for classification is too complex to me to implement in code (even though I understand it completely). Also, when I check the code of others, sometimes I fail to understand the logic behind some implementations. Generally, I think I have a good enough knowledge of math, especially linear algebra and calculus (maybe I am a little rusty in probability theory, tho). Also, my understanding of ML/DL, especially for those topics that I am interested in, is also sufficient. But I think I am a terrible coder, probably because I have never learned how to do clean code etc (I am not a CS student). I have a website, which I built using python-flask and Javascript where my models are deployed. But honestly, the code looks terrible: no unit-testing (I even don't know how to do it, which is a shame); no database; no user authentication, etc.

I am not sure if I want to be in academia after I graduate. The financial benefits of a machine learning engineer or data scientist are really tempting compared to the salary of a postdoc. But I am not sure if I will be able to secure a job with this terrible mess I am able to write some calls 'code'. Especially since I am formally not a computer scientist or mathematician (I am an engineer). I always try to improve myself tho: I do LeetCoding and read and learn more about ML/DL in general, but when it comes to implementation in real life, I fail big time. Surprisingly, I am able to do the homework for my DL classes. But those are that typical 'premade' homework, where I only have to implement a function or just edit some part of the code.

I tried the usual method:

1. watch video/read tutorial
2. implement by myself

But I always fail at step 2. 

&#x200B;

**My questions would be the followings:**

1. Would it be better to just learn general coding to get used to it? For example, to get better in OOP, learn C++/CUDA, do proper unit tests, etc. Time constraints from academia are also pressured me not to 'waste time' on other things but my exact research.
2. If I want to move to the industry, what are the key skills, that I have to master (strictly for ML/DL/coding)? 
3. If you happened to be in a similar situation, or you have a bit of good advice on how to get better, I would be more than grateful if you could share it. 
4. If you think, that I am not worthy to be an ML/DL engineer or data scientist, and I should 'know my place' I am also okay with that, I want honest opinions, not just positive ones.

Many thanks for reading through this long list of text and I am happy to answer questions in the comments as well. Cheers!",32,27,Electronic_Tie_4867,2022-03-20 10:09:21,https://www.reddit.com/r/deeplearning/comments/tihwps/i_feel_like_a_fraud/,0,deeplearning
tc8u6k,Microsoft‚Äôs Latest Machine Learning Research Introduces ŒºTransfer: A New Technique That Can Tune The 6.7 Billion Parameter GPT-3 Model Using Only 7% Of The Pretraining Compute,"Scientists conduct trial and error procedures which experimenting, that many times lear to freat scientific breakthroughs. Similarly, foundational research provides for developing large-scale AI systems theoretical insights that reduce the amount of trial and error required and can be very cost-effective.

Microsoft team tunes massive neural networks that are too expensive to train several times. For this, they employed a specific parameterization that maintains appropriate hyperparameters across varied model sizes. The used ¬µ-Parametrization (or ¬µP, pronounced ‚Äúmyu-P‚Äù) is a unique way to learn all features in the infinite-width limit. The researchers collaborated with the OpenAI team to test the method‚Äôs practical benefit on various realistic cases.

Studies have shown that training large neural networks because their behavior changes as they grow in size are uncertain. Many works suggest heuristics that attempt to maintain consistency in the activation scales at initialization. However, as training progresses, this uniformity breaks off at various model widths.

[**CONTINUE READING MY SUMMARY ON THIS RESEARCH**](https://www.marktechpost.com/2022/03/11/microsofts-latest-machine-learning-research-introduces-%ce%bctransfer-a-new-technique-that-can-tune-the-6-7-billion-parameter-gpt-3-model-using-only-7-of-the-pretraining-compute/)

Paper: https://www.microsoft.com/en-us/research/uploads/prod/2021/11/TP5.pdf

Github:https://github.com/microsoft/mup

https://i.redd.it/7jrt9r3awvm81.gif",32,0,No_Coffee_4638,2022-03-12 04:56:16,https://www.reddit.com/r/deeplearning/comments/tc8u6k/microsofts_latest_machine_learning_research/,0,deeplearning
sj8vnd,Google AI Researchers Propose A Novel Training Method Called ‚ÄòDEEPCTRL‚Äô That Integrates Rules Into Deep Learning,"As the number and range of their training data grow, deep neural networks (DNNs) provide increasingly accurate outputs. While investing in high-quality, large-scale labeled datasets are one way to enhance models, another is to use previous information, referred to as ‚Äúrules‚Äù ‚Äì reasoning heuristics, equations, associative logic, or restrictions. Consider a classic physics problem in which a model is tasked with predicting the future state of a double pendulum system. While the model may learn to expect the system‚Äôs total energy at a particular moment in time only from empirical data, unless it is additionally given an equation that incorporates known physical restrictions, such as energy conservation, it will typically overestimate the energy. On its own, the model cannot represent such well-established physical principles. How could such rules be taught, so DNNs acquire the appropriate information rather than merely learning from the data?

[**Continue Reading**](https://www.marktechpost.com/2022/02/02/google-ai-researchers-propose-a-novel-training-method-called-deepctrl-that-integrates-rules-into-deep-learning/)

Paper: [https://arxiv.org/pdf/2106.07804.pdf](https://arxiv.org/pdf/2106.07804.pdf)

Google Blog: https://ai.googleblog.com/2022/01/controlling-neural-networks-with-rule.html",32,3,ai-lover,2022-02-03 03:40:35,https://www.reddit.com/r/deeplearning/comments/sj8vnd/google_ai_researchers_propose_a_novel_training/,0,deeplearning
sbjisd,Brain Tumor Segmentation and Classification using ResUnet.,,31,1,Sudo_Python,2022-01-24 10:51:35,https://i.redd.it/nvlukkzu8md81.png,0,deeplearning
rqkcj1,"Knowledge Distillation, Model Ensemble and Its Application on Visual Recognition - Link to a free online lecture by the author in comments",,32,4,dataskml,2021-12-28 17:02:06,https://i.redd.it/iuxynqbceb881.png,0,deeplearning
qdpqlm,Coursera canceling access to my prior courses with Coursera Plus? This feels unfair.,"https://i.redd.it/hmyuaalqq2v71.gif

  


Hello all,

I have been subscribing to Coursera ([www.coursera.org](https://www.coursera.org/)) for years and now they emailed the following canceling access to the courses I've previously taken. I have continued paying for my Coursera subscription for three+ years now, and am ""locked into"" this content and reference it frequently. **I thank** Coursera **for the high quality content and quality.** The [deeplearning.ai](https://deeplearning.ai/) specialization in particular was instrumental for me.

That being said, Coursera is now **canceling all prior subscriptions** and forcing users to pay for individual courses.

\- This feels like an unfair practice -- **IMO, prior users should be grandfathered and have the opportunity to keep their current subscription model.** (If the user cancels that subscription it would be expired and no longer available)

Would love to hear some thoughts from the community!

Email from Coursera Below (Oct 22, 2021):

\--**Your all-access catalog subscription to Coursera is ending**

We wanted to let you know starting December 14, 2021, we will stop supporting your current all-access catalog subscription to Coursera.

Some important details about the end of your subscription:

* Your subscription will be cancelled on December 14, 2021.
* You can enroll and make progress in the courses included with your current subscription for 30 days after December 07, 2021.
* Your progress will be saved in any unfinished courses but you‚Äôll need to enroll in the courses again to continue learning after your access ends.
* If you have any questions, [visit the FAQs](https://eventing.coursera.org/redirectSigned/eyJrZXkiOiJlbWFpbC5saW5rLm9wZW4iLCJ2YWx1ZSI6eyJ1cmwiOiJodHRwczovL3d3dy5jb3Vyc2VyYS5zdXBwb3J0L3MvYXJ0aWNsZS8yMTYzNDgxMDMtQ291cnNlcmEtc3Vic2NyaXB0aW9ucz91dG1fbWVkaXVtPWVtYWlsJnV0bV9zb3VyY2U9bWFya2V0aW5nJnV0bV9jYW1wYWlnbj11RDl5NEROWEVleUh2Rl90RWlNUlF3I2NhdGFsb2ciLCJ0cmFja2luZyI6eyJ1c2VySWQiOjExMzk5MDcsInVzZXJFbWFpbCI6ImFrc2hheS5rLmdvZWxAZ21haWwuY29tIiwibm90aWZpY2F0aW9uVHlwZSI6Ii1lU1U0QzMwRWV5ZWctSF9lck1hWHciLCJjYW1wYWlnbklkIjoidUQ5eTRETlhFZXlIdkZfdEVpTVJRdyIsImNhbXBhaWduR3JvdXAiOiJ1RDl5NEROWEVleUh2Rl90RWlNUlF3IiwibGlua3MiOltdfX0sInVzZXJJZCI6MTEzOTkwN30.FUQ8UfwD5w5Ndnk8n0P554ts_Dzrtw-OP0VENBSTSUI) in the Learner Help Center.

You can continue to get unlimited learning by subscribing to [Coursera Plus](https://eventing.coursera.org/redirectSigned/eyJrZXkiOiJlbWFpbC5saW5rLm9wZW4iLCJ2YWx1ZSI6eyJ1cmwiOiJodHRwOi8vY291cnNlcmEub3JnL2NvdXJzZXJhcGx1cy9zcGVjaWFsL3N3czIwMjE_dXRtX21lZGl1bT1lbWFpbCZ1dG1fc291cmNlPW1hcmtldGluZyZ1dG1fY2FtcGFpZ249dUQ5eTRETlhFZXlIdkZfdEVpTVJRdyIsInRyYWNraW5nIjp7InVzZXJJZCI6MTEzOTkwNywidXNlckVtYWlsIjoiYWtzaGF5LmsuZ29lbEBnbWFpbC5jb20iLCJub3RpZmljYXRpb25UeXBlIjoiLWVTVTRDMzBFZXllZy1IX2VyTWFYdyIsImNhbXBhaWduSWQiOiJ1RDl5NEROWEVleUh2Rl90RWlNUlF3IiwiY2FtcGFpZ25Hcm91cCI6InVEOXk0RE5YRWV5SHZGX3RFaU1SUXciLCJsaW5rcyI6W119fSwidXNlcklkIjoxMTM5OTA3fQ.O9nQOXGhiXS9GKurSSZCxdpl5LYzzmTzwfqSwXlxgh4), a new subscription that gives you unlimited access to over 90% of learning programs on Coursera. Subscribe before January 31, 2022 to enjoy a **30-day free trial**.

With a **Coursera Plus** subscription, you can:

* **Get unlimited access** to 3,000+ courses, Guided Projects, Specializations, and Professional Certificates\*
* **Explore and switch courses at any time** to make sure what you‚Äôre learning is the right fit for your skill level and interests
* **Earn unlimited certificates** for one, all-inclusive price",32,1,Wise_Sentence2856,2021-10-22 20:38:35,https://www.reddit.com/r/deeplearning/comments/qdpqlm/coursera_canceling_access_to_my_prior_courses/,0,deeplearning
qbxfyg,"The PDF version of my book ""Deep Learning Interviews"", can now be downloaded",,30,1,dl-interviews,2021-10-20 10:05:29,/r/learnmachinelearning/comments/qbwgvy/the_pdf_version_of_my_book_deep_learning/,0,deeplearning
q2rauj,"DeepMind Introduces ‚ÄòEnformer‚Äô, A Deep Learning Architecture For Predicting Gene Expression From DNA Sequence","DNA contains the genetic information that influences everything from eye color to illness and disorder susceptibility. Genes, which are around 20,000 pieces of DNA in the human body, perform various vital tasks in our cells. Despite this, these genes comprise up less than 2% of the genome. The remaining base pairs in the genome are referred to as ‚Äúnon-coding.‚Äù They include less well-understood instructions on when and where genes should be created or expressed in the human body.¬†

DeepMind, in collaboration with their Alphabet colleagues at [Calico](https://www.calicolabs.com/), introduces [Enformer](https://www.nature.com/articles/s41592-021-01252-x),¬†a neural network architecture that accurately predicts gene expression from DNA sequences.¬†

Earlier studies on gene expression used convolutional neural networks as key building blocks. However, their accuracy and usefulness have been hampered by problems in modeling the influence of distal enhancers on gene expression. The proposed new method is based on Basenji2, a program that can predict regulatory activity from DNA sequences of up to 40,000 base pairs.¬†

# [3 Min Read](https://www.marktechpost.com/2021/10/06/deepmind-introduces-enformer-a-deep-learning-architecture-for-predicting-gene-expression-from-dna-sequence/) | [Paper](https://www.nature.com/articles/s41592-021-01252-x) | [Github](https://github.com/deepmind/deepmind-research/tree/master/enformer)

&#x200B;

https://preview.redd.it/uuhcqah6qvr71.png?width=814&format=png&auto=webp&s=a3cfbc912ee1b1f6f5f6fa0ddbbac67bc22538d0",33,1,techsucker,2021-10-06 19:13:21,https://www.reddit.com/r/deeplearning/comments/q2rauj/deepmind_introduces_enformer_a_deep_learning/,0,deeplearning
odkmim,üé•üî• Focal Transformer from Microsoft | Paper Explained,,33,0,gordicaleksa,2021-07-04 13:37:58,https://youtu.be/YH319yyeoVw,0,deeplearning
oag2if,Details of Tesla's deep learning pipeline,,32,0,bendee983,2021-06-29 20:01:25,https://bdtechtalks.com/2021/06/28/tesla-computer-vision-autonomous-driving/,0,deeplearning
noxm17,New Android RL environment by DeepMind! (why we should care? and how to get started?),,30,0,gordicaleksa,2021-05-31 07:30:19,https://youtu.be/847zrERIr-k,0,deeplearning
jyvp76,Better than DAIN? Increase Video's FPS with RIFE Video Frame Interpolation,,30,1,cloud_weather,2020-11-22 13:33:18,https://youtu.be/60DX2T3zyVo,0,deeplearning
jnhhu7,Can't believe anything,,31,1,Independent-Square32,2020-11-03 19:54:38,https://youtu.be/3COBWXegT-E,0,deeplearning
j7ig7y,"Google, Stanford, & MIT Top NeurIPS 2020 Accepted Papers List","After months marred by controversies over poorly-explained [desk-rejects](https://syncedreview.com/2020/07/16/poorly-explained-neurips-2020-desk-rejects-peeve-ml-researchers/) and other problematic aspects of its [review process](https://syncedreview.com/2020/08/13/neurips-paper-reviews-released-controversies-resurface/), the 34th Conference on Neural Information Processing Systems (NeurIPS 2020) has finally released its [list](https://neurips.cc/Conferences/2020/AcceptedPapersInitial) of accepted papers.

With 38 percent more paper submissions than 2019, this has been another record-breaking year for NeurIPS. A total of 1,903 papers were accepted, compared to 1,428 last year.

The NeurIPS 2020 Program Chairs report that 12,115 paper abstracts were submitted, leading to 9,467 full submissions. After 184 submissions were withdrawn by authors or rejected for violations such as being non-anonymous or exceeding the maximum page count, 11 percent were desk-rejected, leaving 8,186 papers assigned to reviewers. **The NeurIPS 2020 paper acceptance rate is 20.1 percent ‚Äî slightly lower than last year‚Äôs 21 percent.**

Here is a quick read: [Google, Stanford, & MIT Top NeurIPS 2020 Accepted Papers List](https://syncedreview.com/2020/10/08/google-stanford-mit-top-neurips-2020-accepted-papers-list/)",33,6,Yuqing7,2020-10-08 18:23:27,https://www.reddit.com/r/deeplearning/comments/j7ig7y/google_stanford_mit_top_neurips_2020_accepted/,0,deeplearning
il94tc,ECCV 2020: paper summaries and highlights (blog post),"Hi;

I thought I write a blog post where I highlight some of the things that caught my attention while browsing this year's ECCV conference. The blog post contains summaries of some papers (and the mention of some) that I thought were nice (note: this is just a sample, I certainly missed a lot of cool ones).

The post might be helpful to get a general feel of this year's conference quickly since the number of papers (>1.3K) can be overwhelming at times. Check it out!

Blog post: https://yassouali.github.io/ml-blog/eccv2020/",30,0,youali,2020-09-02 15:39:55,https://www.reddit.com/r/deeplearning/comments/il94tc/eccv_2020_paper_summaries_and_highlights_blog_post/,0,deeplearning
hvuu5d,"DeepFaceDrawing Generates Real Faces From Sketches. Image-to-image translation in 2020+, is it biased, could it be used in a real world application? Paper explained",,33,3,OnlyProggingForFun,2020-07-22 14:33:48,https://www.youtube.com/watch?v=djXdgCVB0oM,0,deeplearning
hnmnpk,"Introduction to Robot and Autonomous Vehicle localization, with an introduction to high-fidelity maps.",,34,0,shani_786,2020-07-08 18:37:39,https://youtu.be/YHXdf9rTV2s,0,deeplearning
gqshxd,Federated Learning using PyTorch and PySyft,"In many AI applications, we need a lot of data to train a model. The more data we have, the better the model becomes. This is especially true in areas like healthcare where a good AI model can be immensely useful to humanity as a whole. At the same time, people may not (and should not) be willing to share their data because of privacy concerns.  
This points to a need for a training system that improves a model without a remote server ever getting access to private/personal/local data.  
In today's post, we go over the idea of Federated Learning tries to solve this problem with an example (code)  


[https://www.learnopencv.com/federated-learning-using-pytorch-and-pysyft/](https://www.learnopencv.com/federated-learning-using-pytorch-and-pysyft/)  
Please find the relevant code at:

[https://github.com/spmallick/learnopencv/tree/master/Federated-Learning-Intro](https://github.com/spmallick/learnopencv/tree/master/Federated-Learning-Intro) 

&#x200B;

&#x200B;

https://preview.redd.it/r2svj8r4b2151.png?width=600&format=png&auto=webp&s=3bb45b7b3e4d53c49cb2cacdfb9f4f70b00e7e5f",32,0,spmallick,2020-05-26 07:32:15,https://www.reddit.com/r/deeplearning/comments/gqshxd/federated_learning_using_pytorch_and_pysyft/,0,deeplearning
g9myws,Online Lessons - Statistics for Machine Learning (Refresher for MS studies),"Hi everyone,

I'll be doing a masters in artificial intelligence and speech processing (assuming COVID 19 doesn't interfere) this fall. I'm only really familiar with the signal processing aspect of my master's and I'm not really that confident in what I know in statistics and probability. My adviser recommended me that I brush up on my statistics so I wouldn't have much difficulty adjusting. 

Is there an online course that anyone would recommend that would give out the background needed for machine learning? I'm already reviewing books such as Machine Learning: a probabilistic perspective by Murphy, Elements of Statistical Learning, Pattern Recognition by Bishop, but I would also prefer to add videos into the mix so there would be different sources of learning.

Thanks so much :)",34,6,hydrogenken,2020-04-28 13:14:56,https://www.reddit.com/r/deeplearning/comments/g9myws/online_lessons_statistics_for_machine_learning/,0,deeplearning
g7liym,From CVPR '20: Like zoom‚Äôs virtual background function but better! Deep learning and GANs to enable professional-quality background replacement from your own home,,31,2,MLtinkerer,2020-04-25 02:08:16,/r/LatestInML/comments/g7lge4/from_cvpr_20_like_zooms_virtual_background/,0,deeplearning
g6yq11,"Who Invented Backpropagation? Hinton Says He Didn‚Äôt, but His Work Made It Popular","One might think that news of the 2019 Honda Prize being awarded to Dr. Geoffrey Hinton ‚Äúfor his pioneering research in the field of deep learning in artificial intelligence (AI)‚Äù would prompt the machine learning community to toast the man they call the ‚ÄúGodfather of Deep Learning.‚Äù Instead, the gloves came off and what ensued was an unexpected Internet dust-up.

J√ºrgen Schmidhuber started it. In a blog[ post](http://people.idsia.ch/~juergen/critique-honda-prize-hinton.html#I), the Scientific Director of The Swiss AI Lab IDSI called out the Honda Prize for crediting Hinton with inventing backpropagation, among other things. Schmidhuber argued that ‚Äú**Hinton has made significant contributions to artificial neural networks (NNs) and deep learning, but Honda credits him for fundamental inventions of others whom he did not cite.**‚Äù

Schmidhuber identified what he said were ‚Äúsix false and/or misleading attributions of credit to Dr. Hinton‚Äù in the press release. ‚ÄúI‚Äôll point out,‚Äù he wrote, ‚Äúthat Hinton‚Äôs most visible publications failed to mention essential relevant prior work ‚Äî this may explain some of Honda‚Äôs misattributions.‚Äù

The 6,300 word document, ***Critique of Honda Prize for Dr. Hinton*****, was published on Tuesday on the The Swiss AI Lab IDSIA (Istituto Dalle Molle di Studi sull‚ÄôIntelligenza Artificiale) website. The opening line reads: ‚ÄúWe must stop crediting the wrong people for inventions made by others.‚Äù**

Today, Hinton, University Professor Emeritus at the University of Toronto, responded on [Reddit](https://www.reddit.com/r/MachineLearning/comments/g5ali0/d_schmidhuber_critique_of_honda_prize_for_dr/fo8rew9?utm_source=share&utm_medium=web2x), ‚Äú**I have never claimed that I invented backpropagation.** David Rumelhart invented it independently long after people in other fields had invented it. It is true that when we first published we did not know the history so there were previous inventors that we failed to cite. **What I have claimed is that I was the person to clearly demonstrate that backpropagation could learn interesting internal representations and that this is what made it popular.‚Äù**

Read more: [Who Invented Backpropagation? Hinton Says He Didn‚Äôt, but His Work Made It Popular](https://medium.com/syncedreview/who-invented-backpropagation-hinton-says-he-didnt-but-his-work-made-it-popular-e0854504d6d1)",34,6,Yuqing7,2020-04-24 00:46:30,https://www.reddit.com/r/deeplearning/comments/g6yq11/who_invented_backpropagation_hinton_says_he_didnt/,0,deeplearning
g5prf5,How does the talktotransformer website work so fast?,"At [https://talktotransformer.com/](https://talktotransformer.com/), you can type a prompt and the transformer will autogenerate the text for you using OpenAI's GPT-2 1.5 billion parameter model.

I'm not asking how GPT-2 works, I'm asking something else. When I ran the GPT-2 1.5B model on the free TPU in Google Colab, it took around 20 to 40ish seconds to generate around the same about of text as the website generates per prompt.

And yet, the website is somehow generating text from the prompt almost instantaneously using the 1.5B model. This is on top of all the X number of people who must be using the website at the same time I am, so it is doing text generation concurrently and near-instantaneously using a gigantic model.

I am very confused. Did the creator of the website just use a lot more TPUs/GPUs behind the scenes and is letting them run 24/7 (I don't think so because that would cost a shit ton of money), or am I missing something fundamental here?

This same question can be applied to this website too: [https://demo.allennlp.org/next-token-lm?text=AllenNLP%20is](https://demo.allennlp.org/next-token-lm?text=AllenNLP%20is)

Please keep in mind that I'm relatively new to all of this. Thanks in advance!",32,5,parrot15,2020-04-21 23:00:56,https://www.reddit.com/r/deeplearning/comments/g5prf5/how_does_the_talktotransformer_website_work_so/,0,deeplearning
g5a9jw,Colab tutorial! Just 10min for beginner,,30,5,minsuk-heo,2020-04-21 06:44:32,https://youtu.be/rlSnUXnd5xE,0,deeplearning
g3re4e,Detecto - An object detection library for PyTorch,,30,1,alanbi,2020-04-18 17:31:46,https://medium.com/pytorch/detecto-build-and-train-object-detection-models-with-pytorch-5f31b68a8109,0,deeplearning
fhu12e,[Code Released] A fully Python code available for LipGAN: create talking faces from audio,,32,0,prajwalkr,2020-03-13 04:26:14,https://github.com/Rudrabha/LipGAN/tree/fully_pythonic,0,deeplearning
f74n02,MIT 6.S191: Introduction to Deep Learning,,30,1,None,2020-02-21 02:53:54,http://introtodeeplearning.com/,0,deeplearning
erzgfw,Detecto - computer vision model in 10 lines of code or less,,32,2,alanbi,2020-01-21 19:16:09,https://github.com/alankbi/detecto,0,deeplearning
eqfvml,Model only needs one face image for each person,,34,5,cmillionaire9,2020-01-18 12:33:50,https://youtu.be/N712kl-EZ2c,0,deeplearning
egow34,Decoding human brain activity with deep learning,,33,0,newworld-ai,2019-12-28 09:33:37,https://www.newworldai.com/decoding-human-brain-activity-deep-learning/,0,deeplearning
e1sse9,Deep Learning with PyTorch [Free Book],,32,5,ai-lover,2019-11-26 04:34:12,https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf,0,deeplearning
djnn01,Energy-based Approaches to Representation Learning - Yann LeCun,,33,1,DrJohanson,2019-10-18 13:38:27,https://www.youtube.com/watch?v=m17B-cXcZFI,0,deeplearning
dd7amk,Drones and Artificial Intelligence.,,34,3,cmillionaire9,2019-10-04 13:22:08,https://youtu.be/BMZwG1OpXNQ,0,deeplearning
cqjt9p,Neural Style Transfer - An Intuitive Explanation,,32,2,Automato-YT,2019-08-15 02:24:18,https://youtu.be/q8LQ9I9WAT0,0,deeplearning
c3a74w,Generative Adversarial Networks - The Story So Far,,31,0,pirate7777777,2019-06-21 12:53:35,https://blog.floydhub.com/gans-story-so-far/,0,deeplearning
brfxn0,Facebook Open-Sources Pythia for Vision and Language Multimodal AI Models,,34,4,Yuqing7,2019-05-21 21:08:18,https://medium.com/syncedreview/facebook-open-sources-pythia-for-vision-and-language-multimodal-ai-models-be480644b538,0,deeplearning
adpbl2,Kaggle: How to Place in the Top 10% (part 1),,31,2,keghn,2019-01-08 02:12:31,https://www.youtube.com/watch?v=eNkayufkT04,0,deeplearning
a1ts26,Alibaba Open-Sources Its X-Deep Learning Framework,,32,0,gwen0927,2018-11-30 16:13:11,https://medium.com/syncedreview/alibaba-open-sources-its-x-deep-learning-framework-df1563bc99cd,0,deeplearning
9ze4cy,Tensorflow CNN + Mapbox 3D == Real Life SimCity,"[www.grassland.network](https://www.grassland.network/) I've been building some anonymous. P2P software to provide a (politically) stateless and indelible public record of human activities as live, 3D, simulated cities that can be ""rewinded"". It uses regular digital camera frames (video) and an algebraic equation called [homography](https://en.wikipedia.org/wiki/Homography_(computer_vision)); ***no*** sensors, SLAM or point clouds needed. To ensure the data from other nodes is real, I made a proof-of-work that cryptographically hashes certain hidden activations of feed-forward neural networks to prove whether computational resources were expended on the model to process camera frames correctly (see diagram on website). Several times a day, the last inference output from every node is hashed into a [Merkle Tree](https://brilliant.org/wiki/merkle-tree/) by the network for data ""compression"", indelibility and consistency across all nodes worldwide. Current computational requirements are low as the network's model only detects and tracks people and cars now but that will increase over time for an increasingly accurate and harder to fabricate representation of the real world.

You can perhaps think of it as a form of [inverse surveillance or undersight](https://en.wikipedia.org/wiki/Sousveillance).

It's version 0.1 so there is ""Some Assembly Required"", but I'm constantly updating it. It's open source, so feel free to provide fixes or updates if you want.

Edit \*\*\*:  I update the site several times a day based on questions I get. So refresh the site in your browser each time you visit just in case you've got an old, cached version.",29,15,00hello,2018-11-22 13:31:50,https://www.reddit.com/r/deeplearning/comments/9ze4cy/tensorflow_cnn_mapbox_3d_real_life_simcity/,0,deeplearning
8a8krd,Prof Andrew Ng is writing a book about managing a ML project - sign up for free updates,,31,11,ScotchMonk,2018-04-06 11:00:01,http://www.mlyearning.org/,0,deeplearning
13mcvb3,"What Photoshop Can't Do, DragGAN Can! See How! Paper Explained, Along with Additional Supplementary Video Footage",,31,22,CeFurkan,2023-05-20 00:33:08,https://www.youtube.com/watch?v=55Smbt38KgM&deeplearning,0,deeplearning
12pxedf,Balacoon: fastest neural text-to-speech on CPU,"Hi,

I recently released a text-to-speech model that runs **50 times faster than real-time on a CPU**. To my best knowledge, that's the fastest TTS available. You can find details in a [blog post](https://balacoon.com/blog/on-device/). 

You can try it online in a [huggingface space,](https://huggingface.co/spaces/balacoon/tts) selecting ""en\_us\_hifi92\_light\_cpu.addon"" as a model. Or locally on a Linux machine with a Python package as described in the [tutorial](https://balacoon.com/use/tts/package).

Would be happy to try to answer questions on optimizations and learnings.",30,5,clementruhm,2023-04-17 21:23:27,https://www.reddit.com/r/deeplearning/comments/12pxedf/balacoon_fastest_neural_texttospeech_on_cpu/,0,deeplearning
11zi09h,Just made a PEPE Generator https://huggingface.co/spaces/Dipl0/Dipl0-pepe-diffuser,,31,1,H04K,2023-03-23 11:53:35,https://i.redd.it/76pmyyti9hpa1.jpg,0,deeplearning
11xdx3w,Alpaca Turbo : A chat interface to interact with alpaca models with history and context,"So I made this chat UI that will help you use alpaca models to have coherent conversations with history and the bot will remember your previous questions  


Here is the demo  


you can get the interface from [https://github.com/ViperX7/Alpaca-Turbo](https://github.com/ViperX7/Alpaca-Turbo)  
 

https://reddit.com/link/11xdx3w/video/o7jpmysvt2pa1/player",31,19,viperx7,2023-03-21 11:21:10,https://www.reddit.com/r/deeplearning/comments/11xdx3w/alpaca_turbo_a_chat_interface_to_interact_with/,0,deeplearning
zsqe1b,Popular deep-learning book from Amazon scientists adds Google JAX Python library implementation,,33,0,amazonscience,2022-12-22 16:37:13,https://www.amazon.science/latest-news/popular-deep-learning-book-from-amazon-authors-gets-update,0,deeplearning
zh381d,Progress Table - is it better than TQDM for your use case?,"Hi!

I train lots of DL models. I often check their training progress in the command line. To have a nicer time doing so, I created Progress Table and I decided to share it. It's a direct replacement for TQDM, Keras `Progbar` and other progress tracking utilities.

I'll explain the purpose of this package with ""before"" and ""after"" GIFs:

Before:

&#x200B;

https://i.redd.it/52ckca5ip25a1.gif

After:

&#x200B;

https://i.redd.it/dqbwsw1jp25a1.gif

It's a tiny package with one dependency: `colorama` for displaying colored text.

Install with `pip install progress-table`.

Code and example-based instructions are here: [https://github.com/gahaalt/progress-table](https://github.com/gahaalt/progress-table)

Tell me, if it's interesting for you. Do you have any suggestions for its further development?",31,7,gahaalt,2022-12-09 17:31:14,https://www.reddit.com/r/deeplearning/comments/zh381d/progress_table_is_it_better_than_tqdm_for_your/,0,deeplearning
xdd1fg,What is this bump in my learning curve?,,32,20,Thijs-vW,2022-09-13 17:05:54,https://i.redd.it/lmw6e3v4rnn91.png,0,deeplearning
uo1iz9,Cheat Sheets for Machine Learning and Data Science,,31,2,vadhavaniyafaijan,2022-05-12 13:48:44,https://www.theinsaneapp.com/2020/12/machine-learning-and-data-science-cheat-sheets-pdf.html,0,deeplearning
r7bx6y,Facebook AI and University of Guelph Open-Sources Graph HyperNetworks (GHN-2): A Meta-Model That Predicts Starting Parameters For Deep-Learning Neural Networks,"In machine learning pipelines, deep learning has proved successful in automating feature design. However, many researchers reveal that the techniques for improving neural network parameters are still mostly hand-crafted and computationally inefficient.

To overcome such shortcomings, Facebook AI Research (FAIR) and the University of Guelph have released an updated [Graph HyperNetworks (GHN-2) meta-model](https://arxiv.org/pdf/2110.13100.pdf) that predicts starting parameters for deep-learning neural networks. With no extra training, GHN-2 runs in less than a second on a CPU and predicts values for computer vision (CV) networks that reach up to 77 percent top-1 accuracy on CIFAR-10.

The researchers created the DeepNets-1M dataset to solve the problem of guessing initial parameters for deep-learning models. This dataset contains one million examples of neural network architectures expressed as computational graphs. They then employed meta-learning to train a modified graph hyper-network (GHN) using this dataset, which can be used to forecast parameters for a network architecture that has never been seen before. Even for architectures far larger than the ones used in training, the resulting meta-model performs better at the task. The meta-model revealed parameters that achieved 60% accuracy on CIFAR-10 with no gradient updates when used to start a 24M-parameter ResNet-50.¬†

Quick Read: [https://www.marktechpost.com/2021/12/02/facebook-ai-and-university-of-guelph-open-sources-graph-hypernetworks-ghn-2-a-meta-model-that-predicts-starting-parameters-for-deep-learning-neural-networks/](https://www.marktechpost.com/2021/12/02/facebook-ai-and-university-of-guelph-open-sources-graph-hypernetworks-ghn-2-a-meta-model-that-predicts-starting-parameters-for-deep-learning-neural-networks/) 

GitHub: https://github.com/facebookresearch/ppuda

Paper: https://arxiv.org/pdf/2110.13100.pdf",30,1,techsucker,2021-12-02 17:02:12,https://www.reddit.com/r/deeplearning/comments/r7bx6y/facebook_ai_and_university_of_guelph_opensources/,0,deeplearning
q8zisr,The Ultimate Guide To PyTorch,,31,2,athos45678,2021-10-15 22:55:42,https://blog.paperspace.com/ultimate-guide-to-pytorch/,0,deeplearning
oh4o95,"Since we passed 500 subscribers on the Casual GAN Papers channel I made a web version of the blog for all you guys who liked my paper summaries but could not join the telegram channel! Come check it out, I just posted a summary for Deferred Neural Rendering.",,31,3,None,2021-07-09 21:04:42,https://www.casualganpapers.com/,0,deeplearning
mdq29j,[Project] deep-significance: Easy and Better Significance Testing for Deep Neural Networks (link below),"Hey!  


Recently, I have become somewhat frustrated at ML papers highlighting scores only stemming from a single run in result tables, and claiming that an approach is superior when it only outperforms others marginally. This is why I re-implemented, tested and packaged a statistical significance test proposed by Dror et al. (2019) that is specifically tailored towards neural networks. I also added information about statistical significance testing and how to apply the mentioned test in the most common scenarios faced by ML practitioners!

[https://github.com/Kaleidophon/deep-significance](https://github.com/Kaleidophon/deep-significance)

I'd be very happy to receive some feedback from the community here and improve this further and help move the field forward :-)",32,2,Kaleidophon,2021-03-26 14:37:51,https://www.reddit.com/r/deeplearning/comments/mdq29j/project_deepsignificance_easy_and_better/,0,deeplearning
lv1ntx,A simple multi-agent reinforcement learning tutorial for those who are new to the field,,28,1,justinkterry,2021-03-01 06:04:14,https://towardsdatascience.com/multi-agent-deep-reinforcement-learning-in-15-lines-of-code-using-pettingzoo-e0b963c0820b,0,deeplearning
lm2u30,You can reproduce the whole body of an anime character,,32,5,cmillionaire9,2021-02-17 19:43:45,https://youtu.be/AYtRTPkIid8,0,deeplearning
lhij1r,Why has Google's Performer model not replaced traditional softmax attention?,"Four months ago Google dropped its paper titled 'rethinking attention with Performers'. In it they claim to overcome the O(n^2) memory scaling in traditional transformers, without losing performance like sparse-attention models.

They even go as far as to claim that the performer works as a drop in replacement for any traditional attention model, and seem to imply that all transformers should be replaced by Performers.

But since then, I have barely heard anything about them. I've not seen an OSS implementation, or seen any blogs of people improving their models with them. I understand it's maybe too soon to see new academic papers use them. But I would have expected more attention being paid to them. (LOL) 

Does anyone know what is holding the Performer back from leveling up our attention models? Did Google overhype, or is this likely still going to happen in the near future?",31,14,None,2021-02-11 11:07:00,https://www.reddit.com/r/deeplearning/comments/lhij1r/why_has_googles_performer_model_not_replaced/,0,deeplearning
kza66o,Handling dynamic graphs with GNNs! Temporal Graph Networks (Twitter Research),,28,2,gordicaleksa,2021-01-17 17:05:09,https://youtu.be/0tw66aTfWaI,0,deeplearning
kfa2tz,[D] 2020 in Review | 10 AI Papers That Made an Impact,"Much of the world may be on hold, but AI research is still booming. The volume of peer-reviewed AI papers has grown by more than 300 percent over the last two decades, and attendance at AI conferences continues to increase significantly, according to the Stanford [AI Index](https://hai.stanford.edu/sites/default/files/ai_index_2019_report.pdf). In 2020, AI researchers made exciting progress on applying transformers to areas other than natural-language processing (NLP) tasks, bringing the powerful network architecture to [protein sequences modelling](https://syncedreview.com/2020/07/31/applying-linearly-scalable-transformers-to-model-longer-protein-sequences/) and [computer vision tasks](https://syncedreview.com/2020/05/29/facebook-ais-detr-applies-transformers-to-cv-tasks/) such as object detection and panoptic segmentation. Improvements this year in unsupervised and self-supervised learning methods meanwhile evolved these into serious alternatives to traditional supervised learning methods.

As part of our year-end series, *Synced* highlights 10 artificial intelligence papers that garnered extraordinary attention and accolades in 2020.

Here is a quick read: [2020 in Review | 10 AI Papers That Made an Impact](https://syncedreview.com/2020/12/17/2020-in-review-10-ai-papers-that-made-an-impact/)",32,1,Yuqing7,2020-12-18 00:28:40,https://www.reddit.com/r/deeplearning/comments/kfa2tz/d_2020_in_review_10_ai_papers_that_made_an_impact/,0,deeplearning
gnjv5u,Real time Image animation using first order model,"Hello guy this is my first attempt to real time version for the project based on first order model for image animation

[Link to my project](https://github.com/anandpawara/Real_Time_Image_Animation)

This is project is based on work of  [first order model](https://github.com/AliaksandrSiarohin/first-order-model). I have tried to create openCv application for the project to process real time frames and convert into animated form

I would really appreciate feedback regarding improvement

 [Imgur Link](https://imgur.com/jDcwqI8)

https://reddit.com/link/gnjv5u/video/tsxxn3bejzz41/player",29,6,None,2020-05-20 21:03:35,https://www.reddit.com/r/deeplearning/comments/gnjv5u/real_time_image_animation_using_first_order_model/,0,deeplearning
ga93j7,AI navigation for blind people,,28,3,cmillionaire9,2020-04-29 13:06:23,https://youtu.be/8Ao5qQdGbv4,0,deeplearning
f1wdm6,Fast & Accurate Human Pose Estimation using ShelfNet - 74.6AP on MS COCO @ 127FPS,"This new [repository](https://github.com/fmahoudeau/ShelfNet-Human-Pose-Estimation) is the result of my curiosity to find out whether [ShelfNet](https://arxiv.org/abs/1811.11254v6) is an efficient CNN architecture for computer vision tasks other than semantic segmentation, and more specifically for the human pose estimation task. The answer is a clear yes, with **74.6 mAP** and **127 FPS** on the **MS COCO Keypoints** data set which represents a 3.5x boost in FPS compared to **HRNet** with similar accuracy.

https://i.redd.it/6wc9eaxso5g41.gif",32,1,Fanos6,2020-02-10 20:31:33,https://www.reddit.com/r/deeplearning/comments/f1wdm6/fast_accurate_human_pose_estimation_using/,0,deeplearning
ev79dt,Is PyTorch Catching TensorFlow?,"I'm trying to figure out whether to focus on TensorFlow or PyTorch for teaching a framework. I did some analysis of what's most in demand and shared my results here:

[https://towardsdatascience.com/is-pytorch-catching-tensorflow-ca88f9128304?source=friends\_link&sk=d5fec29960952a15c8e7be9285e32eb6](https://towardsdatascience.com/is-pytorch-catching-tensorflow-ca88f9128304?source=friends_link&sk=d5fec29960952a15c8e7be9285e32eb6)

Constructive feedback is much appreciated!",29,13,discdiver,2020-01-28 15:58:14,https://www.reddit.com/r/deeplearning/comments/ev79dt/is_pytorch_catching_tensorflow/,0,deeplearning
euv1za,Where can I properly learn Tensorflow2.0?,The official tutorial sucks and majority of the youtube videos are just using the same tutorials from the tensorflow page. They dont teach you tensorflow. They just take one example and say vauge things.,31,17,None,2020-01-27 21:47:26,https://www.reddit.com/r/deeplearning/comments/euv1za/where_can_i_properly_learn_tensorflow20/,0,deeplearning
dwldvm,The Beauty of Deep Neural Networks (Art of the Problem posted today),,29,0,puppers90,2019-11-15 04:14:19,https://www.youtube.com/watch?v=r1U6fenGTrU,0,deeplearning
dtftzk,Learn TensorFlow 2.0: Basic Image Classification Tutorial (Part 1 of 5),,31,1,mippie_moe,2019-11-08 14:02:10,https://lambdalabs.com/blog/tensorflow-2-0-tutorial-01-image-classification-basics/,0,deeplearning
cxbovi,few shot face translation GAN: Face swapping video from a single image without training for any face,"Generative adversarial networks integrating modules from FUNIT and SPADE for face-swapping

Inference only takes a few minutes for any face pair on a k80 gpu vs weeks or days of training a face pair

github link: [https://github.com/shaoanlu/fewshot-face-translation-GAN](https://github.com/shaoanlu/fewshot-face-translation-GAN)

elon musk and taylor swift demo video

https://reddit.com/link/cxbovi/video/9hve1gfydij31/player",31,0,PuzzledProgrammer3,2019-08-30 03:53:42,https://www.reddit.com/r/deeplearning/comments/cxbovi/few_shot_face_translation_gan_face_swapping_video/,0,deeplearning
cuu6ii,Simple Perceptron explanation,,28,0,nottingpill,2019-08-24 14:40:40,https://www.youtube.com/watch?v=JNYTQIA7zOs&t=8s,0,deeplearning
cakm3c,Deep Nude Algorithm,I found out that Deep Nude algorithm was deleted from github. Did anyone clone it? Can you please share it?,33,121,frankshawn1992,2019-07-08 12:49:11,https://www.reddit.com/r/deeplearning/comments/cakm3c/deep_nude_algorithm/,0,deeplearning
c25m59,Faster R-CNN Object Detection with PyTorch,,29,2,spmallick,2019-06-18 18:06:58,https://i.redd.it/0qlxt0qnn5531.gif,0,deeplearning
bqkx18,Make a Face GAN (Generative Adversarial Network) in 15 Minutes,,35,0,None,2019-05-19 19:26:34,https://www.youtube.com/watch?v=qbW-X6iW5jE&t=361s,0,deeplearning
bp5931,Where to learn neural network architecture design,"So people at Deep Mind and OpenAi comes up with great models that are really innovatively designed. Can someone please tell me how and where I can learn the skill to design a neural network for a specific problem.
 Thank you",31,12,DongDilly,2019-05-15 23:29:08,https://www.reddit.com/r/deeplearning/comments/bp5931/where_to_learn_neural_network_architecture_design/,0,deeplearning
bg37ne,Everyone Is an Artist: GauGAN Turns Doodles Into Photorealistic Landscapes,,31,1,Yuqing7,2019-04-22 15:11:02,https://medium.com/syncedreview/everyone-is-an-artist-gaugan-turns-doodles-into-photorealistic-landscapes-d1dae15b34e1,0,deeplearning
b8qwnv,"DIY Deep learning workstation, better performance than most of the WS sellers | overheating issue fixed on multiple cards system",,32,14,gimel1213,2019-04-03 00:02:10,https://i.redd.it/rfrli1pwwxp21.jpg,0,deeplearning
b29578,"Deep learning + Music, Music Generation using GAN , How to play songs from the midi images","I am exploring to this repository : [musegan](https://github.com/salu133445/musegan) and tried to exectue it.

My shared [Google Colab Link](https://colab.research.google.com/drive/12Vw3-94YXbOKmNhuBh0TrKrgfZeOVmlQ)

&#x200B;

It executes but i have no idea where do i get the generated music samples or how do i run the music.It produces bunch of `.png` images in the `./exp/`  folder but i don't know how is that helpful for generating music

&#x200B;

even in the ReadMe file of this project the [Results](https://github.com/salu133445/musegan#sample-results) if you download it , it give bunch of images. I have no idea how can i use these images.

&#x200B;

I am new to ML and Deep Learning, I picked this project because i have interest in music and i wanted to get inspired how deep learning will solve this problem.

&#x200B;

i have read about ANN, RNN & CNN  and GAN but i am at a very noob level. But i want to learn this.

I did watch this video of project owner, [Video](https://www.youtube.com/watch?v=SHPjZwSbRhs) But it's in Chinese , i did used [Google Translate (Chinese to English)](https://translate.google.com/?rlz=1C5CHFA_enIN831IN831&um=1&ie=UTF-8&hl=en&client=tw-ob#zh-TW/en/) to convert the audio into english text but it wasn't that great experience.

&#x200B;

These are the slides :      [Slide 1](https://salu133445.github.io/bmusegan/pdf/bmusegan-ismir2018-slides.pdf)[Slide 2](https://salu133445.github.io/musegan/pdf/musegan-aaai2018-slides.pdf)

&#x200B;

&#x200B;

I know this is not the best first project to choose, but this is what interests me so i'll be more happy to invest my time to know about this project.

&#x200B;

My background is in web-development both front-end & back-end.

&#x200B;",31,8,prashantkr314,2019-03-17 19:47:43,https://www.reddit.com/r/deeplearning/comments/b29578/deep_learning_music_music_generation_using_gan/,0,deeplearning
ayd147,"Comprehensive Deep Learning Git Codebook, Video Tutorials and Projects","&#x200B;

https://preview.redd.it/rap1mjxagpk21.jpg?width=1875&format=pjpg&auto=webp&s=4be3591f63a156ab888117f84ed9526d323272fb

**Comprehensive** **Deep Learning tutorials** [(Free Video Tutorials)](https://www.edyoda.com/course/1429) [(Github codebook)](https://github.com/zekelabs/AI101-DeepLearning)

&#x200B;

**Build Deep Learning Projects (Complete Video Series for FREE )**

**1.** [Making your RL Projects in 20 Minutes](https://www.edyoda.com/course/1421)

**2.** [Style Transfer, Face Generation using GANs in 20 minutes](https://www.edyoda.com/course/1418)

**3.** [Language and Machine Learning in 20 minutes](https://www.edyoda.com/course/1419)

**4.** [AI Project - Web application for Object Identification](https://www.edyoda.com/course/1185)

**5.** [Dog Breed Prediction](https://www.edyoda.com/course/1336)

**Free** **Video Series for Beginners to advanced users**

**1.** [Machine Learning - Mastering NumPy](https://www.edyoda.com/course/1263)

**2.** [Machine Learning using Tensorflow](https://www.edyoda.com/course/99)

**3.** [Step by step guide to Tensorflow](https://www.edyoda.com/course/1429)

**4.** [Introduction to Neural Networks](https://www.edyoda.com/course/1417)

**5.** [Knowledge Graphs, Deep Learning and Reasoning](https://www.edyoda.com/course/1420)",31,0,nalinee_choudhary,2019-03-07 14:13:49,https://www.reddit.com/r/deeplearning/comments/ayd147/comprehensive_deep_learning_git_codebook_video/,0,deeplearning
a40oqr,"Hinton explains the differences between the Symbolic and connectionists approach to the AI. He encourages Europe to stop funding ""old-fashioned AI people"" and instead focusing on the connectionists approach a.k.a deep learning",,31,3,dt_magic,2018-12-07 15:05:31,https://www.linkedin.com/feed/update/urn:li:activity:6476698738780966912,0,deeplearning
7jk009,A Tensor Flow implementation of Capsule Networks Explained by Aurelien Geron,,29,0,F4il3d,2017-12-13 15:34:34,https://youtu.be/2Kawrd5szHE,0,deeplearning
7jd56r,"A nice, easy to follow tutorial on Capsule Networks based on Sabour, Frosst and Hinton's Paper.",,30,0,F4il3d,2017-12-12 19:15:04,https://www.youtube.com/watch?v=pPN8d0E3900,0,deeplearning
1ardr2c,Is Math really that Important for Deep Learning.,"I know how algo DL works, but indepth understanding of every algorithm is it that important, If not learning them in depth is really  waste of time?",32,35,_Killua_04,2024-02-15 11:52:36,https://www.reddit.com/r/deeplearning/comments/1ardr2c/is_math_really_that_important_for_deep_learning/,0,deeplearning
168onwq,"Coding LLaMA 2 from scratch in PyTorch, with step by step explanation of KV Cache, Grouped Query Attention, Rotary Positional Embedding, RMS Normalization, SwiGLU and much more!",,29,6,hkproj_,2023-09-03 05:38:09,https://www.youtube.com/watch?v=oM4VmoabDAI,0,deeplearning
1532yrn,Meta just released LLaMa 2 (up to 70B parameters)! ü§Ø,"Meta just released LLaMA 2, it is the next iteration of LLaMA and comes with a commercial-friendly license. This release includes model weights and starting code for pre-trained and fine-tuned Llama language models ‚Äî ranging from 7B to 70B parameters.

Link to the announcement-  
[https://ai.meta.com/llama/](https://ai.meta.com/llama/)

Link to the models-  
[https://huggingface.co/models?other=llama-2](https://huggingface.co/models?other=llama-2)

LLaMA 2 Chat will be as good as OpenAI ChatGPT. ü§©",29,1,None,2023-07-18 16:21:59,https://www.reddit.com/r/deeplearning/comments/1532yrn/meta_just_released_llama_2_up_to_70b_parameters/,0,deeplearning
14jujdi,"DragGAN released, you can try it with my Google Colab notebook","A month ago, everyone was talking about DragGAN. There were many big words and expectations. And a few hours ago, its code was released on GitHub, and of course, I immediately started studying the topic and went to try out this innovative tool, which seemed promising.

As a result, I created:

* **A Google Colab notebook with DragGAN.** I also cleaned it up a bit in case you want to try using it too. I'll leave the link below.
* **Review and tutorial on YouTube**, with general information about GANs, specifically DragGAN, a couple of silly jokes, and my personal opinion after using it. Spoiler: It's not all that great. And one of my *impressive* results are shown at the bottom.

[The Google Colab notebook](https://colab.research.google.com/drive/1-WH-DMgE0dFJ3Q_bkAJX7iSe1DvLooul?usp=sharing)

[The YouTube tutorial](https://www.youtube.com/watch?v=K2p2i62yoG4)",28,4,rocket__cat,2023-06-26 21:53:26,https://www.reddit.com/r/deeplearning/comments/14jujdi/draggan_released_you_can_try_it_with_my_google/,0,deeplearning
12jsi0e,Cheapest GPU for small model deployment,"What is the cheapest GPU cloud platform to deploy small cloud models for API inferencing? I am trying to find the cheapest cloud GPU with 2GB-4GB GPU, which do you recommend? And for an MLOps-based project which platform for similar GPU requirements is the best?",31,5,gokulPRO,2023-04-12 17:00:38,https://www.reddit.com/r/deeplearning/comments/12jsi0e/cheapest_gpu_for_small_model_deployment/,0,deeplearning
zk5esp,ChatGPT context length,"How come ChatGPT can follow entire discussions whereas nowaday's LLM are limited (to the best of my knowledge) 4096 tokens ?

I asked it and it is not able to answer neither, and I found nothing on Google because no paper is published. I was also curious to understand how come Beamsearch was so fast with ChatGPT.

https://preview.redd.it/o6djsmpb5i5a1.png?width=1126&format=png&auto=webp&s=98baae5bf6fa294db408f0530214f8afa8a32a0b",30,10,Wild-Ad3931,2022-12-12 17:29:39,https://www.reddit.com/r/deeplearning/comments/zk5esp/chatgpt_context_length/,0,deeplearning
xhf82r,"450+ Pratice Questions for Pandas, SQL, and NumPy.","Hi all

I have prepared a set of 450+ practice questions that you can use to improve your data science skills in Pandas, SQL, and NumPy libraries.

These questions cover a wide variety of topics from each of these tools.

You can read more about practicing this notebook in my [Blog on Medium](https://medium.com/geekculture/450-practice-questions-that-will-make-you-a-pandas-numpy-and-sql-pro-1cd6f72ee330).

Thanks and I hope you'll have fun solving them :)",31,3,avee-81,2022-09-18 12:20:56,https://www.reddit.com/r/deeplearning/comments/xhf82r/450_pratice_questions_for_pandas_sql_and_numpy/,0,deeplearning
vu4t7k,YoloV7 Finally an official Yolo. This should actually be V5,"[https://github.com/WongKinYiu/yolov7](https://github.com/WongKinYiu/yolov7)

[https://arxiv.org/abs/2207.02696](https://arxiv.org/abs/2207.02696)",29,3,kumurule,2022-07-08 07:15:40,https://www.reddit.com/r/deeplearning/comments/vu4t7k/yolov7_finally_an_official_yolo_this_should/,0,deeplearning
uuv3wr,"Gradio Blocks + Hugging Face event, build ML web demos like DALLE-mini! A hackathon type event from May 17th to May 31st with prizes in which we will create interactive web demos for state-of-the-art machine learning models",,31,1,Illustrious_Row_9971,2022-05-21 20:18:05,https://v.redd.it/8xdo8nil0w091,0,deeplearning
tjzw9c,"Nebullvm, an open-source library to accelerate AI inference by 5-20x in a few lines of code","How does [nebullvm](https://github.com/nebuly-ai/nebullvm) work?

It takes your AI model as input and outputs an optimized version that runs 5-20 times faster on your hardware. In other words, nebullvm tests multiple deep learning compilers to identify the best possible way to execute your model on your specific machine, without impacting the accuracy of your model.

And that's it. In just a few lines of code.

And a big thank you to everyone for supporting this open-source project! The library received 250+ Github stars‚≠ê on release day, and that's just amazing üöÄ

ORIENTATION MAP

Let's learn more about nebullvm and AI optimization. Where should we start? From...

* Some **CONTEXT** on why few developers optimize AI and related negative consequences
* An overview of how the **LIBRARY** works
* Some **USE CASES**, technology demonstrations and benchmarks
* A description of the **TECHNOLOGY** behind the library

Or let's jump straight to the library ‚Üí [nebullvm](https://github.com/nebuly-ai/nebullvm)

CONTEXT

Finally, the adoption of Artificial Intelligence (AI) is growing rapidly, although we are still far from exploiting the full potential of this technology.

Indeed, what typically happens is that AI developers spend most of their time on data analysis, data cleaning, and model testing/training with the objective of building very accurate AI models.

Yet... few models make it into production. If they do, two situations arise:

1. AI models are developed by skilled data scientists and great AI engineers, who often have limited experience with cloud, compilers, hardware, and all the low-level matters. When their models are ready to be deployed, they select the first GPU or CPU they can think of on the cloud or their company/university server, unaware of the severe impact on model performance (i.e. much slower and more expensive computing) caused by uninformed hardware selection, poor cloud infrastructure configuration, and lack of model/hardware post-training optimization.
2. Other companies have developed in-house AI models that work robustly. AI inference is critical to these companies, so they often build a team of hardware/cloud engineers who spend hours looking for out-of-the-box methods to optimize model deployment.

Do you fall into one of these two groups? Then you might be interested in the nebullvm library, and below we explain why.

LIBRARY

How does nebullvm work?

You import the library, nebullvm does some magic, and your AI model will run 5-20 times faster.

And that's it. In just a few lines of code.

The goal of nebullvm library is to let any developer benefit from deep learning compilers without having to waste tons of hours understanding, installing, testing and debugging this powerful technology.

https://preview.redd.it/q6vt7njowwo81.png?width=3446&format=png&auto=webp&s=1c5e88bdb141917297edae5854c09c482a460936

Nebullvm is quickly becoming popular, with 250+ GitHub stars on release day and hundreds of active users from both startups and large tech companies. The library aims to be:

* **Deep learning model agnostic.** Nebullvm supports all the most popular architectures such as transformers, LSTMs, CNNs and FCNs.
* **Hardware agnostic.** The library now works on most CPUs and GPUs and will soon support TPUs and other deep learning-specific ASICs.
* **Framework agnostic.** Nebullvm supports the most widely used frameworks (PyTorch, TensorFlow and Hugging Face) and will soon support many more.
* **Secure.** Everything runs locally on your machine.
* **Easy-to-use.** It takes a few lines of code to install the library and optimize your models.
* **Leveraging the best deep learning compilers**. There are tons of deep learning compilers that optimize the way your AI models run on your hardware. It would take tons of hours for a developer to install and test them at every model deployment. The library does it for you!

Do you like the concept? [Try nebullvm on GitHub and leave a ‚≠ê](https://github.com/nebuly-ai/nebullvm) if you enjoy the project. It's a simple act for you, a big smile for us :) Happy acceleration üöÄ

USE CASES

Why is accelerating computing by 5-20x so valuable?

To **save time** ‚Üí Accelerate your AI services and make them real-time.

To **save money** ‚Üí Reduce cloud computing costs.

To **save energy** ‚Üí Reduce the electricity consumption and carbon footprint of your AI services.

Probably you can easily grasp how accelerated computing can benefit your specific use case. We'll also provide you with some use cases on how nebullvm is helping many in the community across different sectors:

* Fast computing makes search and recommendation engines faster, which leads to a more enjoyable user experience on websites and platforms. Besides, near real-time AI is a strict requirement for many healthtech companies and for autonomous driving, when slow response time can put people's lives in danger. The metaverse and the gaming industry also require near-zero latency to allow people to interact seamlessly. Speed can also provide an edge in sectors such as crypto/NFT/fast trading.
* Lowering costs with minimal effort never hurts anyone. There is little to explain about this.
* Green AI is a topic that is becoming more popular over time. Everyone is well aware of the risks and implications of climate change and it is important to reduce energy consumption where possible. Widespread awareness of the issue is reflected in how purchasing behavior across sectors is moving toward greater sustainability. In addition, low power consumption is a system requirement in some cases, especially on IoT/edge devices that may not be connected to continuous power sources.

TECHNOLOGY DEMONSTRATION

We suggest testing the library on your AI model right away by following the installation instructions on [Github](https://github.com/nebuly-ai/nebullvm). If instead you want to get a hands-on sense of the library's capabilities, check out the [notebooks at this link](https://www.reddit.com/r/nebuly/comments/tjcagv/testing_nebullvm_the_opensource_ai_accelerator_on/) where you can test nebullvm on popular deep learning models. Note that notebooks will still require you to install the library as you will to test nebullvm on your models, which will take several minutes. Once it's installed, nebullvm will optimize your models in a short time.

BENCHMARKS

We have also tested nebullvm on popular AI models and hardware from leading vendors.

* Hardware: M1 Pro, NVIDIA T4, Intel Xeon, AMD EPYC
* AI Models: EfficientNet, Resnet, SqueezeNet, Bert, GPT2

At first glance, we can observe that acceleration varies greatly across hardware-model couplings. Overall, the library provides great positive results, most ranging from 2 to 30 times speedup.

To summarize, the results are:

* Nebullvm provides positive acceleration to non-optimized AI models
* Early results show poorer (yet positive) performance on Hugging Face models. Support for Hugging Face has just been released and improvements will be implemented in future versions
* Nebullvm provides a \~2-3x boost on Intel hardware. These results are most likely related to an already highly optimized implementation of PyTorch for Intel devices
* Extremely good performances on NVIDIA machines
* The library provides great performances also on Apple M1 chips
* And across all scenarios, nebullvm is very useful for its ease of use, allowing you to take advantage of deep learning compilers without having to spend hours studying, testing and debugging this technology

The table below shows the response time in milliseconds (ms) of the non-optimized model and the optimized model for the various model-hardware couplings as an average value over 100 experiments. It also displays the **speedup** provided by nebullvm, where speedup is defined as the response time of the optimized model over the response time of the non-optimized model.

https://preview.redd.it/p2v6kf3twwo81.png?width=2208&format=png&auto=webp&s=0d60f12c24a750953e58d28f1121ca67b0a88600

Hardware used for the experiment

* M1 Pro ‚Üí Apple M1 Pro 16GB of RAM
* Intel Xeon ‚Üí EC2 Instance on AWS - t2.large
* AMD EPYC ‚Üí EC2 Instance on AWS - t4a.large
* Nvidia T4 ‚Üí EC2 instance on AWS - g4dn.xlarge

TECHNOLOGY

Nebullvm leverages the best deep learning compilers to accelerate AI models in inference.

So what exactly are deep learning compilers?

A deep learning compiler takes your model as input and produces an efficient version of it that runs the model computation graph faster on a specific hardware.

How?

There are several methods that, in principle, all attempt to rearrange the computations of neural networks to make better use of the hardware memory layout and optimize hardware utilization.

In very simplistic terms, deep learning optimization can be achieved by optimizing the entire end-to-end computation graph, as well as by restructuring operators (mainly for loops related to matrix multiplications) within the graph \[[1](https://huyenchip.com/2021/09/07/a-friendly-introduction-to-machine-learning-compilers-and-optimizers.html), [2](https://arxiv.org/pdf/2002.03794.pdf)\]. Here are some examples of optimization techniques:

* **Operator fusion**. It refers to the process where a sequence of operators eligible for fusion is first identified and then replaced with a corresponding handwritten implementation. Fusing operators allows for better sharing of computation, removal of intermediate allocations, and facilitates further optimization by combining loop nests. \[[3](https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/46765/Roesch_washington_0250E_22406.pdf?sequence=1&isAllowed=y)\]
* **Quantization**. It refers to¬†techniques for performing computations and storing tensors at lower bitwidths than floating point precision. A quantized model executes some or all of the operations on tensors with integers rather than floating point values. \[[4,](https://arxiv.org/pdf/2103.13630.pdf) [5](https://leimao.github.io/article/Neural-Networks-Quantization/)\]
* **Graph pruning**. Pruning refers to removing certain parameters in the neural network because they are redundant and do not contribute significantly to the output, resulting in a smaller, faster network. \[[6](https://towardsdatascience.com/neural-network-pruning-101-af816aaea61)\]

Deep learning optimization depends greatly on the specific hardware-software coupling, and specific compilers work best on specific couplings. So it is difficult to know a priori the performance of the many deep learning compilers on the market for each specific use case and testing is necessary. This is exactly what [nebullvm](https://github.com/nebuly-ai/nebullvm) does, saving programmers countless hours.

ACKNOWLEDGEMENTS

The team behind nebullvm are a group of former MIT, ETH, and EPFL folks who team up together and launched [Nebuly](https://nebuly.ai/). They developed this open-source library along with a lot of other great technologies to make AI more efficient. You can find out more about Nebuly on its [website](https://nebuly.ai/), [LinkedIn](https://www.linkedin.com/company/72460022), [Twitter](https://twitter.com/nebuly_ai) or [Instagram](https://www.instagram.com/nebuly_ai/).

Many kudos go to [Diego Fiori](https://www.linkedin.com/in/diego-fiori-b64b3016a/), the library's main contributor. Diego is a curious person and always thirsty for knowledge, which he likes to consume as much as good food and wine. He is a versatile programmer, very jealous of his code, and never lets his code look less than magnificent. In short, Diego is the CTO of [Nebuly](https://nebuly.ai/).

Huge thanks also go to the open-source community that has developed numerous DL compilers that enable to accelerate AI models.

And finally, many thanks to all those who are supporting the [nebullvm open-source community](https://github.com/nebuly-ai/nebullvm/stargazers), finding bugs and fixing them, and enabling the creation of a state-of-the-art, this super-powerful AI accelerator.

REFERENCES

Papers and articles about deep learning compilers.

\[1\] A friendly introduction to machine learning compilers and optimizers by [Chip Huyen](https://huyenchip.com/2021/09/07/a-friendly-introduction-to-machine-learning-compilers-and-optimizers.html)

\[2\] The Deep Learning Compiler: A Comprehensive Survey by [Mingzhen Li & Al](https://arxiv.org/pdf/2002.03794.pdf)

\[3\] Principled optimization of dynamic neural networks by [Jared Roesch](https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/46765/Roesch_washington_0250E_22406.pdf?sequence=1&isAllowed=y)

\[4\] A Survey of Quantization Methods for Efficient Neural Network Inference by [Amir Gholami & Al.](https://arxiv.org/pdf/2103.13630.pdf)

\[5\] Quantization for Neural Networks by [Lei Mao](https://leimao.github.io/article/Neural-Networks-Quantization/)

\[6\] Neural Network Pruning 101 by Hugo [Tessier](https://towardsdatascience.com/neural-network-pruning-101-af816aaea61)

Documentation of deep learning compilers used by nebullvm.

* [Apache TVM](https://tvm.apache.org/)
* [NVIDIA](https://www.nvidia.com/)'s [TensorRT](https://developer.nvidia.com/tensorrt)
* [Intel](https://www.intel.com/)'s [OpenVINO](https://docs.openvino.ai/latest/index.html)
* [MLIR](https://mlir.llvm.org/)",32,13,emilec___,2022-03-22 10:28:47,https://www.reddit.com/r/deeplearning/comments/tjzw9c/nebullvm_an_opensource_library_to_accelerate_ai/,0,deeplearning
t8atpp,RunPod.io offering free GPU time to celebrate soft launch,"Hello all! Before I say too much, I read the rules panel on the side, and didn't see anything against this post there. If I have broken any rules in posting this, I am truly sorry!

**TLDR;** My business partner and I are offering free compute time on our platform, [runpod.io](https://runpod.io) in exchange for feedback. Please join our [discord](https://discord.gg/pJ3P2DbUUq) or email [support@runpod.io](mailto:support@runpod.io) to sign up.

**Longer version:**

I know that there are/have been plenty of websites that offer computer time leasing, but we think that we are well positioned to offer a compelling alternative.

For our soft launch, we are offering a few machines for free:

>Machine 1  
>  
>12x 3070 PCIe 3 x16  
>  
>Threadripper PRO 3955WX  
>  
>192 GB RAM  
>  
>3TB NVMe storage

&#x200B;

>Machine 2  
>  
>4x 3080 PCIe 3 x16  
>  
>Threadripper PRO 3955WX  
>  
>256 GB RAM  
>  
>3TB NVMe RAID0

&#x200B;

>Machine 3  
>  
>2x 3090 PCIe 4 x8  
>  
>Ryzen 9 5900X  
>  
>128 GB RAM  
>  
>1TB NVMe storage

We aren't starting with a large fleet of machines, so free access to them will have to be an orchestrated affair.

**Rules:**

You have to have something that you actually want to run. If we see that you're just idling on a machine, we'd kindly ask you to let someone else have a turn.

Productive projects only. No mining for free here please.

Give us honest feedback. We're looking to build something good, and we need your help to do so.

&#x200B;

**Features:**

[FAQ](https://runpod.io/faq)

[How to](https://runpod.io/recipes)

Persistent volume storage, so you can change your working image and keep your data intact.

Stop/Resume pods as long as GPUs are available on your host machine (not locked to specific GPU index)

SSH access to RunPod pods

EZmode Jupyter notebook configuration

Support for exposing ports in your RunPod pod so you can host things like Jupyter notebook

Support for environment variables

Easy payments through Stripe integration

&#x200B;

**Coming soon:**

Benchmark metrics for our offerings

NVLink support

More host machines, both in variety and number, but we want to properly vet them to ensure a good client experience.

you tell us!

**Further out:**

Resume pods on a different machine

Ability to run on a network of machines

Datacenter partners for users that need a higher tier of service

&#x200B;

**Final Thoughts**

All this being said, the platform is 100% operational, so it can already be used. We just want to take it slow so that we can ensure that we can address the feedback that we get appropriately.

We really value your feedback and we want to build something that people would want to use. We've seen some of the other stuff out there and there's a mix of issues that we'd like to solve. The goal is to offer enthusiasts a platform that they would actually enjoy using for a fraction of the price that other platforms advertise. Our roadmap is filled with stuff that we think would be cool to have, but we really want you guys to help us build a roadmap that makes sense. Thank you for anyone who has read this far. I'd love to speak to you!

&#x200B;

Sincerely,

Zhen",32,12,zhl146,2022-03-06 22:58:22,https://www.reddit.com/r/deeplearning/comments/t8atpp/runpodio_offering_free_gpu_time_to_celebrate_soft/,0,deeplearning
s3qel7,Tutorial: Time-Series Transformer + Time2Vec,"# [Tutorial] Transformers for Time-Series (Time2Vec)

How to use transformers for Time-series data? ü§î
> **TLDR:** [The notebook](https://www.kaggle.com/yamqwe/tutorial-time-series-transformer-time2vec)





#### Rolling Window Setup
_____

- Our data comes in a table. 

- We want to model a series. (which is not a table)

- We got a problem. 



In order to solve our problem we will transform the table to the following set-up: 
Each of our input vectors will be a slice of the dataset representing a rolling-window of N times-steps,
For each of these vectors we will also slice a target vector corresponding to the indices of the rolling-window.


In short, we create the following input and output:

- **X** shape: (samples, time-steps, features)
- **y** shape: (samples, 1)

Figure: https://i.ibb.co/ZfsK9ZY/1-q-6btr-S9-S-mc-JDdc-AW-It-A.png


_____

In order for us to get a better understanding, let's plot a fictional time series just to see the this set up in practice. There will be 2 features. `feature_1` is following a sine wave, `feature_2` is a linear function. The time series consists of 100 timesteps.

Figure: https://i.ibb.co/yNPWBcZ/results-6-0.png

> **Credit for this plot goes to Leonie's amazing Time-series notebooks**



#### Time Series Transformers ü§ñ
-----

**Let's apply a Time-Series transformer with the above set-up!**



As we all know, transformers are taking over the state-of-the-art title in any field they get into. It was just a matter of time until we got the first papers implementing them for time-series. 

The rest of the notebook implements a transformer model for learning the representation of a Time-series. 
It learns to attend both to preceding and succeeding segments in individual features, as well as the inter-dependencies between features.


**Differences between Transformers and Time-Series Transformers:**

- 1. In the paper, they use batchnorm rather than layernorm, this is because the problem with batchnorm in the first place was variation in input length for NLP. This is the reason for the inferior performance of batch normalization in NLP (i.e., sentences in most tasks) (Shen et al., 2020). 

- 2. In the paper, they use a **Fully learnable positional encodings** rather than a fixed positional encoding (As the classic BERT is using. It is observed that they perform better for all datasets presented in the paper.

- 3. In the paper, they have an unsupervised training phase using Masked MLM input (sequential masking starting from left). The model then tries to predict all of the input vector but the loss given is only from the masked indices. The reconstruction loss is mse. 

- 4. In this notebook we apply residual skip connections as it is done on the implementation linked above: We use a constant ""SKIP_CONNECTION_STRENGTH"" and multiply the skip connection by it. This improves performance in practice. 

- 5. In this notebook we extend the ""learnable embeddings"" and apply Time2Vec ([paper](https://arxiv.org/abs/1907.05321)). This also improves performance in practice. 

### Architecture & Loss Function

The model is trained with keras for about 1,000 epochs using combined training and test sets. The loss function is **MAE loss** trained end2end to the targets. You could play around with the hyperparameters for a larger model or use more hand-crafted features as the input.

Figure: https://i.ibb.co/TTDp6kZ/1-TWkm-OC8a-K-2-Tgc-CIm-m-KMg.png


```
class TransformerBlock(layers.Layer):
    def __init__(self, embed_dim, feat_dim, num_heads, ff_dim, rate = 0.1):
        super(TransformerBlock, self).__init__()
        self.att = layers.MultiHeadAttention(num_heads = num_heads, key_dim = embed_dim)
        self.ffn = keras.Sequential( [layers.Dense(ff_dim, activation = ""gelu""), layers.Dense(feat_dim),] )
        self.layernorm1 = layers.BatchNormalization()
        self.layernorm2 = layers.BatchNormalization()
        self.dropout1 = layers.Dropout(rate)
        self.dropout2 = layers.Dropout(rate)

    def call(self, inputs, training):
        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training = training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training = training)
        return self.layernorm2(out1 + ffn_output)
```


### Time 2 Vec Embeddings

Mathematically speaking, implementing Time2Vec is quite easy:

Figure: https://i.ibb.co/yhphBqc/1-E8-Zi-ELOi-Gv-Nu-WCAHX8f-Rw.png

[from https://arxiv.org/pdf/1907.05321.pdf]


Where k is the time2vec dimension, tau is a raw time series, F is a periodic activation function, omega and phi are a set of learnable parameters. 

In this notebook, we set F to be a sin function in order to help the algorithm capture periodic behaviors in data. At the same time, the linear term represents the progression of time and can be used for capturing non-periodic patterns in the input that depend on time.



```
class Time2Vec(tf.keras.layers.Layer):
    def __init__(self, kernel_size = 1):
        super(Time2Vec, self).__init__(trainable = True, name = 'Time2VecLayer')
        self.k = kernel_size

    def build(self, input_shape):
        # trend
        self.wb = self.add_weight(name = 'wb', shape = (input_shape[1],), initializer = 'uniform', trainable = True)
        self.bb = self.add_weight(name = 'bb', shape = (input_shape[1],), initializer = 'uniform', trainable = True)
        # periodic
        self.wa = self.add_weight(name = 'wa', shape = (1, input_shape[1], self.k), initializer = 'uniform', trainable = True)
        self.ba = self.add_weight(name = 'ba', shape = (1, input_shape[1], self.k), initializer = 'uniform', trainable = True)
        super(Time2Vec, self).build(input_shape)

    def call(self, inputs, **kwargs):
        bias = self.wb * inputs + self.bb
        dp = K.dot(inputs, self.wa) + self.ba
        wgts = K.sin(dp) # or K.cos(.)
        ret = K.concatenate([K.expand_dims(bias, -1), wgts], -1)
        ret = K.reshape(ret, (-1, inputs.shape[1] * (self.k + 1)))
        return ret

    def compute_output_shape(self, input_shape):
        return (input_shape[0], input_shape[1] * (self.k + 1))
```


This creates a representation that is somewhat similar to positional embedding while improving its representation power, boosting its performance for time-series data.

Figure: https://i.ibb.co/37h8LvW/1-PYxmooqjij-ARQ2f0-PWAW-g.png",32,6,yamqwe,2022-01-14 11:40:52,https://www.reddit.com/r/deeplearning/comments/s3qel7/tutorial_timeseries_transformer_time2vec/,0,deeplearning
qx3rdo,A Beginner‚Äôs Guide to Tensorflow,"A post on getting started with TensorFlow in Deep Learning

[**A Beginner‚Äôs Guide to Tensorflow**](https://debuggercafe.com/a-beginners-guide-to-tensorflow/)

&#x200B;

https://preview.redd.it/z1dgz0ij5g081.png?width=1920&format=png&auto=webp&s=03dc44b87109abaa237061824cb2e5d0ab4d5a8c",29,2,sovit-123,2021-11-19 00:28:14,https://www.reddit.com/r/deeplearning/comments/qx3rdo/a_beginners_guide_to_tensorflow/,0,deeplearning
plgm5i,General CNN memory consumption - Interview Question,"A friend of mine recently interviewed at an AI startup for the role of an AI/ML SDE Intern. He was particularly asked a lot of questions based on memory consumption of CNN models. He was asked questions like how much memory do different CNNs would take? How much memory do different Optimizers consume in a network?

What might the interviewer be expecting here as answers? How would you respond to these questions? I also am preparing for AI based intern roles, so any help with this appreciated!",31,7,MusicalCakehole,2021-09-10 07:57:32,https://www.reddit.com/r/deeplearning/comments/plgm5i/general_cnn_memory_consumption_interview_question/,0,deeplearning
oe5xbe,Convolutional Neural Networks Explained (CNN Visualized),,28,0,SpaghettiFagetti,2021-07-05 12:00:42,https://www.youtube.com/watch?v=pj9-rr1wDhM,0,deeplearning
o0cjxa,Game search engine using Neural Networks - A demo built with 17k mobile strategy game dataset,,28,8,opensourcecolumbus,2021-06-15 11:52:49,https://i.redd.it/aixbz2d14f571.gif,0,deeplearning
ntu6ea,Dummy question: what does E mean in a loss function? I see this notation being used in many papers. This one below is the Wasserstein Distance used in WGANs.,,28,7,banenvy,2021-06-06 19:59:51,https://i.redd.it/lc2mbel9bp371.jpg,0,deeplearning
nax6od,AI turns GTA 5 into the real world,,30,7,cmillionaire9,2021-05-12 19:30:06,https://youtu.be/DfYb4AvT5Qo,0,deeplearning
mm571y,"Baidu Releases ‚ÄòPaddlePaddle‚Äô 2.0, Its Deep Learning Platform, With New Features Including Dynamic Graphs, Reorganized APIs (Documentation, Github link included)","Baidu Brain, a Chinese core AI technology engine, announces the release of PaddlePaddle 2.0. PaddlePaddle (PArallel Distributed Deep LEarning)) is an open-sourced AI platform released by Baidu Brain in 2016 to apply deep learning(DL) to many products at Baidu, such as NLP (Natural Language Processing), translation, and image processing.

PaddlePaddle‚Äôs latest version has features like dynamic (computational) graphs, a new API system, distributed training for trillion-parameter models, and better hardware support.

Summary: [https://www.marktechpost.com/2021/04/07/baidu-releases-paddlepaddle-2-0-its-deep-learning-platform-with-new-features-including-dynamic-graphs-reorganized-apis/](https://www.marktechpost.com/2021/04/07/baidu-releases-paddlepaddle-2-0-its-deep-learning-platform-with-new-features-including-dynamic-graphs-reorganized-apis/) 

API Documentation: [https://www.paddlepaddle.org.cn/documentation/docs/en/api/index\_en.html](https://www.paddlepaddle.org.cn/documentation/docs/en/api/index_en.html) 

GitHub: [https://github.com/PaddlePaddle](https://github.com/PaddlePaddle) 

Gitee: [https://gitee.com/paddlepaddle](https://gitee.com/paddlepaddle)",28,1,techsucker,2021-04-07 15:53:57,https://www.reddit.com/r/deeplearning/comments/mm571y/baidu_releases_paddlepaddle_20_its_deep_learning/,0,deeplearning
minvz9,StyleCLIP: Text-Driven Manipulation of StyleGAN Imagery (SOTA StyleGAN image editing) EXPLAINED,"This idea is so elegant, yet powerful:  
The authors use the recent CLIP model in a loss function to train a mapping network that takes text descriptions of image edits (e.g. ""a man with long hair"", ""Beyonce"", ""A woman without makeup"") and an image encoded in the latent space of a pretrained StyleGAN generator and predicts an offset vector that transforms the input image according to the text description of the edit.   


More details [here](https://t.me/casual_gan/18).   


https://preview.redd.it/pg961l0pesq61.png?width=1438&format=png&auto=webp&s=02227552bbf20b7bf612299a9560eda4617ceb8a",29,9,None,2021-04-02 16:30:48,https://www.reddit.com/r/deeplearning/comments/minvz9/styleclip_textdriven_manipulation_of_stylegan/,0,deeplearning
m9h05r,"GPU alternatives, that you can actually buy?","I am clinging to my GTX 1050 right now as I learn deep learning programming techniques, but the Vram is woefully small to do anything beyond the basics. I can do a lot with my CPU, but it's just not the same as having proper GPU-acceleration.

My options (that I know of) are:

1. **Cloud GPUs** \- the best option at the moment, but it gets expensive running lots of experiments
2. **Pay a scalper** \- I'd rather not
3. **Deep learning ASICs** \- I found an extensive list of Deep Learning ASICs that are in development: [https://blog.inten.to/hardware-for-deep-learning-part-4-asic-96a542fe6a81](https://blog.inten.to/hardware-for-deep-learning-part-4-asic-96a542fe6a81) . I've spent some time looking at all of the companies listed and can't find a single ASIC I can buy outright. Unless you've got $100K or deep industry connections, this seems like a no-go at this point.
4. ????",31,17,Value-Negative,2021-03-20 21:45:47,https://www.reddit.com/r/deeplearning/comments/m9h05r/gpu_alternatives_that_you_can_actually_buy/,0,deeplearning
m1liuz,"AI and Deep Learning pioneers Yoshua Bengio, Geoffrey Hinton and Yann LeCun (2018 Turing Award winners) at NVIDIA GTC21 (Free registration to hear their talks)","Thought this sub would be interested in this: Bengio, Hinton and LeCun won the 2018 ACM Turing Award, known as the Nobel Prize of computing, for breakthroughs that enabled the deep learning revolution. Their work underpins the proliferation of AI technologies now being adopted around the world, from natural language processing to autonomous machines. Bengio is a professor at the University of Montreal and head of the Montreal Institute for Learning Algorithms; Hinton is a professor at the University of Toronto and a researcher at Google; and LeCun is a professor at New York University and chief AI scientist at Facebook.  [https://nvda.ws/38skmfv](https://nvda.ws/38skmfv)

https://preview.redd.it/pgufpwf9p3m61.jpg?width=1209&format=pjpg&auto=webp&s=7df2b732beeb18682ffb89833637388e643c9115",32,2,Ai-GTC,2021-03-10 01:09:06,https://www.reddit.com/r/deeplearning/comments/m1liuz/ai_and_deep_learning_pioneers_yoshua_bengio/,0,deeplearning
lo4yhy,Nucleus Sampling: The Curious Case of Neural Text Degeneration (Research Paper Walkthrough),,28,1,prakhar21,2021-02-20 11:06:37,https://youtu.be/dCORspO2yVY,0,deeplearning
kls615,An in-depth detailed guide for LSTMs and practical implementation in PyTorch,,31,0,ItisAhmad,2020-12-28 15:09:13,https://cnvrg.io/pytorch-lstm/,0,deeplearning
kdte2u,Generate photorealistic landscapes using simple voice commands,,28,3,cmillionaire9,2020-12-15 20:10:06,https://youtu.be/14vq7BqEUjM,0,deeplearning
jmoh34,Reading group for Deep Learning book,"Edit: just created the discord channel
https://discord.gg/Rh5zZGSq
More things to come there

I just picked up the 'Deep Learning' book by Ian Goodfellow, et.al.
I'm thinking of having a reading group to keep each other accountable. We will set up a reading goal for a week and maybe do an hour zoom meeting every week to discuss the reading. If this interests anyone, let me know :D

(EST timezone right here)",31,55,alienmon,2020-11-02 14:35:00,https://www.reddit.com/r/deeplearning/comments/jmoh34/reading_group_for_deep_learning_book/,0,deeplearning
jmeer1,[D] What does it take for a career in Deep Learning?,"
I‚Äôm currently a sophomore at my college studying statistics. My interests lie in data science, specifically I‚Äôve been developing quite an interest in Deep Learning, and have been implementing neural networks from datasets on kaggle. Right now I‚Äôve only done computer vision but I plan to explore a lot more on my journey as I plan to learn about RNNs and it‚Äôs applications to NLP and Timeseries forecasting. My question is what does it take for a career in Deep Learning? I found out from a previous question I had asked on the data science  reddit that machine learning in the industry is much different than in academia. In industry it‚Äôs more so leveraging cloud platforms and infrastructure rather than explicit model building, and that the model building and research aspect is more so in academia. So my question is, what does it take to be a deep learning practitioner, whether it‚Äôs background/degrees/skills etc.",29,13,veeeerain,2020-11-02 01:29:03,https://www.reddit.com/r/deeplearning/comments/jmeer1/d_what_does_it_take_for_a_career_in_deep_learning/,0,deeplearning
jioo6w,Yann LeCun (Chief AI Scientist at Facebook) AR glasses are the killer app for deep learning hardware. The chips need to be ready in 2-3 years for the AR devices in 2025 or 2026,,30,0,AR_MR_XR,2020-10-26 22:17:09,https://youtu.be/GqEyqDCcggU,0,deeplearning
j0rxcc,Deep learning generative models for time series?,"I was wondering what are some good deep learning generative models for time series generation.

Is there anything like PixelCNN, VQ-VAE-2 or even a GAN but specifically for time series generation?

Thanks! :)",32,7,__horned_owl__,2020-09-27 14:23:59,https://www.reddit.com/r/deeplearning/comments/j0rxcc/deep_learning_generative_models_for_time_series/,0,deeplearning
iy4yw3,Why is softmax function the go to for probabilities calculation?,What I can't understand is why so many people use this as a go-to other than for its simplicity and ease to work with. Is this function infallible? Is there a reason why softmax is usually something you will always encounter in deep learning?,30,11,pennilessmillionaire,2020-09-23 06:29:46,https://www.reddit.com/r/deeplearning/comments/iy4yw3/why_is_softmax_function_the_go_to_for/,0,deeplearning
i6pwll,[P] We built an easy way to find image datasets,"Hi r/deeplearning!

My team and I recently launched a website to search for datasets for your machine learning projects. We‚Äôve all experienced the pain of searching for that perfect dataset. The world's datasets are scattered across academic websites and Github repos. That‚Äôs why we came up with Bifrost Data Search.

Bifrost Data Search is an initiative to aggregate, analyse and deliver the world's image datasets straight into the hands of AI developers. You can search from over 1000 listings paired with rich information and in-depth analyses. It‚Äôs **100% free** and we‚Äôre always adding more datasets and features.

This is just a beta release, and we‚Äôd love to hear your feedback so we can make this a valuable resource for the community! We're currently live on [https://www.producthunt.com/posts/bifrost-data-search](https://www.producthunt.com/posts/bifrost-data-search).

We really hope you like it!",29,1,Xcrinklecut,2020-08-09 19:54:30,https://www.reddit.com/r/deeplearning/comments/i6pwll/p_we_built_an_easy_way_to_find_image_datasets/,0,deeplearning
hs8syu,"As a beginner fresh from theoretical aspects of deep learning, how did you start doing projects that were more practical?","I just finished learning the theory behind deep learning and did some basic image classification projects, and i want suggestions. Where do i go from here or start the practical aspect of DL so that i may be able to do well in advanced DL competitions. I want to know how you started doing more advanced stuff?

Did you start with some intermediate kaggle competitions or reproducing someone else's research work ?",30,8,zruh09,2020-07-16 12:33:49,https://www.reddit.com/r/deeplearning/comments/hs8syu/as_a_beginner_fresh_from_theoretical_aspects_of/,0,deeplearning
gwcnxt,How to Advance my Understanding of Deep Learning/Computer Vision,"Hello, 

I just finished ""hands on ml with scikit learn and tensorflow"" and I loved it. I really want to advance my understanding of CNNs, but I don't know what steps to take next. 

\- I've heard great things about the ""Deep Learning with Python"" book by Francois Chollet, perhaps I could give that a read

\- I've done stuff in Kaggle, but I am still at the stage where I need some structure, so :/

\- Perhaps I could read state-of-the-art research papers and document my understandings

&#x200B;

\- How would you guys  suggest I get my hands dirty?",30,6,Stutoucan12,2020-06-04 07:30:06,https://www.reddit.com/r/deeplearning/comments/gwcnxt/how_to_advance_my_understanding_of_deep/,0,deeplearning
gtxaq7,What's the depth of this ResNet model,,29,9,mrvipul_17,2020-05-31 11:12:48,https://i.redd.it/hua2nqj033251.png,0,deeplearning
gpa9e1,Virtual Makeup with semantic segmentation,,31,0,rednivrug,2020-05-23 18:47:54,https://www.youtube.com/watch?v=h7_Ih08rxQw,0,deeplearning
gncjho,Gpt-2 Generated South Park chats between Characters,"[https://www.soulreplica.com/brodown](https://www.soulreplica.com/brodown)

discussion on HN: [https://news.ycombinator.com/item?id=23246418](https://news.ycombinator.com/item?id=23246418)

The chats between the characters are generated by Gpt-2 774M model trained over all season's southpark episodes. The characters sounds exactly like who they are in the show.  The conversations either starts from a random topic, or they can respond  to a random trending tweets (e.g. trump, elon musk, etc.) the results  could be very on point, and sometimes hilarious:

https://preview.redd.it/56zto0ivlxz41.png?width=2222&format=png&auto=webp&s=fbf7882ed5750171d76ba8ef4b59886bec9135d2

https://preview.redd.it/e583h0yulxz41.png?width=2548&format=png&auto=webp&s=86814f5de77377530a48e97ab8f2ddaddaf9fb5d",29,10,askbrodown,2020-05-20 14:40:55,https://www.reddit.com/r/deeplearning/comments/gncjho/gpt2_generated_south_park_chats_between_characters/,0,deeplearning
gbhg4b,Video Depth Estimation,,30,3,cmillionaire9,2020-05-01 12:46:04,https://youtu.be/51CQObCd_K0,0,deeplearning
g2l28r,Unsupervised Image-to-Image Translation Turns Selfies Into Anime Characters,"With the release of the new Tensorflow implementation of unsupervised generative network U-GAT-IT, anyone can simply upload a selfie to the ‚Äò[Selfie 2 Waifu](https://waifu.lofiu.com/index.html)‚Äô website to create their own AI-generated *waifu*\-style anime character in seconds. 

Here is a quick read: [Unsupervised Image-to-Image Translation Turns Selfies Into Anime Characters](https://medium.com/syncedreview/unsupervised-image-to-image-translation-turns-selfies-into-anime-characters-c90293e0f296)

Read the paper at [arXiv](https://arxiv.org/pdf/1907.10830.pdf). Visit this project's [GitHub](https://github.com/taki0112/UGATIT) page.",30,5,Yuqing7,2020-04-16 18:53:28,https://www.reddit.com/r/deeplearning/comments/g2l28r/unsupervised_imagetoimage_translation_turns/,0,deeplearning
fz3m37,Used an evolutionary algorithm to train a neural network which inverts and balances a pendulum,,28,5,cmillionaire9,2020-04-11 11:57:40,https://youtu.be/QJdoQQzuU6I,0,deeplearning
eyvk1e,"Deep learning accurately forecasts heat waves, cold spells",,34,0,key_info,2020-02-04 19:32:10,https://techxplore.com/news/2020-02-deep-accurately-cold.html,0,deeplearning
et9hkt,23 Amazing Deep Learning Project Ideas [Source Code Included],,31,5,karan991136,2020-01-24 12:01:27,https://data-flair.training/blogs/deep-learning-project-ideas/,0,deeplearning
dldroc,GitHub - sommerschield/ancient-text-restoration: Restoring ancient text using deep learning: a case study on Greek epigraphy.,,31,1,bil-sabab,2019-10-22 06:17:50,https://github.com/sommerschield/ancient-text-restoration,0,deeplearning
d26e1g,I wrote a PyTorch-based interface for normalizing flows,"[https://github.com/sshish/NF](https://github.com/sshish/NF)

Models can be easily created by e.g. stacking multiple layers on top of each other, and trained with crossentropy loss and entropy loss.

See examples of how to build a RealNVP or a B-NAF.

The code has pre-defined layers for rotation, permutation, coupling layer, ..., and is easily extensible.

Suggestions and collaborators are welcome.",30,3,stevethesteve2,2019-09-10 11:45:50,https://www.reddit.com/r/deeplearning/comments/d26e1g/i_wrote_a_pytorchbased_interface_for_normalizing/,0,deeplearning
cmgjvu,Explaining How DeepMind's Population Based Training Works,[https://www.youtube.com/watch?v=pEANQ8uau88&t=33s](https://www.youtube.com/watch?v=pEANQ8uau88&t=33s),31,7,HenryAILabs,2019-08-05 20:34:42,https://www.reddit.com/r/deeplearning/comments/cmgjvu/explaining_how_deepminds_population_based/,0,deeplearning
c9qiyx,How to plan and execute your ML and DL projects,,30,1,pirate7777777,2019-07-06 06:38:04,https://blog.floydhub.com/structuring-and-planning-your-machine-learning-project/,0,deeplearning
bwrf5v,25 Websites to Find Data Science Jobs,,27,1,ai_jobs,2019-06-04 17:27:53,https://www.springboard.com/blog/data-science-jobs/,0,deeplearning
bn3734,A Real-World Application of Deep Learning at Industrial Scale,,29,0,crubier,2019-05-10 20:15:23,https://medium.com/sterblue/a-real-world-application-of-deep-learning-at-industrial-scale-2233733f12cc,0,deeplearning
bho9y0,Interacting with the latent space of an AutoEncoder,"I recently made a simple tool for interacting with the latent space of an autoencoder. This helps you to interpret the role played by each neuron at the bottleneck by visualizing the changes in the reconstructed output.

Project : [https://github.com/koulanurag/visTorch](https://github.com/koulanurag/visTorch)

&#x200B;

I hope this could be useful to others as well.",28,2,HeavyStatus4,2019-04-26 16:26:51,https://www.reddit.com/r/deeplearning/comments/bho9y0/interacting_with_the_latent_space_of_an/,0,deeplearning
bffmve,OKAI - An Interactive Introduction to Artificial Intelligence (AI),,30,2,tydlwav,2019-04-20 18:49:44,http://okai.brown.edu,0,deeplearning
axm7b4,Microsoft Unveils Website to Create Art with GANs,,27,0,mhamilton723,2019-03-05 15:14:44,https://www.ailab.microsoft.com/experiments/gen-studio,0,deeplearning
9z4clz,Google Brain & Geoffrey Hinton Technique Thwarts Adversarial Attacks,,30,9,gwen0927,2018-11-21 15:50:22,https://medium.com/syncedreview/google-brain-geoffrey-hinton-technique-thwarts-adversarial-attacks-c1628f8339e9,0,deeplearning
9qdh0p,"""Yann LeCun @EPFL - ""Self-supervised learning: could machines learn like humans?""""",,32,1,dt_magic,2018-10-22 12:43:30,https://www.linkedin.com/feed/update/urn:li:activity:6460062087828815872,0,deeplearning
99h5ol,1x 2080Ti vs 2x 1080Ti for Deep Learning,"I've been wanting to build a beefy system (for both DL, ML, and Gaming) and now that the 1080Ti's are discounted, I was wondering what everyone thought.

Would 1x 2080Ti be better than 2x 1080Ti's? The former is supposedly faster, but the latter has double the memory so you can increase the batch sizes.

cost of 1x 2080Ti ‚âà cost of 2x 1080Ti (with the new discounts)",31,23,TacticalFloridaMan,2018-08-22 21:06:58,https://www.reddit.com/r/deeplearning/comments/99h5ol/1x_2080ti_vs_2x_1080ti_for_deep_learning/,0,deeplearning
7lv3wm,Nvidia changed EULA - no deep learning on geforce gpus in datacenters,,31,17,l3fth4nd3r,2017-12-24 13:21:59,http://www.nvidia.com/content/DriverDownload-March2009/licence.php?lang=us&type=GeForce,0,deeplearning
74hrgx,My new favorite site - Tensorflow Playground,,29,0,latetodata,2017-10-05 18:05:44,http://playground.tensorflow.org,0,deeplearning
1bqjj6n,When ML student struggle:,,29,0,Alphalll,2024-03-29 07:46:53,https://i.redd.it/iqqrw4j5a8rc1.png,0,deeplearning
17ki16j,How much code do you write from scratch vs How much code do you copy paste from the internet?,"I am pretty interested to know more on this. Not only in terms of ethics but in terms of understanding also. What qualifies you to be a successful practitioner? 

I kind of struggle with making something novel of my own. Most of my time goes into finding existing code but then I kind of question how much of the code I am looking at was written from scratch by the person who wrote it vs how much of it was copy pasted from other resources and then slightly tweaked for the use-case of interest.

I ask this because it kind of makes me question my competence - if I am unable to write anything from scratch(basically creating different py files with lots of classes etc or writing a full ipynb notebook) without looking at existing code. Does anyone feel the same way or do I need to work on something?

&#x200B;

If I do have to work on something, can anyone please point me to the right direction as to how to get better?

&#x200B;

Thanks",30,28,SONIC3695,2023-10-31 10:39:12,https://www.reddit.com/r/deeplearning/comments/17ki16j/how_much_code_do_you_write_from_scratch_vs_how/,0,deeplearning
16pr8q0,I hate tensorflow,that's all,28,25,gostreamNFR,2023-09-23 01:19:51,https://www.reddit.com/r/deeplearning/comments/16pr8q0/i_hate_tensorflow/,0,deeplearning
14j92cv,DragGAN code is finally released! (Interactive Point-based Manipulation on the Generative Image Manifold),"&#x200B;

https://reddit.com/link/14j92cv/video/dvf302fz0b8b1/player

[https://github.com/XingangPan/DragGAN](https://github.com/XingangPan/DragGAN)

[https://vcai.mpi-inf.mpg.de/projects/DragGAN/](https://vcai.mpi-inf.mpg.de/projects/DragGAN/)",29,0,rocket__cat,2023-06-26 06:14:34,https://www.reddit.com/r/deeplearning/comments/14j92cv/draggan_code_is_finally_released_interactive/,0,deeplearning
12jya0a,AI Video Generation Bot (@HalluGifBot),,28,4,tomd_96,2023-04-12 20:37:32,https://v.redd.it/ns48erd8jita1,0,deeplearning
12jeouf,A curated list of top AI research papers,"AI research has seen a great acceleration lately. This repository brings together the most important papers from 2022 to today in the fields of natural language processing, computer vision, audio processing, multimodal learning and reinforcement learning.

Github Link : [https://github.com/aimerou/top-ai-papers](https://github.com/aimerou/top-ai-papers)",29,7,Aimerou,2023-04-12 08:04:08,https://www.reddit.com/r/deeplearning/comments/12jeouf/a_curated_list_of_top_ai_research_papers/,0,deeplearning
yh8m84,Google Acquired An AI Avatar Startup 'Alter' For $100 Million To Take On TikTok,,28,0,vadhavaniyafaijan,2022-10-30 08:07:18,https://www.theinsaneapp.com/2022/10/google-acquired-ai-startup-alter.html,0,deeplearning
xoi48w,Introduction to micro-models or: how I learned to stop worrying and love overfitting,"**TLDR;** **What**: Low bias models applied to a small domain of a data distribution. **How**: Overfitting deep learning models on a handful of examples of a narrowly defined task. **Why**: Saving hundreds of hours of hand labelling.

[https://blog.encord.com/post/introduction-to-micro-models-or-how-i-learned-to-stop-worrying-and-love-overfitting](https://blog.encord.com/post/introduction-to-micro-models-or-how-i-learned-to-stop-worrying-and-love-overfitting)

Hi all! First post here from Encord, *the platform for data-centric computer vision.* As part of our work in computer vision we would like to share back our experience with the community - stay tuned for our blog posts and open-source projects!

In this article, we discuss *‚Äúmicro-model‚Äù methodology:* take advantage of overfitting to get highly accurate detections in a small domain of a data distribution. Enjoy!",29,4,encord_team,2022-09-26 12:37:38,https://www.reddit.com/r/deeplearning/comments/xoi48w/introduction_to_micromodels_or_how_i_learned_to/,0,deeplearning
uxo3qf,Hugging Face now allows Pull Requests and Discussions on ML repositories,,29,1,Illustrious_Row_9971,2022-05-25 18:45:01,https://i.redd.it/j9i4r76o3o191.png,0,deeplearning
tbqyup,GFP-GAN explained: Impressive face restoration model!,,30,4,OnlyProggingForFun,2022-03-11 14:10:40,https://youtu.be/nLDVtzcSeqM,0,deeplearning
swz56x,DevOps Fundamentals for Deep Learning Engineers,"I wanted to know what are some DevOps fundamentals that I as a Deep Learning Engineer should really know?

I have enough hands on experience in DL itself but I do not know A LOT about ML or DL in production. All around me I see people deploying their models on web, building applications, hooking up to AWS, creating and managing APIs and what not and I do not know anything about any of it! I am a self learned DL enthusiast so maybe that's the reason, but I would really love to have a roadmap to know what else I need to learn.

Thanks.",29,9,theahmedmustafa,2022-02-20 11:18:12,https://www.reddit.com/r/deeplearning/comments/swz56x/devops_fundamentals_for_deep_learning_engineers/,0,deeplearning
skhhp2,[R] DeepMind‚Äôs AlphaCode Generates Code at a Level Competitive With Human Programmers,"A DeepMind research team presents AlphaCode, an automated code-generation system that can create novel solutions for programming problems that require deep reasoning and achieves a top 54.3% ranking in programming competitions. 

Here is a quick read: [DeepMind‚Äôs AlphaCode Generates Code at a Level Competitive With Human Programmers.](https://syncedreview.com/2022/02/04/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-200/)

DeepMind has released its CodeContests dataset of competitive programming problems and solutions on [GitHub](https://github.com/deepmind/code_contests). The paper *Competition-Level Code Generation with AlphaCode* is on [Google Cloud Storage](https://storage.googleapis.com/deepmind-media/AlphaCode/competition_level_code_generation_with_alphacode.pdf).",28,0,Yuqing7,2022-02-04 16:25:43,https://www.reddit.com/r/deeplearning/comments/skhhp2/r_deepminds_alphacode_generates_code_at_a_level/,0,deeplearning
r09e28,Finding why Pytorch Lightning made my training 4x slower.,,30,3,vonadz,2021-11-23 09:18:41,https://medium.com/@florianernst59/finding-why-pytorch-lightning-made-my-training-4x-slower-ae64a4720bd1,0,deeplearning
qukdof,Nvidia RTX 3090 vs A5000,"Nvidia provides a variety of GPU cards, such as Quadro, RTX, A series, and etc.

Some of them have the exact same number of CUDA cores, but the prices are so different.

In terms of model training/inference, what are the benefits of using A series over RTX? (or one series over other)?",30,34,whasuk,2021-11-15 16:33:52,https://www.reddit.com/r/deeplearning/comments/qukdof/nvidia_rtx_3090_vs_a5000/,0,deeplearning
qaf4sw,Deep Learning and How it works?,,29,5,None,2021-10-18 04:17:07,https://www.reddit.com/gallery/qaf4sw,0,deeplearning
psbhme,Bookmark This Curated List of Github Repositories for Machine Learning,,29,0,vadhavaniyafaijan,2021-09-21 04:32:02,https://www.theinsaneapp.com/2021/09/best-github-repository-for-machine-learning.html,0,deeplearning
pg2pzi,Here is what I learned from writing 50 summaries of popular AI papers!,,29,1,None,2021-09-01 20:46:46,https://www.casualganpapers.com/how-to-learn-to-read-ai-papers-quickly/How-To-Read-AI-Papers-explained.html,0,deeplearning
ofhugb,"""Learn AI Together"" Discord community is looking for teachers, teacher assistants, or professionals willing to help people learning AI by answering questions from time to time"," 

Hey everyone! We are looking for teachers, teacher assistants, or professionals willing to help and exchange with people learning AI by answering questions from time to time.

We are an AI-enthusiasts community of over 15'000 people now where members can chat, ask questions, share resources and projects, find job offers, etc. We are now focusing on getting experts or advanced members to join us and help us help others.

More info about the community and how to join us: [Learn AI Together](https://www.louisbouchard.ai/learn-ai-together/)

Excited to chat with you there!",27,0,OnlyProggingForFun,2021-07-07 12:24:17,https://www.reddit.com/r/deeplearning/comments/ofhugb/learn_ai_together_discord_community_is_looking/,0,deeplearning
oez127,What OpenAI and GitHub‚Äôs ‚ÄúAI pair programmer‚Äù means for the software industry,,31,6,bendee983,2021-07-06 16:56:22,https://bdtechtalks.com/2021/07/05/openai-github-gpt-3-copilot/,0,deeplearning
nqg5oz,Did Deepmind ever publish a paper on how they reduced the energy consumption of Google's data center?,,27,1,kalzbra,2021-06-02 07:32:20,https://www.reddit.com/r/deeplearning/comments/nqg5oz/did_deepmind_ever_publish_a_paper_on_how_they/,0,deeplearning
nanbdg,Understanding Optimization Algorithms of Neural Networks,"Hi everyone! I recently read this [wonderful piece](https://distill.pub/2017/momentum/) about the optimization of neural networks. And then I start to research on latest optimization algoritms such as Adagrad and Adam, but I realized that I can only scratch the surface. The original papers was really intense, and the blog posts that I saw was too simple.

So my question is where should I learn these topics in advance? What is the starting point? I think Classical convex optimization books is little bit different, am I right? Any book or blog post or course suggestion will be appreciated.

Ps: I have some background on basics (linear algebra, probability, neural networks in general)",29,3,tandir_boy,2021-05-12 12:19:57,https://www.reddit.com/r/deeplearning/comments/nanbdg/understanding_optimization_algorithms_of_neural/,0,deeplearning
mf3x2r,"MuZero - Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model Paper explained!",,31,3,gordicaleksa,2021-03-28 16:14:15,https://youtu.be/mH7f7N7s79s,0,deeplearning
lulinv,Very realistic Tom Cruise Deepfake | AI Tom Cruise,,31,6,cmillionaire9,2021-02-28 17:36:00,https://youtu.be/iyiOVUbsPcM,0,deeplearning
khdco3,2020‚Äôs Top 15 Machine Learning & AI Research Papers,,29,0,RubiksCodeNMZ,2020-12-21 08:36:07,https://rubikscode.net/2020/12/21/2020s-top-15-machine-learning-ai-research-papers/,0,deeplearning
jgnokl,"Is the Practical deep learning for coders course recommended as it is focusing entirely on fast.ai. I want to get a good grasp on pytorch and its modules, does the course offer that?","So i understand that [fast.ai](https://fast.ai) is a wrapper for the pytorch framework, is that going to give me an insight into pytorch? If not, is it possible to do their exercises from scratch myself by referring to the pytorch documentation? I am relatively a beginner, have some experience with keras that's it 

&#x200B;",28,6,Dbhasin123,2020-10-23 14:02:44,https://www.reddit.com/r/deeplearning/comments/jgnokl/is_the_practical_deep_learning_for_coders_course/,0,deeplearning
je28zo,BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding (Paper Explained),,29,0,deeplearningperson,2020-10-19 14:06:20,https://youtu.be/j9toSIRf4RI,0,deeplearning
jd8yod,A Step by Step Guide to Build a Powerful Abstractive Summarization Model with T5 Transformers.,,27,1,snrspeaks,2020-10-18 03:16:53,https://shivanandroy.com/transformers-generating-arxiv-papers-title-from-abstracts/,0,deeplearning
iwk50x,DCGAN 3d models training,,29,16,apseren,2020-09-20 19:15:35,https://www.youtube.com/watch?v=ycwZzkwEsoc,0,deeplearning
iobuf5,[D] Which GPU(s) to get for Deep Learning (Updated for RTX 3000 Series),"Tim Dettmers just updated his legendary blogpost to include advice for the RTX 3000 series

Blog: [https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/)

PS: I had a chance to interview him earlier last year, this interview also has some very general PC Building advice (among other topics): [https://www.youtube.com/watch?v=8Fp9m4fNDQ4](https://www.youtube.com/watch?v=8Fp9m4fNDQ4)",29,4,init__27,2020-09-07 17:28:39,https://www.reddit.com/r/deeplearning/comments/iobuf5/d_which_gpus_to_get_for_deep_learning_updated_for/,0,deeplearning
hgj2b7,"From Lyft researchers: The largest self-driving dataset for motion prediction to date, with over 1,000 hours of data!",,29,2,MLtinkerer,2020-06-26 23:57:43,/r/LatestInML/comments/hgibwr/from_lyft_researchers_the_largest_selfdriving/,0,deeplearning
h7gzmj,Ai in sports,,29,2,cmillionaire9,2020-06-12 08:39:54,https://youtu.be/ObVtktCUnr8,0,deeplearning
gugdo5,Free zoom lecture about advances in deep learning and 3D modeling for reddit community going again,"Following the amazing turn in of redditors for this lecture (500 people registered O\_O) We are having 4 more free zoom events for the reddit community.

The lecture is about the advances in Academia in automatic 3D modeling, the lecture is called ""From 2D to 3D with AI"". I usually teach it at conferences and machine learning courses.

There are 2 sets of the events, each set is in two different times to allow for people from different parts of the planet to attend, feel free to join :) These are our reddit events links:

1. [West Hemisphere (technical) - June 5th](https://www.reddit.com/r/2D3DAI/comments/gu097x/from_2d_to_3d_using_artificial_intelligence_west/)
2. [East Hemisphere (technical) - June 5th](https://www.reddit.com/r/2D3DAI/comments/gu06j6/from_2d_to_3d_using_artificial_intelligence_east/)
3. [West Hemisphere (semi-technical) - June 4th](https://www.reddit.com/r/2D3DAI/comments/gu07uq/from_2d_to_3d_using_artificial_intelligence_west/)
4. [East Hemisphere (semi-technical) - June 4th](https://www.reddit.com/r/2D3DAI/comments/gu072a/from_2d_to_3d_using_artificial_intelligence_east/)

The semi-technical lecture does not require background knowledge, while the technical will require intro level knowledge of neural networks, especially CNNs and ResNet. The content for both lectures is quite similar other than some technical details, so please pick the one that is right for you.",30,8,pinter69,2020-06-01 07:53:27,https://www.reddit.com/r/deeplearning/comments/gugdo5/free_zoom_lecture_about_advances_in_deep_learning/,0,deeplearning
giu5d2,Horovod: Uber‚Äôs Open Source Distributed Deep Learning Framework (Codes and Paper included),,28,2,ai-lover,2020-05-13 07:20:25,https://www.marktechpost.com/2020/05/13/horovod-ubers-open-source-distributed-deep-learning-framework/,0,deeplearning
gcney2,Tips on managing Deep Learning experiments,"Hi, since DL normally needs a lot of experiments with trial and error, but the code and projects can be in a mess when they out of control, I mean many trials, algorithms, models, parameters,  libraries, dependencies, platforms and GPUs, etc. If you run many experiments and have a 3-day holiday, you may even forget what are these files in your remote machine, not to mention how to collect the results. So, are there any tips on better managing Deep Learning experiments?",29,14,AlexanderYau,2020-05-03 08:55:08,https://www.reddit.com/r/deeplearning/comments/gcney2/tips_on_managing_deep_learning_experiments/,0,deeplearning
fvx7wk,"How to train an AI to do ""DIVISION"" | Learning Unnecessary Things | Epis...",,30,2,theunnecessarythings,2020-04-06 11:37:44,https://www.youtube.com/watch?v=_2uykvQF9-M&feature=share,0,deeplearning
fpuo09,No need to switch from Jupyter to any IDE! A visual debugger for Jupyterlab is here,,29,3,bhavesh91,2020-03-27 10:31:02,http://youtu.be/CdZN_vVfHqw,0,deeplearning
fe9wz0,Consumer GPU best suited to machine learning /training networks (from a cost / benefit perspective)?,"Forgive me if this is the wrong sub, I apologize! If it is, maybe someone could at least point me in the right direction.

I rambled on about background info for too long, so see bottom of post for background. Question itself follows: 


I know the primary difference is that RTX cards can do ray-tracing, while GTX cannot -- but it's not immediately apparent to me whether I should care, given that I won't be using the GPU for its ability to render realistic real-time action scenes.

Given that the GTX line is considerably more affordable, I'd like to know if the RTX equivalents will outperform the GTX counterparts in tasks like neural network training. Or even if I should bite the bullet and spring for a Quadro (though I sincerely hope that won't be the case). Money is very much an issue here, and i'll be trying to get any recommendations used or refurbed.  I have a baby on the way and cant justify the price tag on new high end parts at MSRP.

I'm looking to build/purchase a workstation to use from home for research/data analysis (high- throughput of z-stacks containing 20-40 16 bit slices at 1280x1280 resolution, in two color channels per slice). That ends up being around 440 individual high-res 16bit images to process (z- projections, 3d projections, background subtraction, CLAHE, registration, segmentation, ROI /signal counting)... it's a LOT of work. Well, a lot of time twiddling my thumbs while the 2012 HP z220 at my desk thrashes and cries in agony. I've written programs to carry out the whole process from receiving the Z-stacks to spitting out all the processed data and summary sheets. It just takes AGES on this methuselah. I also have a background in machine learning and deep neural networks, and would like to bring those benefits to my new lab.  I'm sure i'll be granted a new system at work sooner rather than later, but I'd like to upgrade my home setup as well (currently composed of a 5 year old ZBook I pushed to 32GB RAM with 3 screens). 

While I play some games, theyre all old and have no trouble on any gpu i've seen (EverQuest, if you're familiar). I run 3 characters, one per screen, and my zbook has no problem rendering all three at respectable settings. But I also do fairly serious and intensive music production, so more, faster cpus are the only thing to really help in that arena. 

I'm looking at NVidia graphics cards, since it's so much easier to push parallel processing tasks to the GPU with something like CUDA than it is to jury-rig a workaround for an AMD card. Specifically, i'm trying to decide between a GTX and an RTX series card.",29,17,Avast_WM,2020-03-06 07:14:22,https://www.reddit.com/r/deeplearning/comments/fe9wz0/consumer_gpu_best_suited_to_machine_learning/,0,deeplearning
f6r8o4,Information Extraction from Receipts with Graph Convolutional Networks,,29,4,manneshiva,2020-02-20 10:34:55,https://nanonets.com/blog/information-extraction-graph-convolutional-networks/?utm_source=reddit&utm_medium=social&utm_campaign=gcn&utm_content=dl,0,deeplearning
e5wwfu,Course: Deep Learning in Computer Vision,"Course: Deep Learning in Computer Vision 

By Prof. Kosta Derpanis, Ryerson University, Canada

Computer Vision is broadly defined as the study of recovering useful properties of the world from one or more images.¬† In recent years, Deep Learning has emerged as a powerful tool for addressing computer vision tasks.¬† This course will cover a range of foundational topics at the intersection of Deep Learning and Computer Vision.

Slides and Videos 

#computerscience #computervision #deeplearning 

http://www.scs.ryerson.ca/~kosta/CP8309-F2018/index.html",29,4,aiforworld2,2019-12-04 09:44:16,https://www.reddit.com/r/deeplearning/comments/e5wwfu/course_deep_learning_in_computer_vision/,0,deeplearning
dge1qu,AI & Architecture,,29,2,cmillionaire9,2019-10-11 11:53:01,https://youtu.be/45d5W6jJ0SQ,0,deeplearning
celnq5,Implementing K-Means Clustering From Scratch: Simply Explained,,28,4,None,2019-07-18 01:04:07,https://www.youtube.com/watch?v=8nOIB5LDiWo&t=133s,0,deeplearning
bq2s8b,Indian Digits Dataset via CMATERdb in easy to use NumPy format,"CMATERdb is the pattern recognition database repository created at the 'Center for Microprocessor Applications for Training Education and Research' (CMATER) research laboratory, Jadavpur University, Kolkata 700032, INDIA. This database is free for all non-commercial uses.

**Dataset Description:**

* **CMATERdb 3.1.1: Handwritten Bangla numeral database** is a balanced dataset of total 6000 Bangla numerals (32x32 RGB coloured, 6000 images), each having 600 images per class (per digit).
* **CMATERdb 3.2.1: Handwritten Devanagari numeral database** is a balanced dataset of total 3000 Devanagari numerals (32x32 RGB coloured, 3000 images), each having 300 images per class (per digit).
* **CMATERdb 3.4.1: Handwritten Telugu numeral database** is a balanced dataset of total 3000 Telugu numerals (32x32 RGB coloured, 3000 images), each having 300 images per class (per digit).

**Links:**

[GitHub Repository](https://github.com/prabhuomkar/CMATERdb)

[Download Link](https://github.com/prabhuomkar/CMATERdb#get-the-data)

Please acknowledge CMATER explicitly, whenever you use this database for academic and research purposes.",29,0,op_prabhuomkar,2019-05-18 10:57:49,https://www.reddit.com/r/deeplearning/comments/bq2s8b/indian_digits_dataset_via_cmaterdb_in_easy_to_use/,0,deeplearning
bm3h1o,"Fast-Pytorch with Google Colab: Pytorch Tutorial, Pytorch Implementations","This    repo aims to cover Pytorch details, Pytorch example implementations,    Pytorch sample codes, running Pytorch codes with Google Colab (with  K80   GPU/CPU) in a nutshell.

**Tutorial Link:** [**https://github.com/omerbsezer/Fast-Pytorch**](https://github.com/omerbsezer/Fast-Pytorch)

## Table of Contents:

* üî•[Fast Pytorch Tutorial](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#pytorchtutorial)  

   * [Pytorch Playground](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#pytorchplayground)  

      * üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/Pytorch_Playground.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/Pytorch_Playground.ipynb)
   * [Model (Neural Network Layers)](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#model)
   * [Optimizer](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#optimizer)
   * [Loss Functions](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#lossfunctions)
   * [Pooling Layers](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#poolinglayers)
   * [Non-linear activation functions](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#nonlinearactivation)
   * [Basic 2 Layer NN](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#example)
* üî•[Fast Torchvision Tutorial](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#torchvisiontutorial)  

   * [ImageFolder](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#imagefolder)
   * [Transforms](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#transforms)
   * [Datasets](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#datasets)
   * [Models](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#torchvisionmodels)
   * [Utils](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#utils)
* üî•[Pytorch with Google Colab](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#pytorchcolab)
* üî•[Pytorch Example Implementations](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#pytorchexamples)  

   * [MLP](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#mlp)  

      * MLP 1 Class with Binary Cross Entropy (BCE) Loss: üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_1class_BinaryCrossEntropyLoss.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_1class_BinaryCrossEntropyLoss.ipynb)
      * MLP 2 Classes with Cross Entropy Loss: üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_2class_CrossEntropyLoss.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_2class_CrossEntropyLoss.ipynb)
      * MLP 3-Layer with MNIST Example: üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_3layer_MNIST.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/MLP_3layer_MNIST.ipynb)
   * [CNN](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#cnn)  

      * CNN with MNIST Example: üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/CNN_Mnist.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/CNN_Mnist.ipynb)
      * Improved CNN with MNIST Example: üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/Improved_CNN_Mnist.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/Improved_CNN_Mnist.ipynb)
   * [CNN Visualization](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#cnnvisualization)  

      * CNN Visualization: üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/CNN_Visualization.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/CNN_Visualization.ipynb)
   * [RNN](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#rnn)  

      * RNN Text Generation: üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/RNN_word_embeddings.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/RNN_word_embeddings.ipynb)
   * [Transfer Learning](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#transferlearning)  

      * Transfer Learning Implementation: üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/TransferLearning.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/TransferLearning.ipynb)
   * [DCGAN](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#dcgan)  

      * DCGAN Implementation: üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/DCGAN.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/DCGAN.ipynb)
   * [ChatBot](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#chatbot)  

      * Chatbot Implementation: üìó[\[Colab\]](https://colab.research.google.com/github/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/ChatBot.ipynb), üìì[\[Notebook\]](https://github.com/omerbsezer/Fast-Pytorch/blob/master/Learning_Pytorch/ChatBot.ipynb)
* üî•[Pytorch Sample Codes](https://github.com/omerbsezer/Fast-Pytorch/blob/master/README.md#pytorchsamplecodes)

**Extra:** Reinforcement Learning Tutorial:

[**https://github.com/omerbsezer/Reinforcement\_learning\_tutorial\_with\_demo**](https://github.com/omerbsezer/Reinforcement_learning_tutorial_with_demo)

**Extra:**     Image  Generation With AI:  Generative Models Tutorial with    Python+Tensorflow  Codes (GANs, VAE,  Bayesian Classifier Sampling,    Auto-Regressive Models,  Generative  Models in RL)

**Tutorial Link**: [**https://github.com/omerbsezer/Generative\_Models\_Tutorial\_with\_Demo**](https://github.com/omerbsezer/Generative_Models_Tutorial_with_Demo)",28,1,obsezer,2019-05-08 10:15:09,https://www.reddit.com/r/deeplearning/comments/bm3h1o/fastpytorch_with_google_colab_pytorch_tutorial/,0,deeplearning
b59omy,"A PyTorch implementation of ""Capsule Graph Neural Network"" (ICLR 2019).","&#x200B;

https://preview.redd.it/vff6x48l69o21.jpg?width=1337&format=pjpg&auto=webp&s=221167d44b08dc31f8262a0dd4bbfd6c277ac053

PyTorch: [https://github.com/benedekrozemberczki/CapsGNN](https://github.com/benedekrozemberczki/CapsGNN)

Paper: [https://openreview.net/forum?id=Byl8BnRcYm](https://openreview.net/forum?id=Byl8BnRcYm)

Abstract:

The high-quality node embeddings learned from the Graph Neural Networks (GNNs) have been applied to a wide range of node-based applications and some of them have achieved state-of-the-art (SOTA) performance. However, when applying node embeddings learned from GNNs to generate graph embeddings, the scalar node representation may not suffice to preserve the node/graph properties efficiently, resulting in sub-optimal graph embeddings.  Inspired by the Capsule Neural Network (CapsNet), we propose the Capsule Graph Neural Network (CapsGNN), which adopts the concept of capsules to address the weakness in existing GNN-based graph embeddings algorithms. By extracting node features in the form of capsules, routing mechanism can be utilized to capture important information at the graph level. As a result, our model generates multiple embeddings for each graph to capture graph properties from different aspects. The attention module incorporated in CapsGNN is used to tackle graphs with various sizes which also enables the model to focus on critical parts of the graphs.  Our extensive evaluations with 10 graph-structured datasets demonstrate that CapsGNN has a powerful mechanism that operates to capture macroscopic properties of the whole graph by data-driven. It outperforms other SOTA techniques on several graph classification tasks, by virtue of the new instrument.

&#x200B;

&#x200B;",27,0,benitorosenberg,2019-03-25 11:48:48,https://www.reddit.com/r/deeplearning/comments/b59omy/a_pytorch_implementation_of_capsule_graph_neural/,0,deeplearning
ayt4mp,Google Debuts TensorFlow 2.0 Alpha,,30,1,Yuqing7,2019-03-08 17:52:46,https://medium.com/syncedreview/google-debuts-tensorflow-2-0-alpha-ef1e01180c29,0,deeplearning
af1a1s,Deep Learning Basics: Introduction and Overview - MIT (Lex Fridman ),,31,1,ai-lover,2019-01-11 23:12:39,https://www.youtube.com/watch?v=O5xeyoRL95U,0,deeplearning
a2t77b,DeepMind AlphaFold Delivers ‚ÄúUnprecedented Progress‚Äù on Protein Folding,,30,0,gwen0927,2018-12-03 21:24:15,https://medium.com/syncedreview/deepmind-alphafold-delivers-unprecedented-progress-on-protein-folding-789fcc1420ea,0,deeplearning
9zsfrs,Advanced Deep Learning & Reinforcement Learning,,29,0,keghn,2018-11-23 21:48:28,https://www.youtube.com/playlist?list=PLqYmG7hTraZDNJre23vqCGIVpfZ_K2RZs,0,deeplearning
9x76t6,"For anyone looking to get into machine learning, I would advise that you don't learn the behemoth libraries like Tensorflow or Theano, but instead learn how to use a high-level API like Keras. Here's a quick video to explain what it is. Hope I was helpful!",,30,3,antaloaalonso,2018-11-15 03:05:04,https://www.youtube.com/watch?v=yMzTrZ3_NIA&t=2s,0,deeplearning
9w28qy,Website for trending deep learning research papers.,,29,2,Karthik9999,2018-11-11 08:22:40,http://assert.pub,0,deeplearning
8v0qc7,T2F: Text to Face generation using Deep Learning,,30,0,akanimax,2018-06-30 09:24:22,https://medium.com/@animeshsk3/t2f-text-to-face-generation-using-deep-learning-b3b6ba5a5a93,0,deeplearning
1648zlm,"Oh ok, cool.",,30,4,Blehdi,2023-08-29 05:01:09,https://i.redd.it/4221qzmgezkb1.jpg,0,deeplearning
14x5ceq,A Comparison of Large Language Models (LLMs) in Biomedical Domain,,28,0,dahmedahe,2023-07-11 22:14:18,https://provectus.com/blog/comparison-large-language-models-biomedical-domain/,0,deeplearning
12okc3x,How does GPT4 learn to become multimodal compared to GPT3.5 during the training process?,**How does GPT4 learn to become multimodal compared to GPT3.5 during the training process?**,27,8,Fabulous-Regular7478,2023-04-16 18:40:01,https://www.reddit.com/r/deeplearning/comments/12okc3x/how_does_gpt4_learn_to_become_multimodal_compared/,0,deeplearning
12749vf,Any advanced and updated DL courses?,"Do you know any Deep Learning course that covers topics such as attention, self-attention, transformes, diffusion models, and eventually LLM? It would be great if it has theory but also applications and examples.

Context: I work as a ML eng, and I have experience working with CNNs, GANs, LSTMs and some other architectures. In the last years I've been mostly doing backend or working with simple ML stuff. I would like to be updated (again).  


They can be free or paid. Thanks!",28,7,nuquichoco,2023-03-31 00:20:59,https://www.reddit.com/r/deeplearning/comments/12749vf/any_advanced_and_updated_dl_courses/,0,deeplearning
10sk5ey,New Book: Understanding Deep Learning,"Hey all,  I have written a new  textbook on Deep Learning and I'm looking for people to read it to find mistakes, ambiguities etc.  The draft is online at:  


[https://udlbook.github.io/udlbook/](https://udlbook.github.io/udlbook/)  


It starts at a very basic level without requiring much math and works right up to the latest results in diffusion models.  There are novel figures that illustrate every idea.  Based on other questions I've seen in this forum, it should be useful for a bunch of you.  


TOC below.   Enjoy!

https://preview.redd.it/8wet0aht4zfa1.png?width=355&format=png&auto=webp&s=bc7c6fb33365477bbc83bbad4ac8029d85a7b3fa",29,4,SimonJDPrince,2023-02-03 13:20:18,https://www.reddit.com/r/deeplearning/comments/10sk5ey/new_book_understanding_deep_learning/,0,deeplearning
10cgsft,Chronological list of Resources to Learn Deep Learning from Complete Beginner to Advanced Level,,30,2,glum-platimium,2023-01-15 10:42:46,https://www.codelivly.com/resources-to-learn-deep-learning-from-complete-beginner-to-advanced-level/,0,deeplearning
w8cfd2,Search for code implementations of AI/ML papers like a pro!,"**Pro tip for machine learners:** Instead of searching around on Google or elsewhere for code implementations for AI/machine learning techniques/methods/tasks, you can now directly find them on CatalyzeX ‚Äî we‚Äôve rolled out a search filter toggle that allows you to see only papers that have code available! https://www.catalyzex.com/s/photo%20style%20transfer?with\_code=true 

Do check it out live, and your feedback and constructive criticism is highly welcome anytime! üôè (Disclaimer: I am one of the creators of CatalyzeX)

https://reddit.com/link/w8cfd2/video/x352u33mxud91/player",28,6,MLtinkerer,2022-07-26 06:36:26,https://www.reddit.com/r/deeplearning/comments/w8cfd2/search_for_code_implementations_of_aiml_papers/,0,deeplearning
vokp2h,The U-Net neural network architecture for semantic segmentation (and other things),,28,4,roycoding,2022-06-30 22:24:40,https://i.redd.it/epwkjfogas891.png,0,deeplearning
systn5,A Program to Build E(N)-Equivariant Steerable CNNs - Link to a free online lecture by the author in comments,,29,6,dataskml,2022-02-22 17:16:03,https://i.redd.it/v7jblbkk3fj81.png,0,deeplearning
s2xj5w,Football Analytics pipeline using #DeepLearning and #ComputerVision,,29,16,average-joee,2022-01-13 11:39:09,https://www.youtube.com/watch?v=pbdi6XG1nCg,0,deeplearning
nwk1zy,Non-Parametric Transformers | Paper explained!,,28,1,gordicaleksa,2021-06-10 10:15:04,https://youtu.be/6ekOVosCQN8,0,deeplearning
nrvxgq,Looking for study partners,"I'm looking for 4 people who are experienced and interested in deep learning. I'd like to organize a study group for reading 2019-2021 top conference (ICML/ICLR/NIPS/AAAI/EMNLP/COLT/..) paper together. This will be a 3 months study group. Details:

Everyone picks 5 papers from top conference --> we take turns to share the content/idea/points of the paper -->  once a week, 2 people per week, 30-60 mins for one person --> use slack as communication tool and use google meet for the meeting

Rules: every week attendance !! prepare slides before presentation!!",28,16,Environment_123,2021-06-04 03:53:00,https://www.reddit.com/r/deeplearning/comments/nrvxgq/looking_for_study_partners/,0,deeplearning
n3ukyd,"The AI Monthly Top 3 ‚Äî April 2021: a curated list of the latest breakthroughs in AI in April 2021 with a clear video explanation, link to a more in-depth article, and references.",,28,0,OnlyProggingForFun,2021-05-03 12:20:50,https://www.louisbouchard.ai/the-ai-monthly-top-3-april-2021/,0,deeplearning
kumrjn,Super new addition to GANs,,26,3,cmillionaire9,2021-01-10 20:54:52,https://youtu.be/0DHOmpAbzCM,0,deeplearning
kszejm,CNN Racoon - Library for creating interactive dashboards for Convolutional Neural Networks,,28,1,RubiksCodeNMZ,2021-01-08 09:48:36,https://github.com/lucko515/cnn-raccoon,0,deeplearning
jzh1eg,"""Graph Structure of Neural Networks"" - A fascinating paper by SNAP Stanford",,28,1,flawnson,2020-11-23 12:52:23,/r/GeometricDeepLearning/comments/jzgyrq/graph_structure_of_neural_networks_a_fascinating/,0,deeplearning
jyayz8,The latest AI algorithm to make the image dance,,27,3,Independent-Square32,2020-11-21 13:45:42,https://youtu.be/i6WT_lcXMgw,0,deeplearning
jvrvxl,[Published this Summer] GameGAN: Whole PAC-MAN Game Recreated Using Only AI by NVIDIA. NO GAME ENGINES NEEDED! Is this the future of game development?,,26,4,OnlyProggingForFun,2020-11-17 12:07:13,https://youtu.be/RzFxhSfTww4,0,deeplearning
j3tlsz,"Are the eternal compatability issues with CUDA, CUDNN, NVIDIA drivers etc. with different (new) releases of tensorflow/keras a good reason for switcing to pytorch.",Basically as the title says. I'm getting tired of running in to these issues again and again? Is it the same with pytorch?,27,30,Seahorsejockey,2020-10-02 12:32:42,https://www.reddit.com/r/deeplearning/comments/j3tlsz/are_the_eternal_compatability_issues_with_cuda/,0,deeplearning
j0akdm,Some deep learning project ideas! (Note: I've got all of these implemented on my GitHub),,27,7,gordicaleksa,2020-09-26 17:55:15,https://youtu.be/ynx48f7LhCc,0,deeplearning
ige3cd,Deep Learning Object Detection at the zoo,,26,4,None,2020-08-25 15:14:48,https://youtu.be/sh8pGFGZABM,0,deeplearning
g0nerc,Retail and Artificial Intelligence.,,27,1,cmillionaire9,2020-04-13 17:25:59,https://youtu.be/TCLGMKH3vH4,0,deeplearning
16hiuep,Deepnudes for fee ai ??,,26,344,Acceptable_Beat_9713,2023-09-13 09:55:44,https://www.reddit.com/r/deeplearning/comments/16hiuep/deepnudes_for_fee_ai/,0,deeplearning
1bu6cvp,do you feel like whole AI hype gives bubble vibes or is it just me?,"i feel like AI (ML/DL algorithms) are not very reliable to use to solve real world problems and it is not because of not having enough data, compute power or whatever. i feel like DL algorithms are inherently not very reliable because of stochastic nature of parameter initialization, backpropagation, hidden layers, non interpretability of the output, inherent bias in the data, and I haven't even started on the legal part of collecting data. I know that the world is going apeshit investing in AI, but sooner or later when the reality check hits, the bubble might burst. Is it just me that feels this way? what do you think?",20,37,mal_mal_mal,2024-04-02 18:37:51,https://www.reddit.com/r/deeplearning/comments/1bu6cvp/do_you_feel_like_whole_ai_hype_gives_bubble_vibes/,0,deeplearning
